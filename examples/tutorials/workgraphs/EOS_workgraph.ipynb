{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233a4da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profile<uuid='1ad5c4ff2c1141ee9b4a511ac6859016' name='presto'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aiida import load_profile  \n",
    "load_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ca17e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import load_code\n",
    "from aiida_mlip.data.model import ModelData\n",
    "\n",
    "uri = \"https://github.com/stfc/janus-core/raw/main/tests/models/mace_mp_small.model\"\n",
    "model = ModelData.from_uri(uri, architecture=\"mace_mp\")\n",
    "\n",
    "janus_code = load_code(\"janus@localhost\")\n",
    "qe_code = load_code(\"qe@localhost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14451078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.plugins import CalculationFactory\n",
    "descriptorsCalc = CalculationFactory(\"mlip.descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c433338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_workgraph import WorkGraph, task\n",
    "from pathlib import Path\n",
    "from ase.io import read, write, iread\n",
    "from ase import Atoms\n",
    "import numpy as np\n",
    "from aiida.orm import SinglefileData, Float, InstalledCode, List, Dict, KpointsData, StructureData, load_group, Str, Bool, Int\n",
    "from aiida_quantumespresso.calculations.pw import PwCalculation\n",
    "from aiida_workgraph.manager import get_current_graph\n",
    "from ase import units\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "\n",
    "@task.calcfunction(outputs=[\"scaled_structures\"])\n",
    "def create_scales(\n",
    "    min_v: Float,\n",
    "    max_v:Float,\n",
    "    num_structs: int,\n",
    "    **structures\n",
    "): \n",
    "    lattice_scalars = np.cbrt(np.linspace(min_v.value, max_v.value, num_structs.value))\n",
    "    scaled_structures = {}\n",
    "\n",
    "    for structure in structures.values():\n",
    "\n",
    "        atom = structure.get_ase()\n",
    "        cell = atom.get_cell()\n",
    "\n",
    "        for i, s in enumerate(lattice_scalars):\n",
    "            scaled_atom = atom.copy()\n",
    "            scaled_atom.set_cell(cell * s, scale_atoms=True)\n",
    "            struct_data = f\"struct{i}\"\n",
    "            scaled_structures[struct_data] = StructureData(ase=scaled_atom)\n",
    "    \n",
    "    print(scaled_structures)\n",
    "\n",
    "    return {\n",
    "        \"scaled_structures\": scaled_structures\n",
    "    }\n",
    "\n",
    "@task.graph()\n",
    "def qe(\n",
    "    code: InstalledCode,\n",
    "    kpoints_mesh: List,\n",
    "    task_metadata: Dict,\n",
    "    **scaled_structures,\n",
    "    ):\n",
    "\n",
    "    wg = get_current_graph()\n",
    "\n",
    "    kpoints = KpointsData()\n",
    "    kpoints.set_kpoints_mesh(kpoints_mesh)\n",
    "\n",
    "    pseudo_family = load_group('SSSP/1.3/PBE/efficiency')\n",
    "    \n",
    "    output_structures = {}\n",
    "\n",
    "    for i, structs in scaled_structures:\n",
    "        print(i)\n",
    "        print(structs)\n",
    "            \n",
    "    #         structure = StructureData(ase=structs)\n",
    "    #         pseudos = pseudo_family.get_pseudos(structure=structure)\n",
    "\n",
    "    #         ecutwfc, ecutrho = pseudo_family.get_recommended_cutoffs(\n",
    "    #             structure=structure,\n",
    "    #             unit='Ry',\n",
    "    #         )\n",
    "\n",
    "    #         pw_params = {\n",
    "    #             \"CONTROL\": {\n",
    "    #                 \"calculation\": \"scf\",\n",
    "    #                 'tprnfor': True,\n",
    "    #                 'tstress': True,\n",
    "    #             },\n",
    "    #             \"SYSTEM\": {\n",
    "    #                 \"ecutwfc\": ecutwfc,\n",
    "    #                 \"ecutrho\": ecutrho,\n",
    "    #             },\n",
    "    #         }\n",
    "            \n",
    "    #         qe_task = wg.add_task(\n",
    "    #             PwCalculation,\n",
    "    #             code=code,\n",
    "    #             parameters=pw_params,\n",
    "    #             kpoints=kpoints,\n",
    "    #             pseudos=pseudos,\n",
    "    #             metadata=task_metadata.value,\n",
    "    #             structure=structure,\n",
    "    #         )\n",
    "\n",
    "    #         output_structures[f\"struct{i}\"] = {\n",
    "    #                 \"trajectory\":qe_task.outputs.output_trajectory,\n",
    "    #                 \"parameters\": qe_task.outputs.output_parameters\n",
    "    #             }\n",
    "        \n",
    "    #     wg.update_ctx({\n",
    "    #         \"structures\": output_structures\n",
    "    #     })\n",
    "\n",
    "    # return {\n",
    "    #     \"structures\": wg.ctx.structures,\n",
    "    # }\n",
    "\n",
    "@task.calcfunction(outputs=[\"test_file\", \"train_file\", \"valid_file\"])\n",
    "def create_train_files(**structures):\n",
    "\n",
    "    # tmpfile = tempfile.NamedTemporaryFile(suffix=\".extxyz\")\n",
    "    \n",
    "    structures_stack = list(structures.keys())\n",
    "    shuffle(structures_stack)\n",
    "    \n",
    "    n = len(structures_stack)\n",
    "    i1 = int(n*0.7)\n",
    "    i2 = int(n*0.9)\n",
    "\n",
    "    training_split = {\n",
    "        \"test\":structures_stack[:i1],\n",
    "        \"train\":structures_stack[i1:i2],\n",
    "        \"valid\":structures_stack[i2:]\n",
    "    }\n",
    "\n",
    "    files = {}\n",
    "\n",
    "    for split, split_structures in training_split.items():\n",
    "        tmpfile = tempfile.NamedTemporaryFile(suffix=f\"{split}.extxyz\")\n",
    "        for struct in split_structures:\n",
    "\n",
    "            trajectory = structures[struct][\"trajectory\"]\n",
    "            fileStructure = trajectory.get_structure(index=0)\n",
    "            fileAtoms = fileStructure.get_ase()\n",
    "\n",
    "            stress = trajectory.arrays[\"stress\"][0]\n",
    "            converted_stress = stress * units.GPa\n",
    "            fileAtoms.info[\"qe_stress\"] = converted_stress\n",
    "\n",
    "            fileAtoms.info[\"units\"] = {\"energy\": \"eV\",\"forces\": \"ev/Ang\",\"stress\": \"ev/Ang^3\"}\n",
    "            fileAtoms.set_array(\"qe_forces\", trajectory.arrays[\"forces\"][0])\n",
    "\n",
    "            parameters = structures[struct][\"parameters\"]\n",
    "            fileParams = parameters.get_dict()\n",
    "            fileAtoms.info[\"qe_energy\"] = fileParams[\"energy\"]\n",
    "            \n",
    "            write(Path(tmpfile.name), fileAtoms, append=True)\n",
    "\n",
    "        files[f\"{split}_file\"] = SinglefileData(tmpfile)\n",
    "    \n",
    "    for filename, file in files.items():\n",
    "        with file.as_path() as path:\n",
    "            num_structs = len(read(path, index=\":\"))\n",
    "        print(f\"{filename} has {num_structs} structures\")\n",
    "\n",
    "    return{\n",
    "        \"test_file\": files[\"test_file\"],\n",
    "        \"train_file\": files[\"train_file\"],\n",
    "        \"valid_file\": files[\"valid_file\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a35e9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cuda\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "}\n",
    "\n",
    "scales_inputs = {\n",
    "\n",
    "}\n",
    "\n",
    "qe_inputs = {\n",
    "    \"task_metadata\": Dict({\n",
    "            \"options\": {\n",
    "                \"resources\": {\n",
    "                    \"tot_num_mpiprocs\":1,\n",
    "                    'num_mpiprocs_per_machine':1,\n",
    "                    'num_cores_per_mpiproc':8,\n",
    "                },\n",
    "                \"max_wallclock_seconds\": 3600,\n",
    "                \"queue_name\": \"scarf\",\n",
    "                \"qos\": \"scarf\",\n",
    "                \"environment_variables\": {},\n",
    "                \"withmpi\": True,\n",
    "                \"prepend_text\": \"\"\"\n",
    "                \"\"\",\n",
    "                \"append_text\": \"\",\n",
    "            },\n",
    "    }),\n",
    "    \"kpoints_mesh\": List([1, 1, 1]),\n",
    "    \"code\": qe_code,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9074302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with WorkGraph(\"EOS_workflow\") as wg:\n",
    "\n",
    "    initial_structure = str(Path(\"../structures/NaCl-traj.xyz\").resolve())\n",
    "\n",
    "    structures = {}\n",
    "    for i, struct in enumerate(iread(initial_structure)):\n",
    "        structures[f\"structs{i}\"] = StructureData(ase=struct)\n",
    "\n",
    "    scales_task = wg.add_task(\n",
    "        create_scales,\n",
    "        min_v= 0.95,\n",
    "        max_v= 1.05,\n",
    "        num_structs= 12,\n",
    "        **structures\n",
    "    )\n",
    "\n",
    "    qe_task = wg.add_task(\n",
    "        qe,\n",
    "        **qe_inputs,\n",
    "        scaled_structures=scales_task.outputs.scaled_structures\n",
    "    )\n",
    "    \n",
    "    # train_task = wg.add_task(\n",
    "    #     create_train_files,\n",
    "    #     structures=qe_task.outputs.structures\n",
    "    # )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f230babb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2025 11:53:51 AM <97822> aiida.broker.rabbitmq: [WARNING] RabbitMQ v3.12.1 is not supported and will cause unexpected problems!\n",
      "11/21/2025 11:53:51 AM <97822> aiida.broker.rabbitmq: [WARNING] It can cause long-running workflows to crash and jobs to be submitted multiple times.\n",
      "11/21/2025 11:53:51 AM <97822> aiida.broker.rabbitmq: [WARNING] See https://github.com/aiidateam/aiida-core/wiki/RabbitMQ-version-to-use for details.\n",
      "11/21/2025 11:53:52 AM <97822> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [16387|WorkGraphEngine|continue_workgraph]: tasks ready to run: create_scales\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'struct0': <StructureData: uuid: 8584cf18-ed5e-4340-9628-60c648d6d597 (unstored)>, 'struct1': <StructureData: uuid: a66774bf-b5da-4bf9-ab31-a4cddf4a6bca (unstored)>, 'struct2': <StructureData: uuid: 6312ee83-1f49-426d-baa4-a11df8023a55 (unstored)>, 'struct3': <StructureData: uuid: 5fc3e5bd-d14c-452c-8ccd-78c9ea315ace (unstored)>, 'struct4': <StructureData: uuid: 2e7ce5f5-8deb-4d7c-a233-99b73f3937df (unstored)>, 'struct5': <StructureData: uuid: be3c16ce-2fd1-4c12-9a69-5448b0c552b4 (unstored)>, 'struct6': <StructureData: uuid: 20fd22d9-44b3-44e7-a8af-95cc0bf4b227 (unstored)>, 'struct7': <StructureData: uuid: 26019825-d84c-46b3-9313-d42ca5af7223 (unstored)>, 'struct8': <StructureData: uuid: 9880190a-b06c-40e0-91c7-44e6b1a5fcef (unstored)>, 'struct9': <StructureData: uuid: 13d3d141-ba09-4b93-9a4c-d64dac4e5e0d (unstored)>, 'struct10': <StructureData: uuid: 24b6c6c2-0a6c-42cc-b9a0-45698797cab6 (unstored)>, 'struct11': <StructureData: uuid: 00dcb033-752b-4640-a2a8-e2a060028985 (unstored)>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2025 11:53:52 AM <97822> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [16387|WorkGraphEngine|update_task_state]: Task: create_scales, type: CALCFUNCTION, finished.\n",
      "11/21/2025 11:53:52 AM <97822> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [16387|WorkGraphEngine|continue_workgraph]: tasks ready to run: qe\n",
      "11/21/2025 11:53:52 AM <97822> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [16387|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 16404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ase.atoms.Atoms'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2025 11:53:53 AM <97822> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [16404|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "11/21/2025 11:53:53 AM <97822> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [16404|WorkGraphEngine|finalize]: Finalize workgraph.\n",
      "11/21/2025 11:53:53 AM <97822> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [16387|WorkGraphEngine|update_task_state]: Task: qe, type: GRAPH, finished.\n",
      "11/21/2025 11:53:53 AM <97822> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [16387|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "11/21/2025 11:53:53 AM <97822> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [16387|WorkGraphEngine|finalize]: Finalize workgraph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5396929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskSocketNamespace(name='scaled_structures', sockets=[])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg.tasks.qe.inputs.scaled_structures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiida-mlip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
