{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233a4da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profile<uuid='1ad5c4ff2c1141ee9b4a511ac6859016' name='presto'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aiida import load_profile  \n",
    "load_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ca17e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import load_code\n",
    "from aiida_mlip.data.model import ModelData\n",
    "\n",
    "uri = \"https://github.com/stfc/janus-core/raw/main/tests/models/mace_mp_small.model\"\n",
    "model = ModelData.from_uri(uri, architecture=\"mace_mp\")\n",
    "\n",
    "janus_code = load_code(\"janus@localhost\")\n",
    "qe_code = load_code(\"qe@localhost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14451078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.plugins import CalculationFactory\n",
    "descriptorsCalc = CalculationFactory(\"mlip.descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c433338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_workgraph import WorkGraph, task\n",
    "from pathlib import Path\n",
    "from ase.io import read, write, iread\n",
    "from ase import Atoms\n",
    "import numpy as np\n",
    "from aiida.orm import SinglefileData, Float, InstalledCode, List, Dict, KpointsData, StructureData, load_group, Str, Bool, Int\n",
    "from aiida_quantumespresso.calculations.pw import PwCalculation\n",
    "from aiida_workgraph.manager import get_current_graph\n",
    "from ase import units\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from sample_split import process_and_split_data\n",
    "\n",
    "@task.calcfunction(outputs=[\"scaled_file\"])\n",
    "def create_scales(\n",
    "    min_v: Float,\n",
    "    max_v:Float,\n",
    "    num_structs: int,\n",
    "    **structures\n",
    "): \n",
    "    \n",
    "    atoms = []\n",
    "    for i, struct in structures.items():\n",
    "        with struct.as_path() as path:\n",
    "            atoms.append(read(path))\n",
    "\n",
    "    lattice_scalars = np.cbrt(np.linspace(min_v.value, max_v.value, num_structs.value))\n",
    "    b = atoms.copy()\n",
    "    for i, s in enumerate(lattice_scalars):\n",
    "        b[i].set_cell((atoms[i].get_cell()) * s, scale_atoms=True)\n",
    "        write(\"scaled.extxyz\",b[i],append=i>0)\n",
    "\n",
    "    return {\n",
    "        \"scaled_file\": SinglefileData(Path(\"scaled.extxyz\").resolve())\n",
    "    }\n",
    "\n",
    "@task.graph(outputs = [\"structures\"])\n",
    "def qe(\n",
    "    code: InstalledCode,\n",
    "    kpoints_mesh: List,\n",
    "    task_metadata: Dict,\n",
    "    scaled_file: SinglefileData,\n",
    "    ):\n",
    "\n",
    "    wg = get_current_graph()\n",
    "\n",
    "    kpoints = KpointsData()\n",
    "    kpoints.set_kpoints_mesh(kpoints_mesh)\n",
    "\n",
    "    pseudo_family = load_group('SSSP/1.3/PBE/efficiency')\n",
    "    \n",
    "    output_structures = {}\n",
    "\n",
    "    with scaled_file.as_path() as path:\n",
    "        for i, structs in enumerate(iread(path, format=\"extxyz\")):\n",
    "            \n",
    "            structure = StructureData(ase=structs)\n",
    "            pseudos = pseudo_family.get_pseudos(structure=structure)\n",
    "\n",
    "            ecutwfc, ecutrho = pseudo_family.get_recommended_cutoffs(\n",
    "                structure=structure,\n",
    "                unit='Ry',\n",
    "            )\n",
    "\n",
    "            pw_params = {\n",
    "                \"CONTROL\": {\n",
    "                    \"calculation\": \"scf\",\n",
    "                    'tprnfor': True,\n",
    "                    'tstress': True,\n",
    "                },\n",
    "                \"SYSTEM\": {\n",
    "                    \"ecutwfc\": ecutwfc,\n",
    "                    \"ecutrho\": ecutrho,\n",
    "                },\n",
    "            }\n",
    "            \n",
    "            qe_task = wg.add_task(\n",
    "                PwCalculation,\n",
    "                code=code,\n",
    "                parameters=pw_params,\n",
    "                kpoints=kpoints,\n",
    "                pseudos=pseudos,\n",
    "                metadata=task_metadata.value,\n",
    "                structure=structure,\n",
    "            )\n",
    "\n",
    "            output_structures[f\"struct{i}\"] = {\n",
    "                    \"trajectory\":qe_task.outputs.output_trajectory,\n",
    "                    \"parameters\": qe_task.outputs.output_parameters\n",
    "                }\n",
    "        \n",
    "        wg.update_ctx({\n",
    "            \"structures\": output_structures\n",
    "        })\n",
    "            # wg.update_ctx({\n",
    "            #     f\"struct{i}\" :{\n",
    "            #         \"trajectory\":qe_task.outputs.output_trajectory,\n",
    "            #         \"parameters\": qe_task.outputs.output_parameters\n",
    "            #     }\n",
    "            # })\n",
    "\n",
    "    return {\n",
    "        \"structures\": wg.ctx.structures,\n",
    "    }\n",
    "\n",
    "@task.calcfunction(outputs=[\"test_file\"])\n",
    "def create_train_files(**structures):\n",
    "\n",
    "    tmpfile = tempfile.NamedTemporaryFile(suffix=\".extxyz\")\n",
    "    \n",
    "    for structs in structures.values():    \n",
    "\n",
    "        trajectory = structs[\"trajectory\"]\n",
    "\n",
    "        fileStructure = trajectory.get_structure(index=0)\n",
    "        fileAtoms = fileStructure.get_ase()\n",
    "\n",
    "        stress = trajectory.arrays[\"stress\"][0]\n",
    "        converted_stress = stress * units.GPa\n",
    "        fileAtoms.info[\"qe_stress\"] = converted_stress\n",
    "\n",
    "        fileAtoms.info[\"units\"] = {\"energy\": \"eV\",\"forces\": \"ev/Ang\",\"stress\": \"ev/Ang^3\"}\n",
    "        fileAtoms.set_array(\"qe_forces\", trajectory.arrays[\"forces\"][0])\n",
    "\n",
    "        parameters = structs[\"parameters\"]\n",
    "        fileParams = parameters.get_dict()\n",
    "        fileAtoms.info[\"qe_energy\"] = fileParams[\"energy\"]\n",
    "        write(Path(tmpfile.name), fileAtoms, append=True)\n",
    "\n",
    "    process_inputs = {\n",
    "        \"config_types\": Str(\"\"),\n",
    "        \"prefix\": Str(\"\"),\n",
    "        \"scale\": Float(1.0e5),\n",
    "        \"append_mode\": Bool(False),\n",
    "        \"n_samples\": Int(len(structures)),\n",
    "        \"trajectory_data\": tmpfile.name\n",
    "    }\n",
    "\n",
    "    process_and_split_data(**process_inputs)\n",
    "                \n",
    "    return{\n",
    "        \"test_file\": SinglefileData(tmpfile)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a35e9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cuda\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "}\n",
    "\n",
    "scales_inputs = {\n",
    "    \"min_v\": 0.95,\n",
    "    \"max_v\": 1.05,\n",
    "    \"num_structs\": 12\n",
    "}\n",
    "\n",
    "qe_inputs = {\n",
    "    \"task_metadata\": Dict({\n",
    "            \"options\": {\n",
    "                \"resources\": {\n",
    "                    \"tot_num_mpiprocs\":1,\n",
    "                    'num_mpiprocs_per_machine':1,\n",
    "                    'num_cores_per_mpiproc':8,\n",
    "                },\n",
    "                \"max_wallclock_seconds\": 3600,\n",
    "                \"queue_name\": \"scarf\",\n",
    "                \"qos\": \"scarf\",\n",
    "                \"environment_variables\": {},\n",
    "                \"withmpi\": True,\n",
    "                \"prepend_text\": \"\"\"\n",
    "                \"\"\",\n",
    "                \"append_text\": \"\",\n",
    "            },\n",
    "    }),\n",
    "    \"kpoints_mesh\": List([1, 1, 1]),\n",
    "    \"code\": qe_code,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9074302a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defining outputnode\n"
     ]
    }
   ],
   "source": [
    "with WorkGraph(\"EOS_workflow\") as wg:\n",
    "\n",
    "    initial_structure = Path(\"../structures/NaCl-traj.xyz\").resolve()\n",
    "\n",
    "\n",
    "    final_structures = {}\n",
    "\n",
    "    for i, struct in enumerate(iread(initial_structure)):\n",
    "        structure = StructureData(ase=struct)\n",
    "        \n",
    "        descriptors_calc = wg.add_task(\n",
    "            descriptorsCalc,\n",
    "            **calc_inputs,\n",
    "            struct=structure,\n",
    "            calc_per_element=True,\n",
    "        )\n",
    "\n",
    "        final_structures[f\"structs{i}\"] = descriptors_calc.outputs.xyz_output\n",
    "        \n",
    "    scales_task = wg.add_task(\n",
    "        create_scales,\n",
    "        **scales_inputs,\n",
    "        structures=final_structures\n",
    "    )\n",
    "\n",
    "    qe_task = wg.add_task(\n",
    "        qe,\n",
    "        scaled_file=scales_task.outputs.scaled_file,\n",
    "        **qe_inputs\n",
    "    )\n",
    "    \n",
    "    train_task = wg.add_task(\n",
    "        create_train_files,\n",
    "        structures=qe_task.outputs.structures\n",
    "    )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f230babb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/17/2025 04:14:57 PM <165050> aiida.broker.rabbitmq: [WARNING] RabbitMQ v3.12.1 is not supported and will cause unexpected problems!\n",
      "11/17/2025 04:14:57 PM <165050> aiida.broker.rabbitmq: [WARNING] It can cause long-running workflows to crash and jobs to be submitted multiple times.\n",
      "11/17/2025 04:14:57 PM <165050> aiida.broker.rabbitmq: [WARNING] See https://github.com/aiidateam/aiida-core/wiki/RabbitMQ-version-to-use for details.\n",
      "11/17/2025 04:14:58 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|continue_workgraph]: tasks ready to run: Descriptors,Descriptors1,Descriptors2,Descriptors3,Descriptors4,Descriptors5,Descriptors6,Descriptors7,Descriptors8,Descriptors9,Descriptors10,Descriptors11\n",
      "11/17/2025 04:15:00 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 10138, 10143, 10148, 10153, 10158, 10163, 10168, 10173, 10178, 10183, 10188, 10193\n",
      "11/17/2025 04:15:13 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|update_task_state]: Task: Descriptors, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:13 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|update_task_state]: Task: Descriptors1, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:13 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|update_task_state]: Task: Descriptors2, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:14 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|update_task_state]: Task: Descriptors3, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:14 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|update_task_state]: Task: Descriptors4, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:14 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|update_task_state]: Task: Descriptors5, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:14 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|update_task_state]: Task: Descriptors6, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:14 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|update_task_state]: Task: Descriptors7, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:14 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|update_task_state]: Task: Descriptors8, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:14 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|update_task_state]: Task: Descriptors9, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:14 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|update_task_state]: Task: Descriptors10, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:14 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|update_task_state]: Task: Descriptors11, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:15 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|continue_workgraph]: tasks ready to run: create_scales\n",
      "11/17/2025 04:15:15 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|update_task_state]: Task: create_scales, type: CALCFUNCTION, finished.\n",
      "11/17/2025 04:15:15 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|continue_workgraph]: tasks ready to run: qe\n",
      "11/17/2025 04:15:16 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 10284\n",
      "11/17/2025 04:15:17 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|continue_workgraph]: tasks ready to run: PwCalculation,PwCalculation1,PwCalculation2,PwCalculation3,PwCalculation4,PwCalculation5,PwCalculation6,PwCalculation7,PwCalculation8,PwCalculation9,PwCalculation10,PwCalculation11\n",
      "11/17/2025 04:15:21 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 10286, 10288, 10290, 10292, 10294, 10296, 10298, 10300, 10302, 10304, 10306, 10308\n",
      "11/17/2025 04:15:37 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|update_task_state]: Task: PwCalculation, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:37 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "11/17/2025 04:15:37 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 10288, 10290, 10292, 10294, 10296, 10298, 10300, 10302, 10304, 10306, 10308\n",
      "11/17/2025 04:15:40 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|update_task_state]: Task: PwCalculation1, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:40 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|update_task_state]: Task: PwCalculation2, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:40 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|update_task_state]: Task: PwCalculation3, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:41 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|update_task_state]: Task: PwCalculation4, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:41 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|update_task_state]: Task: PwCalculation5, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:41 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|update_task_state]: Task: PwCalculation7, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:41 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "11/17/2025 04:15:41 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 10298, 10302, 10304, 10306, 10308\n",
      "11/17/2025 04:15:44 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|update_task_state]: Task: PwCalculation6, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:44 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|update_task_state]: Task: PwCalculation8, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:44 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|update_task_state]: Task: PwCalculation9, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:44 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|update_task_state]: Task: PwCalculation10, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:44 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|update_task_state]: Task: PwCalculation11, type: CALCJOB, finished.\n",
      "11/17/2025 04:15:44 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "11/17/2025 04:15:44 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10284|WorkGraphEngine|finalize]: Finalize workgraph.\n",
      "11/17/2025 04:15:45 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|update_task_state]: Task: qe, type: GRAPH, finished.\n",
      "11/17/2025 04:15:45 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|continue_workgraph]: tasks ready to run: create_train_files\n",
      "11/17/2025 04:15:46 PM <165050> aiida.orm.nodes.process.calculation.calcfunction.CalcFunctionNode: [REPORT] [10369|create_train_files|on_except]: Traceback (most recent call last):\n",
      "  File \"/home/strix/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/process_states.py\", line 250, in execute\n",
      "    result = await self.run_fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/strix/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/processes/functions.py\", line 603, in run\n",
      "    result = self._func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_165050/2840419190.py\", line 139, in create_train_files\n",
      "    process_and_split_data(**process_inputs)\n",
      "  File \"/home/strix/aiida-mlip/examples/tutorials/workgraphs/sample_split.py\", line 134, in process_and_split_data\n",
      "    [atoms[x].info[f\"mace_mp_{s}_descriptor\"] * scale for s in specs]\n",
      "     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'mace_mp_Cl_descriptor'\n",
      "\n",
      "11/17/2025 04:15:46 PM <165050> plumpy.processes: [ERROR] Error in task create_train_files: 'mace_mp_Cl_descriptor'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/strix/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_workgraph/engine/task_manager.py\", line 202, in execute_function_task\n",
      "    process, _ = task.execute(args, kwargs, var_kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/strix/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_workgraph/tasks/aiida.py\", line 35, in execute\n",
      "    _, process = run_get_node(executor, **kwargs, **var_kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/strix/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/launch.py\", line 65, in run_get_node\n",
      "    return runner.run_get_node(process, inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/strix/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/runners.py\", line 291, in run_get_node\n",
      "    result, node = self._run(process, inputs, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/strix/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/runners.py\", line 241, in _run\n",
      "    result, node = process.run_get_node(**inputs)  # type: ignore[union-attr]\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/strix/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/processes/functions.py\", line 246, in run_get_node\n",
      "    result = process.execute()\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/strix/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/processes/functions.py\", line 555, in execute\n",
      "    result = super().execute()\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/strix/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/processes.py\", line 101, in func_wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/strix/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/processes.py\", line 1313, in execute\n",
      "    return self.future().result()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/strix/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/process_states.py\", line 250, in execute\n",
      "    result = await self.run_fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/strix/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/processes/functions.py\", line 603, in run\n",
      "    result = self._func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_165050/2840419190.py\", line 139, in create_train_files\n",
      "    process_and_split_data(**process_inputs)\n",
      "  File \"/home/strix/aiida-mlip/examples/tutorials/workgraphs/sample_split.py\", line 134, in process_and_split_data\n",
      "    [atoms[x].info[f\"mace_mp_{s}_descriptor\"] * scale for s in specs]\n",
      "     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'mace_mp_Cl_descriptor'\n",
      "\n",
      "11/17/2025 04:15:46 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|on_task_failed]: Task, create_train_files, type: CALCFUNCTION, failed.\n",
      "11/17/2025 04:15:46 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|run_error_handlers]: Run error handlers for create_train_files\n",
      "11/17/2025 04:15:46 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "11/17/2025 04:15:46 PM <165050> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [10133|WorkGraphEngine|is_workgraph_finished]: WorkGraph finished, but tasks: ['create_train_files'] failed. Thus all their child tasks are skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'qe_stress': array([[ 1.86398131e-01,  5.97281145e-17, -1.99093715e-17],\n",
      "       [ 5.97281145e-17,  1.86398131e-01, -5.97281145e-17],\n",
      "       [-5.97281145e-17, -1.99093715e-17,  1.86398131e-01]]), 'units': {'energy': 'eV', 'forces': 'ev/Ang', 'stress': 'ev/Ang^3'}, 'qe_energy': -1748.7982484694}\n",
      "create files: train_file=PosixPath('train.xyz'), valid_file=PosixPath('valid.xyz') and test_file=PosixPath('test.xyz')\n",
      "Processing: ('all', 'unknown_system'), 12 frames\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d82d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QE task is not appending decriptor so it causes creat_train_to fail"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiida-mlip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
