{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c13c1dd7",
   "metadata": {},
   "source": [
    "# Running multiple calculations on a given model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81fa1b",
   "metadata": {},
   "source": [
    "## Aim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ecbb39",
   "metadata": {},
   "source": [
    "This notebook demonstrates how different types of tasks can be connected within a workflow and run a workflow on an external computer. As an example, we start from a structure, optimize its geometry, compute descriptors, then use a filtering function to split the resulting structures into training fles, run Quantum Espresso to get energies on an external system(scarf) and finally run training on the output files. The goal is to show how workflows can be setup to run on external systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acf0b46",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "The initial setup is very similar to the other tutorials, such as `singlepoint.ipynb`, which goes into more detail about what each step is doing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bfb65e",
   "metadata": {},
   "source": [
    "Load the aiida profile and code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79098139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida import load_profile\n",
    "load_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_mlip.data.model import ModelData\n",
    "uri = \"https://github.com/stfc/janus-core/raw/main/tests/models/mace_mp_small.model\"\n",
    "model = ModelData.from_uri(uri, architecture=\"mace_mp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b9564",
   "metadata": {},
   "source": [
    "We can load the computer and set the directory in which we want to store the data to. The work directory is a placeholder so change accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import load_code, load_computer\n",
    "\n",
    "janus_code = load_code(\"janus@localhost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d661593",
   "metadata": {},
   "source": [
    "We must now choose the calculations to perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.plugins import CalculationFactory\n",
    "geomoptCalc = CalculationFactory(\"mlip.opt\")\n",
    "descriptorsCalc = CalculationFactory(\"mlip.descriptors\")\n",
    "trainCalc = CalculationFactory(\"mlip.train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37df1f81",
   "metadata": {},
   "source": [
    "Before setting up the work graph, we first configure the `Quantum Espresso (QE)` task by defining the code and input parameters. Since we need to run QE on multiple structures, we create multiple `PwCalculation` tasks dynamically within the same task using `get_current_graph()`. This allows us to run QE for each structure and return the corresponding `TrajectoryData` and parameters for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aff44c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_workgraph import task\n",
    "from aiida_workgraph.manager import get_current_graph\n",
    "from aiida.orm import StructureData, load_group, KpointsData, SinglefileData\n",
    "from ase.io import iread\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from aiida_quantumespresso.calculations.pw import PwCalculation\n",
    "from sample_split import process_and_split_data\n",
    "\n",
    "\n",
    "@task.graph(outputs = [\"test_file\", \"train_file\", \"valid_file\"])\n",
    "def qe(**inputs):\n",
    "\n",
    "    qe_code = load_code(\"qe@scarf\")\n",
    "    wg = get_current_graph()\n",
    "\n",
    "    kpoints = KpointsData()\n",
    "    kpoints.set_kpoints_mesh(inputs['kpoint_mesh'].value)\n",
    "\n",
    "    pseudo_family = load_group('SSSP/1.3/PBE/efficiency')\n",
    "    files = {\"test_file\": inputs['test_file'],\"train_file\":inputs['train_file'],\"valid_file\":inputs['valid_file']}\n",
    "\n",
    "    for file_name, file in files.items():\n",
    "        with file.as_path() as path:\n",
    "            for i, structs in enumerate(iread(path, format=\"extxyz\")):\n",
    "                \n",
    "                structure = StructureData(ase=structs)\n",
    "                pseudos = pseudo_family.get_pseudos(structure=structure)\n",
    "\n",
    "                ecutwfc, ecutrho = pseudo_family.get_recommended_cutoffs(\n",
    "                    structure=structure,\n",
    "                    unit='Ry',\n",
    "                )\n",
    "\n",
    "                pw_params = {\n",
    "                    \"CONTROL\": {\n",
    "                        \"calculation\": \"scf\",\n",
    "                        'tprnfor': True,\n",
    "                        'tstress': True,\n",
    "                    },\n",
    "                    \"SYSTEM\": {\n",
    "                        \"ecutwfc\": ecutwfc,\n",
    "                        \"ecutrho\": ecutrho,\n",
    "                    },\n",
    "                }\n",
    "\n",
    "                qe_task = wg.add_task(\n",
    "                    PwCalculation,\n",
    "                    code = qe_code,\n",
    "                    parameters= pw_params,\n",
    "                    kpoints= kpoints,\n",
    "                    pseudos= pseudos,\n",
    "                    metadata= inputs[\"calc_metadata\"].value,\n",
    "                    structure= structure,\n",
    "                )\n",
    "\n",
    "                structfile = f\"{file_name}.struct{i}\"\n",
    "                wg.update_ctx({structfile:{\n",
    "                    \"trajectory\":qe_task.outputs.output_trajectory,\n",
    "                    \"parameters\": qe_task.outputs.output_parameters\n",
    "                }})\n",
    "\n",
    "    return {\n",
    "        \"test_file\": wg.ctx.test_file,\n",
    "        \"train_file\": wg.ctx.train_file,\n",
    "        \"valid_file\": wg.ctx.valid_file\n",
    "    }    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_mlip.data.config import JanusConfigfile\n",
    "from aiida.orm import Dict, TrajectoryData\n",
    "from ase.io import write\n",
    "from ase import units\n",
    "\n",
    "@task.calcfunction(outputs = [\"JanusConfigfile\"])\n",
    "def create_train_file(**inputs):\n",
    "\n",
    "    training_files = {}\n",
    "    \n",
    "    for file_name, structs in inputs.items():\n",
    "        path = Path(f\"mlip_{file_name}.extxyz\")\n",
    "\n",
    "        for stuct_out_params in structs.values():\n",
    "            \n",
    "            trajectory = stuct_out_params[\"trajectory\"]\n",
    "\n",
    "            fileStructure = trajectory.get_structure(index=0)\n",
    "            fileAtoms = fileStructure.get_ase()\n",
    "\n",
    "            stress = trajectory.arrays[\"stress\"][0]\n",
    "            converted_stress = stress * units.GPa\n",
    "            fileAtoms.info[\"qe_stress\"] = converted_stress\n",
    "\n",
    "            fileAtoms.info[\"units\"] = {\"energy\": \"eV\",\"forces\": \"ev/Ang\",\"stress\": \"ev/Ang^3\"}\n",
    "            fileAtoms.set_array(\"qe_forces\", trajectory.arrays[\"forces\"][0])\n",
    "\n",
    "            parameters = stuct_out_params[\"parameters\"]\n",
    "            fileParams = parameters.get_dict()\n",
    "            fileAtoms.info[\"qe_energy\"] = fileParams[\"energy\"]\n",
    "            write(path, fileAtoms, append=True)\n",
    "\n",
    "        training_files[file_name] = str(path.resolve())\n",
    "\n",
    "    with open(\"JanusConfigfile.yml\", \"a\") as f:\n",
    "        yaml.safe_dump(training_files, f, sort_keys=False)\n",
    "\n",
    "    return{'JanusConfigfile': JanusConfigfile(str(Path(\"JanusConfigfile.yml\").resolve()))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8534d73f",
   "metadata": {},
   "source": [
    "For this task, we are using a task to run a pure python function. This is to demonstrate the flexibility of tasks and how you can run pure python functions on the workchain. This returns `SinglefileData` instances of the test, train and valid files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c5e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task.calcfunction(outputs = [\"test_file\", \"train_file\", \"valid_file\"])\n",
    "def create_aiida_files(**inputs):\n",
    "     \n",
    "    files = process_and_split_data(**inputs)\n",
    "\n",
    "    return {\n",
    "        \"train_file\": SinglefileData(files[\"train_file\"]),\n",
    "        \"test_file\": SinglefileData(files[\"test_file\"]),\n",
    "        \"valid_file\": SinglefileData(files[\"valid_file\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aebeed5",
   "metadata": {},
   "source": [
    "We initialize the inputs we want for all the calculations. These variables can be changed depending on the configuration you are running and whether you want to change any inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5760b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import Str, Float, Bool, Int, List\n",
    "\n",
    "calc_inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cpu\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "}\n",
    "\n",
    "goemopt_inputs = {\n",
    "    \"fmax\": Float(0.1),\n",
    "    \"opt_cell_lengths\": Bool(False),\n",
    "    \"opt_cell_fully\": Bool(True),\n",
    "}\n",
    "\n",
    "split_task_inputs = {\n",
    "    \"config_types\": Str(\"\"),\n",
    "    \"prefix\": Str(\"\"),\n",
    "    \"scale\": Float(1.0e5),\n",
    "    \"append_mode\": Bool(False),\n",
    "}\n",
    "\n",
    "qe_inputs = {\n",
    "    \"calc_metadata\":  Dict({\n",
    "        \"options\": {\n",
    "            \"resources\": {\n",
    "                \"num_machines\": 1,\n",
    "                'num_mpiprocs_per_machine': 32,\n",
    "            },\n",
    "            'max_wallclock_seconds': 3600,\n",
    "            'queue_name': 'scarf',                  \n",
    "            'qos': 'scarf',\n",
    "            'environment_variables': {},\n",
    "            'withmpi': True,                       \n",
    "            'prepend_text': '''\n",
    "            module purge\n",
    "            module use /work4/scd/scarf562/eb-common/modules/all\n",
    "            module load amd-modules\n",
    "            module load QuantumESPRESSO/7.2-foss-2023a\n",
    "            ''',\n",
    "            'append_text': ''  \n",
    "        }\n",
    "    }),\n",
    "    \"kpoint_mesh\": List([1,1,1])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0299e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_workgraph import WorkGraph\n",
    "from aiida.orm import StructureData\n",
    "from ase.io import iread\n",
    "\n",
    "initial_structure = \"../structures/NaCl-traj.xyz\"\n",
    "\n",
    "with WorkGraph(\"QE Calculation Workgraph\") as wg:\n",
    "\n",
    "    final_structures = {}\n",
    "\n",
    "    for i, struct in enumerate(iread(initial_structure)):\n",
    "\n",
    "        structure = StructureData(ase=struct)\n",
    "        geomopt_calc = wg.add_task(\n",
    "            geomoptCalc,\n",
    "            **calc_inputs,\n",
    "            **goemopt_inputs,\n",
    "            struct=structure,\n",
    "        )\n",
    "        \n",
    "        descriptors_calc = wg.add_task(\n",
    "            descriptorsCalc,\n",
    "            **calc_inputs,\n",
    "            struct=geomopt_calc.outputs.final_structure,\n",
    "            calc_per_element=True,\n",
    "        )\n",
    "\n",
    "        final_structures[f\"structs{i}\"] = descriptors_calc.outputs.xyz_output\n",
    "\n",
    "    split_task = wg.add_task(\n",
    "        create_aiida_files, \n",
    "        **split_task_inputs,\n",
    "        trajectory_data=final_structures,\n",
    "        n_samples= Int(len(final_structures)),\n",
    "        )\n",
    "\n",
    "    qe_task = wg.add_task(\n",
    "        qe, \n",
    "        name=\"QE_workflow\",\n",
    "        test_file= split_task.outputs.test_file,\n",
    "        train_file= split_task.outputs.train_file,\n",
    "        valid_file= split_task.outputs.valid_file,\n",
    "        **qe_inputs\n",
    "        )\n",
    "\n",
    "    training_files = wg.add_task(\n",
    "        create_train_file, \n",
    "        test_file= qe_task.outputs.test_file,\n",
    "        train_file= qe_task.outputs.train_file,\n",
    "        valid_file= qe_task.outputs.valid_file,\n",
    "        )\n",
    "\n",
    "    train_task = wg.add_task(\n",
    "        trainCalc,\n",
    "        mlip_config=training_files.outputs.JanusConfigfile,\n",
    "        code=calc_inputs[\"code\"],\n",
    "        foundation_model=calc_inputs[\"model\"],\n",
    "        metadata=calc_inputs[\"metadata\"],\n",
    "        fine_tune=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3c72ca",
   "metadata": {},
   "source": [
    "Visualise the workgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d119cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5fd6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9d256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg.tasks.Train.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36396f",
   "metadata": {},
   "source": [
    "If we want to get the training plot, we have to pull it from the remote folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9cd027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "folder = wg.tasks.Train.outputs.remote_folder.value\n",
    "picturePath = f\"{os.getcwd()}/traingraph.png\"\n",
    "folder.getfile(relpath='results/test_run-123_train_Default_stage_one.png',destpath=picturePath)\n",
    "\n",
    "img = mpimg.imread(picturePath)\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiida-mlip (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
