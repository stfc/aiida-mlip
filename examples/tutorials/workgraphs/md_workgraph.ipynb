{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ecbb39",
   "metadata": {},
   "source": [
    "# WorkGraph Example: MD Simulation with DFT Labeling and Model Fine-tuning\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial demonstrates an end-to-end workflow for generating training data and fine-tuning a machine learning interatomic potential (MLIP). The workflow consists of:\n",
    "\n",
    "1. **Molecular Dynamics (MD)**: Generate diverse structural configurations of NaCl\n",
    "2. **Descriptor Calculation**: Compute MLIP descriptors for structure filtering\n",
    "3. **Data Splitting**: Filter and split structures into train/validation/test sets\n",
    "4. **DFT Labeling**: Calculate accurate energies, forces, and stresses using Quantum ESPRESSO\n",
    "5. **Model Fine-tuning**: Train a MACE model on the DFT-labeled data\n",
    "\n",
    "\n",
    "## Workflow Architecture\n",
    "\n",
    "```\n",
    "Initial Structure (NaCl)\n",
    "        ↓\n",
    "    [MD Simulation] → Trajectory (6 snapshots)\n",
    "        ↓\n",
    "    [Descriptors] → Structure features\n",
    "        ↓\n",
    "    [Filter & Split] → Train/Valid/Test sets\n",
    "        ↓\n",
    "    [Quantum ESPRESSO] → DFT energies/forces/stresses\n",
    "        ↓\n",
    "    [Create Training Files] → ExtXYZ with DFT labels\n",
    "        ↓\n",
    "    [Fine-tune MACE] → Improved MLIP model\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bfb65e",
   "metadata": {},
   "source": [
    "### Load AiiDA Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79098139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profile<uuid='60b17659a9844c4bbd3bef8de0a8f417' name='presto'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aiida import load_profile\n",
    "load_profile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef36ae",
   "metadata": {},
   "source": [
    "### Verify SSSP Pseudopotentials\n",
    "\n",
    "Quantum ESPRESSO requires pseudopotentials for DFT calculations. We check that the SSSP library is installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716ecb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SSSP pseudopotentials installed (103 pseudos)\n"
     ]
    }
   ],
   "source": [
    "from aiida.orm import load_group\n",
    "try:\n",
    "    pseudo_family = load_group('SSSP/1.3/PBE/efficiency')\n",
    "    print(f\" SSSP pseudopotentials installed ({len(pseudo_family.nodes)} pseudos)\")\n",
    "except Exception:\n",
    "    print(\" SSSP not installed, Run: aiida-pseudo install sssp -v 1.3 -p efficiency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d393384",
   "metadata": {},
   "source": [
    "### Load ML Potential Model\n",
    "We download a pre-trained MACE model from the janus-core repository. This foundation model will be:\n",
    "- Used for the initial MD simulation\n",
    "- Used to calculate descriptors for filtering\n",
    "- Fine-tuned on our DFT-labeled data\n",
    "\n",
    "The `ModelData.from_uri()` function automatically caches the model locally to avoid repeated downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc2cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_mlip.data.model import ModelData\n",
    "uri = \"https://github.com/stfc/janus-core/raw/main/tests/models/mace_mp_small.model\"\n",
    "model = ModelData.from_uri(uri, architecture=\"mace_mp\", cache_dir=\"mlips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c68186",
   "metadata": {},
   "source": [
    "### Define Initial Structure\n",
    "\n",
    "We create a rocksalt NaCl structure with a lattice parameter of 5.63 Å. This serves as the starting point for our MD simulation.\n",
    "\n",
    "**Why NaCl?** It's a simple ionic crystal that demonstrates:\n",
    "- Multi-element systems\n",
    "- Different atomic environments\n",
    "- Structural variations during MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89ba5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import StructureData\n",
    "from ase.build import bulk\n",
    "from ase.io import read, iread\n",
    "\n",
    "# structure = StructureData(ase=read(\"Structures/qmof-ffeef76.cif\"))\n",
    "init_structure = StructureData(ase=bulk(\"NaCl\", \"rocksalt\", 5.63))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12932e35",
   "metadata": {},
   "source": [
    "### Load Computational Codes\n",
    "\n",
    "We need two codes:\n",
    "- **janus@localhost**: For MLIP calculations (MD, descriptors, training) - runs locally\n",
    "- **qe@scarf**: For DFT calculations with Quantum ESPRESSO - runs on HPC cluster\n",
    "\n",
    "See examples>tutorials>aiida_setup for setting up janus code and external computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae62816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import load_code\n",
    "janus_code = load_code(\"janus@localhost\")\n",
    "qe_code = load_code(\"qe@scarf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f240333a",
   "metadata": {},
   "source": [
    "### Define Calculation Types\n",
    "\n",
    "We define three calculation types from the `aiida-mlip` plugin:\n",
    "- `mdCalc`: Molecular dynamics simulation\n",
    "- `descriptorsCalc`: Compute structural descriptors\n",
    "- `trainCalc`: Fine-tune the MLIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4c78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.plugins import CalculationFactory\n",
    "\n",
    "mdCalc = CalculationFactory(\"mlip.md\")\n",
    "descriptorsCalc = CalculationFactory(\"mlip.descriptors\")\n",
    "trainCalc = CalculationFactory(\"mlip.train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36acd26d",
   "metadata": {},
   "source": [
    "## Task 1: Descriptors Calculation\n",
    "\n",
    "### Purpose\n",
    "After MD generates trajectory snapshots, we calculate descriptors for each structure. These descriptors:\n",
    "- Characterize the local atomic environment\n",
    "- Enable intelligent filtering of structures\n",
    "- Are calculated per-element (separate Na and Cl descriptors)\n",
    "\n",
    "### Implementation Details\n",
    "This task uses a **dynamic graph** pattern:\n",
    "- Loops over each structure in the trajectory\n",
    "- Creates a separate `Descriptors` calculation task for each\n",
    "- Stores results in the workflow context\n",
    "- Returns all structures as `final_structs` dictionary\n",
    "\n",
    "The `get_current_graph()` function allows us to dynamically add tasks within this task, enabling parallel execution of descriptor calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0b91b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defining outputnode\n"
     ]
    }
   ],
   "source": [
    "from aiida_workgraph import WorkGraph, task, dynamic, namespace\n",
    "from aiida.orm import SinglefileData\n",
    "\n",
    "descriptorsTask = task(CalculationFactory(\"mlip.descriptors\"))\n",
    "\n",
    "@task.graph(outputs=namespace(final_structs=dynamic(SinglefileData)))\n",
    "def descriptors_task(\n",
    "    code,\n",
    "    model,\n",
    "    device,\n",
    "    arch,\n",
    "    file,\n",
    "):\n",
    "    results = {}\n",
    "    \n",
    "    with file.as_path() as path:\n",
    "        for i, structs in enumerate(iread(path)):\n",
    "            structure = StructureData(ase=structs)\n",
    "\n",
    "            desc_calc = descriptorsTask(\n",
    "                code=code,\n",
    "                model=model,\n",
    "                device=device,\n",
    "                arch=arch,\n",
    "                struct=structure,\n",
    "                calc_per_element=True,\n",
    "                metadata={\"options\": {\"resources\": {\"num_machines\": 1}}}\n",
    "            )\n",
    "\n",
    "            results[f\"struct{i}\"] = desc_calc.xyz_output\n",
    "\n",
    "    return {\"final_structs\": results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ecc71",
   "metadata": {},
   "source": [
    "## Task 2: Quantum ESPRESSO DFT Calculations\n",
    "\n",
    "### Purpose\n",
    "Run high-accuracy DFT calculations to obtain reference data:\n",
    "- **Total energy**: Ground state energy of each structure\n",
    "- **Forces**: Atomic forces for training\n",
    "- **Stress tensor**: Needed for NPT dynamics and equation of state\n",
    "\n",
    "### Implementation Details\n",
    "\n",
    "This task processes three files (train, test, validation) and runs DFT calculations on each structure:\n",
    "\n",
    "**Pseudopotentials**: Automatically retrieves appropriate pseudopotentials for Na and Cl from SSSP library\n",
    "\n",
    "**Cutoff energies**: Uses recommended values from SSSP for convergence:\n",
    "- `ecutwfc`: Plane-wave kinetic energy cutoff\n",
    "- `ecutrho`: Charge density cutoff\n",
    "\n",
    "**K-points**: Uses Γ-point only (1×1×1 mesh) - sufficient for the supercell size\n",
    "\n",
    "**DFT Parameters**:\n",
    "- SCF calculation (self-consistent field)\n",
    "- `tprnfor=True`: Calculate forces\n",
    "- `tstress=True`: Calculate stress tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62de8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_workgraph import task\n",
    "from aiida_workgraph.manager import get_current_graph\n",
    "from aiida.orm import StructureData, load_group, KpointsData, SinglefileData, InstalledCode, List, Dict\n",
    "from ase.io import iread\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from aiida_quantumespresso.calculations.pw import PwCalculation\n",
    "from sample_split import process_and_split_data\n",
    "\n",
    "\n",
    "@task.graph(outputs = [\"test_file\", \"train_file\", \"valid_file\"])\n",
    "def qe(\n",
    "    code: InstalledCode,\n",
    "    kpoints_mesh: List,\n",
    "    task_metadata: Dict,\n",
    "    test_file: SinglefileData,\n",
    "    train_file: SinglefileData,\n",
    "    valid_file: SinglefileData\n",
    "    ):\n",
    "\n",
    "    wg = get_current_graph()\n",
    "\n",
    "    kpoints = KpointsData()\n",
    "    kpoints.set_kpoints_mesh(kpoints_mesh)\n",
    "\n",
    "    pseudo_family = load_group('SSSP/1.3/PBE/efficiency')\n",
    "    \n",
    "    files = {\"test_file\": test_file, \"train_file\": train_file, \"valid_file\": valid_file}\n",
    "\n",
    "    for file_name, file in files.items():\n",
    "        with file.as_path() as path:\n",
    "            for i, structs in enumerate(iread(path, format=\"extxyz\")):\n",
    "                \n",
    "                structure = StructureData(ase=structs)\n",
    "                pseudos = pseudo_family.get_pseudos(structure=structure)\n",
    "\n",
    "                ecutwfc, ecutrho = pseudo_family.get_recommended_cutoffs(\n",
    "                    structure=structure,\n",
    "                    unit='Ry',\n",
    "                )\n",
    "\n",
    "                pw_params = {\n",
    "                    \"CONTROL\": {\n",
    "                        \"calculation\": \"scf\",\n",
    "                        'tprnfor': True,\n",
    "                        'tstress': True,\n",
    "                    },\n",
    "                    \"SYSTEM\": {\n",
    "                        \"ecutwfc\": ecutwfc,\n",
    "                        \"ecutrho\": ecutrho,\n",
    "                    },\n",
    "                }\n",
    "                \n",
    "                qe_task = wg.add_task(\n",
    "                    PwCalculation,\n",
    "                    code=code,\n",
    "                    parameters=pw_params,\n",
    "                    kpoints=kpoints,\n",
    "                    pseudos=pseudos,\n",
    "                    metadata=task_metadata.value,\n",
    "                    structure=structure,\n",
    "                )\n",
    "                \n",
    "                structfile = f\"{file_name}.struct{i}\"\n",
    "\n",
    "                wg.update_ctx({\n",
    "                    structfile:{\n",
    "                        \"trajectory\":qe_task.outputs.output_trajectory,\n",
    "                        \"parameters\": qe_task.outputs.output_parameters\n",
    "                    }\n",
    "                })\n",
    "\n",
    "    return {\n",
    "        \"test_file\": wg.ctx.test_file,\n",
    "        \"train_file\": wg.ctx.train_file,\n",
    "        \"valid_file\": wg.ctx.valid_file\n",
    "    }    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcacee8",
   "metadata": {},
   "source": [
    "## Task 3: Create Training Files\n",
    "\n",
    "Extract DFT results from Quantum ESPRESSO and format them for MLIP training.\n",
    "\n",
    "1. **Extract data** from QE output:\n",
    "   - Energy from `output_parameters`\n",
    "   - Forces from `output_trajectory`\n",
    "   - Stress tensor from `output_trajectory`\n",
    "\n",
    "2. **Unit conversion**:\n",
    "   - Stress: Convert from Quantum ESPRESSO units to eV/Å³\n",
    "   - Energy: Already in eV\n",
    "   - Forces: Already in eV/Å\n",
    "\n",
    "3. **Create ExtXYZ files**:\n",
    "   - `mlip_train_file.extxyz`: Structures for training\n",
    "   - `mlip_valid_file.extxyz`: Structures for validation\n",
    "   - `mlip_test_file.extxyz`: Structures for testing\n",
    "\n",
    "4. **Update config file**:\n",
    "   - Adds file paths to `JanusConfigfile.yml`\n",
    "   - This config file contains all training parameters\n",
    "\n",
    "\n",
    "The extended XYZ format includes:\n",
    "- Atomic positions\n",
    "- Lattice vectors\n",
    "- DFT energies in `info` dict\n",
    "- Forces as atomic arrays\n",
    "- Stress tensor in `info` dict\n",
    "- Unit specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a430a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_mlip.data.config import JanusConfigfile\n",
    "from aiida.orm import Dict\n",
    "from ase.io import write\n",
    "from ase import units\n",
    "\n",
    "@task.calcfunction(outputs = [\"JanusConfigfile\"])\n",
    "def create_train_file(**inputs):\n",
    "\n",
    "    training_files = {}\n",
    "    \n",
    "    for file_name, structs in inputs.items():\n",
    "        path = Path(f\"mlip_{file_name}.extxyz\")\n",
    "\n",
    "        for struct_out_params in structs.values():\n",
    "            \n",
    "            trajectory = struct_out_params[\"trajectory\"]\n",
    "\n",
    "            fileStructure = trajectory.get_structure(index=0)\n",
    "            fileAtoms = fileStructure.get_ase()\n",
    "\n",
    "            stress = trajectory.arrays[\"stress\"][0]\n",
    "            converted_stress = stress * units.GPa\n",
    "            fileAtoms.info[\"qe_stress\"] = converted_stress\n",
    "\n",
    "            fileAtoms.info[\"units\"] = {\"energy\": \"eV\",\"forces\": \"ev/Ang\",\"stress\": \"ev/Ang^3\"}\n",
    "            fileAtoms.set_array(\"qe_forces\", trajectory.arrays[\"forces\"][0])\n",
    "\n",
    "            parameters = struct_out_params[\"parameters\"]\n",
    "            fileParams = parameters.get_dict()\n",
    "            fileAtoms.info[\"qe_energy\"] = fileParams[\"energy\"]\n",
    "            write(path, fileAtoms, append=True)\n",
    "\n",
    "        training_files[file_name] = str(path.resolve())\n",
    "\n",
    "    with open(\"JanusConfigfile.yml\", \"a\") as f:\n",
    "        yaml.safe_dump(training_files, f, sort_keys=False)\n",
    "\n",
    "    return{'JanusConfigfile': JanusConfigfile(Path(\"JanusConfigfile.yml\").resolve())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5766874",
   "metadata": {},
   "source": [
    "## Task 4: Data Filtering and Splitting\n",
    "\n",
    "Split the MD trajectory into train/validation/test sets using FPS (Farthest Point Sampling).\n",
    "\n",
    "Note: The warnings about `k is too large` appear when you have fewer structures than the target split size - the algorithm automatically adjusts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ac1993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import Int\n",
    "@task.calcfunction(outputs = [\"test_file\", \"train_file\", \"valid_file\"])\n",
    "def create_qe_files(**inputs):\n",
    "\n",
    "    n_samples = Int(len(inputs['trajectory_data']))\n",
    "    print(n_samples)\n",
    "\n",
    "    files = process_and_split_data( \n",
    "        **inputs,\n",
    "        n_samples=n_samples,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"train_file\": SinglefileData(files[\"train_file\"]),\n",
    "        \"test_file\": SinglefileData(files[\"test_file\"]),\n",
    "        \"valid_file\": SinglefileData(files[\"valid_file\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff193a2",
   "metadata": {},
   "source": [
    "## Configure Input Parameters\n",
    "\n",
    "\n",
    "**NVT Ensemble**: \n",
    "- Maintains constant Number of particles, Volume, and Temperature\n",
    "- Suitable for sampling structural variations\n",
    "- Uses a thermostat to control temperature\n",
    "\n",
    "See https://stfc.github.io/janus-core/tutorials/cli/md.html for other ensemvles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1795dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import Str, Float, Bool, Int, Dict\n",
    "inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cpu\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "    \"ensemble\": Str(\"NVT\"),\n",
    "    \"struct\": init_structure,\n",
    "    \"md_kwargs\": Dict(\n",
    "        {\n",
    "            \"steps\": 10,\n",
    "            \"traj-every\": 2\n",
    "        }\n",
    "    )\n",
    "}\n",
    "calc_inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cpu\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "}\n",
    "split_task_inputs = {\n",
    "    \"config_types\": Str(\"\"),\n",
    "    \"prefix\": Str(\"\"),\n",
    "    \"scale\": Float(1.0e5),\n",
    "    \"append_mode\": Bool(False),\n",
    "}\n",
    "qe_inputs = {\n",
    "    \"task_metadata\": Dict({\n",
    "            \"options\": {\n",
    "                \"resources\": {\n",
    "                    \"num_machines\": 1,\n",
    "                    \"num_mpiprocs_per_machine\": 32,\n",
    "                },\n",
    "                \"max_wallclock_seconds\": 3600,\n",
    "                \"queue_name\": \"scarf\",\n",
    "                \"qos\": \"scarf\",\n",
    "                \"environment_variables\": {},\n",
    "                \"withmpi\": True,\n",
    "                \"prepend_text\": \"\"\"\n",
    "                    module purge\n",
    "                    module use /work4/scd/scarf562/eb-common/modules/all\n",
    "                    module load amd-modules\n",
    "                    module load QuantumESPRESSO/7.2-foss-2023a\n",
    "                \"\"\",\n",
    "                \"append_text\": \"\",\n",
    "            },\n",
    "    }),\n",
    "    \"kpoints_mesh\": List([1, 1, 1]),\n",
    "    \"code\": qe_code,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0241edf",
   "metadata": {},
   "source": [
    "\n",
    "## Build and Run the WorkGraph\n",
    "\n",
    "### WorkGraph Structure\n",
    "\n",
    "The workflow is defined using AiiDA WorkGraph, which:\n",
    "- Automatically manages task dependencies\n",
    "- Enables parallel execution where possible\n",
    "- Tracks provenance of all calculations\n",
    "- Handles job submission to HPC\n",
    "\n",
    "Each task waits for its inputs before executing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82a4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdTask = task(mdCalc)\n",
    "trainTask = task(trainCalc)\n",
    "\n",
    "@task.graph()\n",
    "def md_training_workflow(\n",
    "    janus_code,\n",
    "    qe_code,\n",
    "    model,\n",
    "    md_kwargs,\n",
    "    ensemble,\n",
    "    init_structure,\n",
    "    split_inputs,\n",
    "    qe_metadata,\n",
    "    qe_kpoints,\n",
    "):\n",
    "    md_calc = mdTask(\n",
    "        code=janus_code,\n",
    "        model=model,\n",
    "        arch=Str(model.architecture),\n",
    "        device=Str(\"cpu\"),\n",
    "        metadata={\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "        ensemble=ensemble,\n",
    "        struct=init_structure,\n",
    "        md_kwargs=md_kwargs\n",
    "    )\n",
    "\n",
    "    descriptors_calc = descriptors_task(\n",
    "        code=janus_code,\n",
    "        model=model,\n",
    "        device=Str(\"cpu\"),\n",
    "        arch=Str(model.architecture),\n",
    "        file=md_calc.traj_file\n",
    "    )\n",
    "   \n",
    "    split_task = create_qe_files(\n",
    "        **split_inputs,\n",
    "        trajectory_data=descriptors_calc.final_structs,\n",
    "    )\n",
    "    \n",
    "    qe_task = qe(\n",
    "        code=qe_code,\n",
    "        kpoints_mesh=qe_kpoints,\n",
    "        task_metadata=qe_metadata,\n",
    "        test_file=split_task.test_file,\n",
    "        train_file=split_task.train_file,\n",
    "        valid_file=split_task.valid_file,\n",
    "    )\n",
    "\n",
    "    training_files = create_train_file(\n",
    "        test_file=qe_task.test_file,\n",
    "        train_file=qe_task.train_file,\n",
    "        valid_file=qe_task.valid_file,\n",
    "    )\n",
    "\n",
    "    train_task = trainTask(\n",
    "        mlip_config=training_files.JanusConfigfile,\n",
    "        code=janus_code,\n",
    "        foundation_model=model,\n",
    "        metadata={\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "        fine_tune=True,\n",
    "    )\n",
    "\n",
    "wg = md_training_workflow.build(\n",
    "    janus_code=janus_code,\n",
    "    qe_code=qe_code,\n",
    "    model=model,\n",
    "    md_kwargs=inputs[\"md_kwargs\"],\n",
    "    ensemble=inputs[\"ensemble\"],\n",
    "    init_structure=init_structure,\n",
    "    split_inputs=split_task_inputs,\n",
    "    qe_metadata=qe_inputs[\"task_metadata\"],\n",
    "    qe_kpoints=qe_inputs[\"kpoints_mesh\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd843a",
   "metadata": {},
   "source": [
    "### Execution\n",
    "\n",
    "`wg.run()` submits the entire workflow and monitors its progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4394b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/23/2025 01:07:05 PM <865880> aiida.broker.rabbitmq: [WARNING] RabbitMQ v3.12.1 is not supported and will cause unexpected problems!\n",
      "12/23/2025 01:07:05 PM <865880> aiida.broker.rabbitmq: [WARNING] It can cause long-running workflows to crash and jobs to be submitted multiple times.\n",
      "12/23/2025 01:07:05 PM <865880> aiida.broker.rabbitmq: [WARNING] See https://github.com/aiidateam/aiida-core/wiki/RabbitMQ-version-to-use for details.\n",
      "12/23/2025 01:07:05 PM <865880> aiida.broker.rabbitmq: [WARNING] It can cause long-running workflows to crash and jobs to be submitted multiple times.\n",
      "12/23/2025 01:07:05 PM <865880> aiida.broker.rabbitmq: [WARNING] See https://github.com/aiidateam/aiida-core/wiki/RabbitMQ-version-to-use for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/23/2025 01:07:05 PM <865880> aiida.broker.rabbitmq: [WARNING] RabbitMQ v3.12.1 is not supported and will cause unexpected problems!\n",
      "12/23/2025 01:07:05 PM <865880> aiida.broker.rabbitmq: [WARNING] It can cause long-running workflows to crash and jobs to be submitted multiple times.\n",
      "12/23/2025 01:07:05 PM <865880> aiida.broker.rabbitmq: [WARNING] See https://github.com/aiidateam/aiida-core/wiki/RabbitMQ-version-to-use for details.\n",
      "12/23/2025 01:07:05 PM <865880> aiida.broker.rabbitmq: [WARNING] It can cause long-running workflows to crash and jobs to be submitted multiple times.\n",
      "12/23/2025 01:07:05 PM <865880> aiida.broker.rabbitmq: [WARNING] See https://github.com/aiidateam/aiida-core/wiki/RabbitMQ-version-to-use for details.\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "type `<class 'aiida.orm.nodes.data.code.installed.InstalledCode'>` is not supported as it is not json-serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mwg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_workgraph/workgraph.py:148\u001b[39m, in \u001b[36mWorkGraph.run\u001b[39m\u001b[34m(self, inputs, metadata)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28mself\u001b[39m.check_before_run()\n\u001b[32m    147\u001b[39m inputs = \u001b[38;5;28mself\u001b[39m.to_engine_inputs(metadata=metadata)\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m _, node = \u001b[43maiida\u001b[49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_get_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWorkGraphEngine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28mself\u001b[39m.process = node\n\u001b[32m    150\u001b[39m \u001b[38;5;28mself\u001b[39m.update()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/launch.py:65\u001b[39m, in \u001b[36mrun_get_node\u001b[39m\u001b[34m(process, inputs, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     63\u001b[39m     runner = manager.get_manager().get_runner()\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_get_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/runners.py:291\u001b[39m, in \u001b[36mRunner.run_get_node\u001b[39m\u001b[34m(self, process, inputs, **kwargs)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_get_node\u001b[39m(\n\u001b[32m    281\u001b[39m     \u001b[38;5;28mself\u001b[39m, process: TYPE_RUN_PROCESS, inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs: Any\n\u001b[32m    282\u001b[39m ) -> ResultAndNode:\n\u001b[32m    283\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run the process with the supplied inputs in this runner that will block until the process is completed.\u001b[39;00m\n\u001b[32m    284\u001b[39m \n\u001b[32m    285\u001b[39m \u001b[33;03m    The return value will be the results of the completed process\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    289\u001b[39m \u001b[33;03m    :return: tuple of the outputs of the process and the calculation node\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     result, node = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ResultAndNode(result, node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/runners.py:245\u001b[39m, in \u001b[36mRunner._run\u001b[39m\u001b[34m(self, process, inputs, **kwargs)\u001b[39m\n\u001b[32m    242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result, node\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m utils.loop_scope(\u001b[38;5;28mself\u001b[39m.loop):\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m     process_inited = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minstantiate_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mkill_process\u001b[39m(_num, _frame):\n\u001b[32m    248\u001b[39m \u001b[38;5;250m        \u001b[39m\u001b[33;03m\"\"\"Send the kill signal to the process in the current scope.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/runners.py:174\u001b[39m, in \u001b[36mRunner.instantiate_process\u001b[39m\u001b[34m(self, process, **inputs)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minstantiate_process\u001b[39m(\u001b[38;5;28mself\u001b[39m, process: TYPE_RUN_PROCESS, **inputs):\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m instantiate_process\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_process\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/utils.py:86\u001b[39m, in \u001b[36minstantiate_process\u001b[39m\u001b[34m(runner, process, **inputs)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33minvalid process \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(process)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, needs to be Process or ProcessBuilder\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m process = \u001b[43mprocess_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m process\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/base/state_machine.py:205\u001b[39m, in \u001b[36mStateMachineMeta.__call__\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[33;03mCreate the state machine and enter the initial state.\u001b[39;00m\n\u001b[32m    199\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m \u001b[33;03m:return: An instance of the state machine\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    204\u001b[39m inst: StateMachine = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransition_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_initial_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m call_with_super_check(inst.init)\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inst\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/base/state_machine.py:357\u001b[39m, in \u001b[36mStateMachine.transition_to\u001b[39m\u001b[34m(self, new_state, **kwargs)\u001b[39m\n\u001b[32m    355\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    356\u001b[39m     \u001b[38;5;28mself\u001b[39m._transition_failing = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransition_failed\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28mself\u001b[39m._transition_failing = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/processes.py:1095\u001b[39m, in \u001b[36mProcess.transition_failed\u001b[39m\u001b[34m(self, initial_state, final_state, exception, trace)\u001b[39m\n\u001b[32m   1086\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransition_failed\u001b[39m(\n\u001b[32m   1087\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1088\u001b[39m     initial_state: Hashable,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1092\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1093\u001b[39m     \u001b[38;5;66;03m# If we are creating, then reraise instead of failing.\u001b[39;00m\n\u001b[32m   1094\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m final_state == process_states.ProcessState.CREATED:\n\u001b[32m-> \u001b[39m\u001b[32m1095\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exception.with_traceback(trace)\n\u001b[32m   1097\u001b[39m     new_state = \u001b[38;5;28mself\u001b[39m._create_state_instance(\n\u001b[32m   1098\u001b[39m         process_states.ProcessState.EXCEPTED, exception=exception, trace_back=trace\n\u001b[32m   1099\u001b[39m     )\n\u001b[32m   1100\u001b[39m     \u001b[38;5;28mself\u001b[39m.transition_to(new_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/base/state_machine.py:343\u001b[39m, in \u001b[36mStateMachine.transition_to\u001b[39m\u001b[34m(self, new_state, **kwargs)\u001b[39m\n\u001b[32m    340\u001b[39m     \u001b[38;5;28mself\u001b[39m._exit_current_state(new_state)\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_enter_next_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m StateEntryFailed \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m    345\u001b[39m     new_state = exception.state\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/base/state_machine.py:410\u001b[39m, in \u001b[36mStateMachine._enter_next_state\u001b[39m\u001b[34m(self, next_state)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_enter_next_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, next_state: State) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    409\u001b[39m     last_state = \u001b[38;5;28mself\u001b[39m._state\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fire_state_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStateEventHook\u001b[49m\u001b[43m.\u001b[49m\u001b[43mENTERING_STATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m     \u001b[38;5;66;03m# Enter the new state\u001b[39;00m\n\u001b[32m    412\u001b[39m     next_state.do_enter()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/base/state_machine.py:311\u001b[39m, in \u001b[36mStateMachine._fire_state_event\u001b[39m\u001b[34m(self, hook, state)\u001b[39m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fire_state_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, hook: Hashable, state: Optional[State]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    310\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_callbacks.get(hook, []):\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m         \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/processes.py:358\u001b[39m, in \u001b[36mProcess._setup_event_hooks.<locals>.<lambda>\u001b[39m\u001b[34m(_s, _h, state)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_setup_event_hooks\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    356\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Set the event hooks to process, when it is created or loaded(recreated).\"\"\"\u001b[39;00m\n\u001b[32m    357\u001b[39m     event_hooks = {\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m         state_machine.StateEventHook.ENTERING_STATE: \u001b[38;5;28;01mlambda\u001b[39;00m _s, _h, state: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mon_entering\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_states\u001b[49m\u001b[43m.\u001b[49m\u001b[43mState\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    361\u001b[39m         state_machine.StateEventHook.ENTERED_STATE: \u001b[38;5;28;01mlambda\u001b[39;00m _s, _h, from_state: \u001b[38;5;28mself\u001b[39m.on_entered(\n\u001b[32m    362\u001b[39m             cast(Optional[process_states.State], from_state)\n\u001b[32m    363\u001b[39m         ),\n\u001b[32m    364\u001b[39m         state_machine.StateEventHook.EXITING_STATE: \u001b[38;5;28;01mlambda\u001b[39;00m _s, _h, _state: \u001b[38;5;28mself\u001b[39m.on_exiting(),\n\u001b[32m    365\u001b[39m     }\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook, callback \u001b[38;5;129;01min\u001b[39;00m event_hooks.items():\n\u001b[32m    367\u001b[39m         \u001b[38;5;28mself\u001b[39m.add_state_event_callback(hook, callback)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/processes.py:725\u001b[39m, in \u001b[36mProcess.on_entering\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m    723\u001b[39m state_label = state.LABEL\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m state_label == process_states.ProcessState.CREATED:\n\u001b[32m--> \u001b[39m\u001b[32m725\u001b[39m     \u001b[43mcall_with_super_check\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mon_create\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m state_label == process_states.ProcessState.RUNNING:\n\u001b[32m    727\u001b[39m     call_with_super_check(\u001b[38;5;28mself\u001b[39m.on_run)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/base/utils.py:31\u001b[39m, in \u001b[36mcall_with_super_check\u001b[39m\u001b[34m(wrapped, *args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m call_count = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m_called\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m0\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28mself\u001b[39m._called = call_count + \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBase \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwrapped.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m was not called from \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mHint: Did you forget to call the super?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._called == call_count, msg\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_workgraph/engine/workgraph.py:251\u001b[39m, in \u001b[36mWorkGraphEngine.on_create\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Called when a Process is created.\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maiida_workgraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m save_workgraph_data\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m raw_inputs = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m.inputs)\n\u001b[32m    253\u001b[39m \u001b[38;5;28mself\u001b[39m.node.label = raw_inputs[WorkGraphSpec.WORKGRAPH_DATA_KEY][\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/processes/process.py:459\u001b[39m, in \u001b[36mProcess.on_create\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    457\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(current, Process):\n\u001b[32m    458\u001b[39m         \u001b[38;5;28mself\u001b[39m._parent_pid = current.pid  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m \u001b[38;5;28mself\u001b[39m._pid = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_and_setup_db_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/processes/process.py:660\u001b[39m, in \u001b[36mProcess._create_and_setup_db_record\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metadata.store_provenance:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstore_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.node.is_finished_ok:\n\u001b[32m    662\u001b[39m             \u001b[38;5;28mself\u001b[39m._state = Finished(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/orm/nodes/node.py:551\u001b[39m, in \u001b[36mNode.store_all\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    549\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m link_triple \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.base.links.incoming_cache:\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m link_triple.node.is_stored:\n\u001b[32m--> \u001b[39m\u001b[32m551\u001b[39m         \u001b[43mlink_triple\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.store()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/orm/nodes/node.py:574\u001b[39m, in \u001b[36mNode.store\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    570\u001b[39m \u001b[38;5;28mself\u001b[39m._verify_are_parents_stored()\n\u001b[32m    572\u001b[39m \u001b[38;5;66;03m# Clean the values on the backend node *before* computing the hash in `_get_same_node`. This will allow\u001b[39;00m\n\u001b[32m    573\u001b[39m \u001b[38;5;66;03m# us to set `clean=False` if we are storing normally, since the values will already have been cleaned\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend_entity\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclean_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[38;5;66;03m# Retrieve the cached node if ``should_use_cache`` returns True\u001b[39;00m\n\u001b[32m    577\u001b[39m same_node = \u001b[38;5;28mself\u001b[39m.base.caching._get_same_node() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.base.caching.should_use_cache() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/storage/psql_dos/orm/nodes.py:207\u001b[39m, in \u001b[36mSqlaNode.clean_values\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclean_values\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.attributes = \u001b[43mclean_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.extras = clean_value(\u001b[38;5;28mself\u001b[39m.model.extras)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/orm/implementation/utils.py:102\u001b[39m, in \u001b[36mclean_value\u001b[39m\u001b[34m(value)\u001b[39m\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m clean_builtin(value.value)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Mapping):\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# Check dictionary before iterables\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: \u001b[43mclean_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m value.items()}\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Iterable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# list, tuple, ... but not a string\u001b[39;00m\n\u001b[32m    106\u001b[39m     \u001b[38;5;66;03m# This should also properly take care of dealing with the\u001b[39;00m\n\u001b[32m    107\u001b[39m     \u001b[38;5;66;03m# basedatatypes.List object\u001b[39;00m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [clean_value(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/orm/implementation/utils.py:115\u001b[39m, in \u001b[36mclean_value\u001b[39m\u001b[34m(value)\u001b[39m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [clean_value(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# If I don't know what to do I just return the value\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# itself - it's not super robust, but relies on duck typing\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# (e.g. if there is something that behaves like an integer\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# but is not an integer, I still accept it)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclean_builtin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/orm/implementation/utils.py:95\u001b[39m, in \u001b[36mclean_value.<locals>.clean_builtin\u001b[39m\u001b[34m(val)\u001b[39m\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m new_val\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Anything else we do not understand and we refuse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exceptions.ValidationError(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtype `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(val)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` is not supported as it is not json-serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mValidationError\u001b[39m: type `<class 'aiida.orm.nodes.data.code.installed.InstalledCode'>` is not supported as it is not json-serializable"
     ]
    }
   ],
   "source": [
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9639a",
   "metadata": {},
   "source": [
    "\n",
    "### Visualize the WorkGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c6d0545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db155187e22e42759ce4ba2473924496",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "NodeGraphWidget(settings={'minimap': True}, style={'width': '90%', 'height': '600px'}, value={'name': 'md_trai…"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ed58e",
   "metadata": {},
   "source": [
    "### After successful completion, you have:\n",
    "\n",
    "1. **Fine-tuned MACE model**: Improved accuracy for NaCl systems\n",
    "2. **Training datasets**: ExtXYZ files with DFT labels\n",
    "3. **Complete provenance**: Full AiiDA history of all calculations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiida-mlip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
