{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c13c1dd7",
   "metadata": {},
   "source": [
    "# WorkGraph example to run Molecular Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81fa1b",
   "metadata": {},
   "source": [
    "## Aim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ecbb39",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to run a molecular dynamics simulation. As an example, we start with a salt crystal structure, run a molecular dynamics simulation on it that takes snapshots of the trajectory over time and then compute the descriptors on each structure snapshot. The workgraph uses a filtering function to split the resulting data into three files for training the machine learning model.\n",
    "The goal is to show how to run the descriptors on each snapshot of the MD sim. \n",
    "\n",
    "note to self: NVT keeps temp and vol constant, is this adequate? MD req. temp change?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bfb65e",
   "metadata": {},
   "source": [
    "Load the aiida profile, structure, model and code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79098139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profile<uuid='60b17659a9844c4bbd3bef8de0a8f417' name='presto'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aiida import load_profile\n",
    "load_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bc2cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_mlip.data.model import ModelData\n",
    "uri = \"https://github.com/stfc/janus-core/raw/main/tests/models/mace_mp_small.model\"\n",
    "model = ModelData.from_uri(uri, architecture=\"mace_mp\", cache_dir=\"mlips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89ba5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import StructureData\n",
    "from ase.build import bulk\n",
    "from ase.io import read, iread\n",
    "\n",
    "# structure = StructureData(ase=read(\"Structures/qmof-ffeef76.cif\"))\n",
    "init_structure = StructureData(ase=bulk(\"NaCl\", \"rocksalt\", 5.63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae62816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import load_code\n",
    "janus_code = load_code(\"janus@localhost\")\n",
    "qe_code = load_code(\"qe@scarf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f240333a",
   "metadata": {},
   "source": [
    "We initialize the inputs we want for all the calculations. These variables can be changed depending on the configuration you are running and whether you want to change any inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e4c78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.plugins import CalculationFactory\n",
    "\n",
    "mdCalc = CalculationFactory(\"mlip.md\")\n",
    "descriptorsCalc = CalculationFactory(\"mlip.descriptors\")\n",
    "trainCalc = CalculationFactory(\"mlip.train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36acd26d",
   "metadata": {},
   "source": [
    "configure the descriptors task to run on each trajectory snapshop so we create multiple tasks dynamically within the same task using `get_current_graph()`. This allows us to run descriptors for each structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f0b91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_workgraph import WorkGraph, task\n",
    "from aiida_workgraph.manager import get_current_graph\n",
    "\n",
    "@task.graph(outputs = [\"final_structs\"])\n",
    "def descriptors_task(\n",
    "    code,\n",
    "    model,\n",
    "    device,\n",
    "    arch,\n",
    "    file,\n",
    "):\n",
    "    descriptorsCalc = CalculationFactory(\"mlip.descriptors\")\n",
    "    wg = get_current_graph()\n",
    "    final_structures={}\n",
    "    \n",
    "    with file.as_path() as path:\n",
    "        for i, structs in enumerate(iread(path)):\n",
    "            structure = StructureData(ase=structs)\n",
    "\n",
    "            desc_calc = wg.add_task(\n",
    "                descriptorsCalc,\n",
    "                code=code,\n",
    "                model=model,\n",
    "                device=device,\n",
    "                arch=arch,\n",
    "                struct=structure,\n",
    "                calc_per_element=bool(True), # per element descriptors ie. mace Na and Cl\n",
    "                metadata={\"options\": {\"resources\": {\"num_machines\": 1}}}\n",
    "            )\n",
    "\n",
    "            structfile = f\"final_structs.struct{i}\"\n",
    "            #   final_structures[f\"structs{i}\"] = desc_calc.outputs.xyz_output\n",
    "            wg.update_ctx({\n",
    "                structfile : desc_calc.outputs.xyz_output,\n",
    "            })\n",
    "\n",
    "    \n",
    "    n_samp = len(final_structures)\n",
    "    return {\n",
    "        \"final_structs\": wg.ctx.final_structs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ecc71",
   "metadata": {},
   "source": [
    "configure the `Quantum Espresso (QE)` task by defining the code and input parameters. Since we need to run QE on multiple structures, we create multiple `PwCalculation` tasks dynamically within the same task using `get_current_graph()`. This allows us to run QE for each structure and return the corresponding `TrajectoryData` and parameters for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62de8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_workgraph import task\n",
    "from aiida_workgraph.manager import get_current_graph\n",
    "from aiida.orm import StructureData, load_group, KpointsData, SinglefileData, InstalledCode, List, Dict\n",
    "from ase.io import iread\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from aiida_quantumespresso.calculations.pw import PwCalculation\n",
    "from sample_split import process_and_split_data\n",
    "\n",
    "\n",
    "@task.graph(outputs = [\"test_file\", \"train_file\", \"valid_file\"])\n",
    "def qe(\n",
    "    code: InstalledCode,\n",
    "    kpoints_mesh: List,\n",
    "    task_metadata: Dict,\n",
    "    test_file: SinglefileData,\n",
    "    train_file: SinglefileData,\n",
    "    valid_file: SinglefileData\n",
    "    ):\n",
    "\n",
    "    wg = get_current_graph()\n",
    "\n",
    "    kpoints = KpointsData()\n",
    "    kpoints.set_kpoints_mesh(kpoints_mesh)\n",
    "\n",
    "    pseudo_family = load_group('SSSP/1.3/PBE/efficiency')\n",
    "    \n",
    "    files = {\"test_file\": test_file, \"train_file\": train_file, \"valid_file\": valid_file}\n",
    "\n",
    "    for file_name, file in files.items():\n",
    "        with file.as_path() as path:\n",
    "            for i, structs in enumerate(iread(path, format=\"extxyz\")):\n",
    "                \n",
    "                structure = StructureData(ase=structs)\n",
    "                pseudos = pseudo_family.get_pseudos(structure=structure)\n",
    "\n",
    "                ecutwfc, ecutrho = pseudo_family.get_recommended_cutoffs(\n",
    "                    structure=structure,\n",
    "                    unit='Ry',\n",
    "                )\n",
    "\n",
    "                pw_params = {\n",
    "                    \"CONTROL\": {\n",
    "                        \"calculation\": \"scf\",\n",
    "                        'tprnfor': True,\n",
    "                        'tstress': True,\n",
    "                    },\n",
    "                    \"SYSTEM\": {\n",
    "                        \"ecutwfc\": ecutwfc,\n",
    "                        \"ecutrho\": ecutrho,\n",
    "                    },\n",
    "                }\n",
    "                \n",
    "                qe_task = wg.add_task(\n",
    "                    PwCalculation,\n",
    "                    code=code,\n",
    "                    parameters=pw_params,\n",
    "                    kpoints=kpoints,\n",
    "                    pseudos=pseudos,\n",
    "                    metadata=task_metadata.value,\n",
    "                    structure=structure,\n",
    "                )\n",
    "                \n",
    "                structfile = f\"{file_name}.struct{i}\"\n",
    "\n",
    "                wg.update_ctx({\n",
    "                    structfile:{\n",
    "                        \"trajectory\":qe_task.outputs.output_trajectory,\n",
    "                        \"parameters\": qe_task.outputs.output_parameters\n",
    "                    }\n",
    "                })\n",
    "\n",
    "    return {\n",
    "        \"test_file\": wg.ctx.test_file,\n",
    "        \"train_file\": wg.ctx.train_file,\n",
    "        \"valid_file\": wg.ctx.valid_file\n",
    "    }    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcacee8",
   "metadata": {},
   "source": [
    "The next task we need is a function which can extract the required parameters from the QE tasks and create the files for training. This task creates `mlip_[file]_file.extxyz`, adds the filepath to the example `JanusConfigfile.yml` that we provide. This file sets all of the inputs for fine-tuning, so should be modified according to your needs. Finally, the task returns a `JanusConfigfile` object which is used for the training calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a430a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_mlip.data.config import JanusConfigfile\n",
    "from aiida.orm import Dict\n",
    "from ase.io import write\n",
    "from ase import units\n",
    "\n",
    "@task.calcfunction(outputs = [\"JanusConfigfile\"])\n",
    "def create_train_file(**inputs):\n",
    "\n",
    "    training_files = {}\n",
    "    \n",
    "    for file_name, structs in inputs.items():\n",
    "        path = Path(f\"mlip_{file_name}.extxyz\")\n",
    "\n",
    "        for struct_out_params in structs.values():\n",
    "            \n",
    "            trajectory = struct_out_params[\"trajectory\"]\n",
    "\n",
    "            fileStructure = trajectory.get_structure(index=0)\n",
    "            fileAtoms = fileStructure.get_ase()\n",
    "\n",
    "            stress = trajectory.arrays[\"stress\"][0]\n",
    "            converted_stress = stress * units.GPa\n",
    "            fileAtoms.info[\"qe_stress\"] = converted_stress\n",
    "\n",
    "            fileAtoms.info[\"units\"] = {\"energy\": \"eV\",\"forces\": \"ev/Ang\",\"stress\": \"ev/Ang^3\"}\n",
    "            fileAtoms.set_array(\"qe_forces\", trajectory.arrays[\"forces\"][0])\n",
    "\n",
    "            parameters = struct_out_params[\"parameters\"]\n",
    "            fileParams = parameters.get_dict()\n",
    "            fileAtoms.info[\"qe_energy\"] = fileParams[\"energy\"]\n",
    "            write(path, fileAtoms, append=True)\n",
    "\n",
    "        training_files[file_name] = str(path.resolve())\n",
    "\n",
    "    with open(\"JanusConfigfile.yml\", \"a\") as f:\n",
    "        yaml.safe_dump(training_files, f, sort_keys=False)\n",
    "\n",
    "    return{'JanusConfigfile': JanusConfigfile(Path(\"JanusConfigfile.yml\").resolve())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5766874",
   "metadata": {},
   "source": [
    "For this task, we are using a task to run a pure python function. This is to demonstrate the flexibility of tasks and how you can run python functions with Workgraph. Also this task has to be a calcfunction, as we are returning `SinglefileData` instances of the test, train and valid files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ac1993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import Int\n",
    "@task.calcfunction(outputs = [\"test_file\", \"train_file\", \"valid_file\"])\n",
    "def create_qe_files(**inputs):\n",
    "\n",
    "    n_samples = Int(len(inputs['trajectory_data']))\n",
    "    print(n_samples)\n",
    "\n",
    "    # n_samples= descriptors_calc.outputs.n_samp,\n",
    "\n",
    "    # n_samples= Int(len(descriptors_calc.outputs.structs)), #this doesnt work because it is a future value\n",
    "#   # Calculate n_samples inside the task where trajectory_data is available\n",
    "    # n_samples \n",
    "    files = process_and_split_data( \n",
    "        **inputs,\n",
    "        n_samples=n_samples,\n",
    "        \n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"train_file\": SinglefileData(files[\"train_file\"]),\n",
    "        \"test_file\": SinglefileData(files[\"test_file\"]),\n",
    "        \"valid_file\": SinglefileData(files[\"valid_file\"])\n",
    "    }\n",
    "\n",
    "# @task.calcfunction(outputs=[\"test_file\", \"train_file\", \"valid_file\"])\n",
    "# def create_qe_files(trajectory_data, config_types, prefix, scale, append_mode):\n",
    "#     \"\"\"Create split files using the sample_split function\"\"\"\n",
    "    \n",
    "# # Note to self! trajectory_data fdoesnt exist! reead the errors\n",
    "    \n",
    "#     # Calculate n_samples inside the task where trajectory_data is available\n",
    "#     n_samples = len(trajectory_data)\n",
    "    \n",
    "#     # Call process_and_split_data with all required parameters\n",
    "#     files = process_and_split_data(\n",
    "#         trajectory_data=trajectory_data,\n",
    "#         config_types=config_types,\n",
    "#         prefix=prefix,\n",
    "#         scale=scale,\n",
    "#         append_mode=append_mode,\n",
    "#         n_samples=n_samples  # Calculate here instead of passing from outside\n",
    "#     )\n",
    "\n",
    "#     return {\n",
    "#         \"train_file\": SinglefileData(files[\"train_file\"]),\n",
    "#         \"test_file\": SinglefileData(files[\"test_file\"]),\n",
    "#         \"valid_file\": SinglefileData(files[\"valid_file\"])\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1795dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to tidy up these inputs: inputs is original (needs renaming for md_inputs) and others are QE etc\n",
    "\n",
    "from aiida.orm import Str, Float, Bool, Int, Dict\n",
    "inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cpu\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "    \"ensemble\": Str(\"NVT\"),\n",
    "    \"struct\": init_structure,\n",
    "    \"md_kwargs\": Dict(\n",
    "        {\n",
    "            \"steps\": 10,\n",
    "            \"traj-every\": 2\n",
    "        }\n",
    "    )\n",
    "}\n",
    "calc_inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cpu\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "}\n",
    "\n",
    "split_task_inputs = {\n",
    "    \"config_types\": Str(\"\"),\n",
    "    \"prefix\": Str(\"\"),\n",
    "    \"scale\": Float(1.0e5),\n",
    "    \"append_mode\": Bool(False),\n",
    "}\n",
    "\n",
    "qe_inputs = {\n",
    "    \"task_metadata\": Dict({\n",
    "            \"options\": {\n",
    "                \"resources\": {\n",
    "                    \"num_machines\": 1,\n",
    "                    \"num_mpiprocs_per_machine\": 32,\n",
    "                },\n",
    "                \"max_wallclock_seconds\": 3600,\n",
    "                \"queue_name\": \"scarf\",\n",
    "                \"qos\": \"scarf\",\n",
    "                \"environment_variables\": {},\n",
    "                \"withmpi\": True,\n",
    "                \"prepend_text\": \"\"\"\n",
    "                    module purge\n",
    "                    module use /work4/scd/scarf562/eb-common/modules/all\n",
    "                    module load amd-modules\n",
    "                    module load QuantumESPRESSO/7.2-foss-2023a\n",
    "                \"\"\",\n",
    "                \"append_text\": \"\",\n",
    "            },\n",
    "    }),\n",
    "    \"kpoints_mesh\": List([1, 1, 1]),\n",
    "    \"code\": qe_code,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e82a4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "with WorkGraph(\"MD\") as wg:\n",
    "\n",
    "    md_calc = wg.add_task(\n",
    "        mdCalc,\n",
    "        name=\"md_calc\",\n",
    "        **inputs\n",
    "    )\n",
    "\n",
    "    descriptors_calc = wg.add_task(\n",
    "        descriptors_task,\n",
    "        code=janus_code,\n",
    "        model=model,\n",
    "        device=Str(\"cpu\"),\n",
    "        arch=Str(model.architecture),\n",
    "        file=md_calc.outputs.traj_file\n",
    "    )\n",
    "   \n",
    "    split_task = wg.add_task(\n",
    "        create_qe_files, \n",
    "        **split_task_inputs,\n",
    "        trajectory_data=descriptors_calc.outputs.final_structs,\n",
    "        # file=descriptors_calc.outputs.structs, #this is not currently doing anything \n",
    "        # n_samples= Int(len(descriptors_calc.outputs.structs)), #this doesnt work because it is a future value\n",
    "        )\n",
    "    \n",
    "    qe_task = wg.add_task(\n",
    "        qe, \n",
    "        name=\"QE_workflow\",\n",
    "        test_file= split_task.outputs.test_file,\n",
    "        train_file= split_task.outputs.train_file,\n",
    "        valid_file= split_task.outputs.valid_file,\n",
    "        **qe_inputs\n",
    "    )\n",
    "\n",
    "    training_files = wg.add_task(\n",
    "        create_train_file, \n",
    "        test_file= qe_task.outputs.test_file,\n",
    "        train_file= qe_task.outputs.train_file,\n",
    "        valid_file= qe_task.outputs.valid_file,\n",
    "        )\n",
    "\n",
    "    train_task = wg.add_task(\n",
    "        trainCalc,\n",
    "        mlip_config=training_files.outputs.JanusConfigfile,\n",
    "        code=calc_inputs[\"code\"],\n",
    "        foundation_model=calc_inputs[\"model\"],\n",
    "        metadata=calc_inputs[\"metadata\"],\n",
    "        fine_tune=True,\n",
    "    )\n",
    "    # split_task = wg.add_task(\n",
    "    #     create_split_files,\n",
    "    #     name=\"split_data\",\n",
    "    #     config_types=Str(\"\"),\n",
    "    #     prefix=Str(\"\"),\n",
    "    #     scale=Float(1.0e5),\n",
    "    #     append_mode=Bool(False),\n",
    "    #     trajectory_data=descriptors_calc.outputs.structs,  \n",
    "    # )\n",
    "\n",
    "    # split_task = wg.add_task(\n",
    "    #     process_and_split_data,\n",
    "    #     config_types= Str(\"\"),\n",
    "    #     n_samples=Int(len(descriptors_calc.outputs.structs)),\n",
    "    #     prefix= Str(\"\"),\n",
    "    #     scale= Float(1.0e5),\n",
    "    #     append_mode= Bool(False),\n",
    "    #     # create_aiida_files, \n",
    "    #     # **split_task_inputs,\n",
    "    #     trajectory_data=descriptors_calc.outputs.structs,\n",
    "    #     # n_samples= Int(len(final_structures)),\n",
    "    # )\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4394b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/09/2025 02:25:17 PM <7867> aiida.broker.rabbitmq: [WARNING] RabbitMQ v3.12.1 is not supported and will cause unexpected problems!\n",
      "12/09/2025 02:25:17 PM <7867> aiida.broker.rabbitmq: [WARNING] It can cause long-running workflows to crash and jobs to be submitted multiple times.\n",
      "12/09/2025 02:25:17 PM <7867> aiida.broker.rabbitmq: [WARNING] See https://github.com/aiidateam/aiida-core/wiki/RabbitMQ-version-to-use for details.\n",
      "12/09/2025 02:25:18 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|continue_workgraph]: tasks ready to run: md_calc\n",
      "12/09/2025 02:25:18 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 4415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qoj42292/.aiida/scratch/presto/af/b7/09c7-ac04-447c-9a63-ed2449883808 md-summary.yml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/09/2025 02:25:28 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|update_task_state]: Task: md_calc, type: CALCJOB, finished.\n",
      "12/09/2025 02:25:28 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|continue_workgraph]: tasks ready to run: descriptors_task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defining outputnode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/09/2025 02:25:29 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 4432\n",
      "12/09/2025 02:25:29 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4432|WorkGraphEngine|continue_workgraph]: tasks ready to run: Descriptors,Descriptors1,Descriptors2,Descriptors3,Descriptors4,Descriptors5\n",
      "12/09/2025 02:25:31 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4432|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 4437, 4442, 4447, 4452, 4457, 4462\n",
      "12/09/2025 02:25:47 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4432|WorkGraphEngine|update_task_state]: Task: Descriptors, type: CALCJOB, finished.\n",
      "12/09/2025 02:25:47 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4432|WorkGraphEngine|update_task_state]: Task: Descriptors1, type: CALCJOB, finished.\n",
      "12/09/2025 02:25:47 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4432|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "12/09/2025 02:25:47 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4432|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 4447, 4452, 4457, 4462\n",
      "12/09/2025 02:25:49 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4432|WorkGraphEngine|update_task_state]: Task: Descriptors2, type: CALCJOB, finished.\n",
      "12/09/2025 02:25:49 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4432|WorkGraphEngine|update_task_state]: Task: Descriptors3, type: CALCJOB, finished.\n",
      "12/09/2025 02:25:49 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4432|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "12/09/2025 02:25:49 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4432|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 4457, 4462\n",
      "12/09/2025 02:25:51 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4432|WorkGraphEngine|update_task_state]: Task: Descriptors4, type: CALCJOB, finished.\n",
      "12/09/2025 02:25:51 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4432|WorkGraphEngine|update_task_state]: Task: Descriptors5, type: CALCJOB, finished.\n",
      "12/09/2025 02:25:51 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4432|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "12/09/2025 02:25:51 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4432|WorkGraphEngine|finalize]: Finalize workgraph.\n",
      "12/09/2025 02:25:51 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|update_task_state]: Task: descriptors_task, type: GRAPH, finished.\n",
      "12/09/2025 02:25:52 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|continue_workgraph]: tasks ready to run: create_qe_files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uuid: 17bd649b-48b0-4c3e-92d0-2e8104399419 (unstored) value: 6\n",
      "create files: train_file=PosixPath('train.xyz'), valid_file=PosixPath('valid.xyz') and test_file=PosixPath('test.xyz')\n",
      "Processing: ('all', 'aiida'), 6 frames\n",
      "  ('all', 'aiida'): total=6, train_target=4,                     vt_target=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/fpsample/wrapper.py:98: UserWarning: k is too large, set to 6\n",
      "  warnings.warn(f\"k is too large, set to {n_pts}\")\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/fpsample/wrapper.py:98: UserWarning: k is too large, set to 2\n",
      "  warnings.warn(f\"k is too large, set to {n_pts}\")\n",
      "12/09/2025 02:25:52 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|update_task_state]: Task: create_qe_files, type: CALCFUNCTION, finished.\n",
      "12/09/2025 02:25:52 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|continue_workgraph]: tasks ready to run: QE_workflow\n",
      "12/09/2025 02:25:54 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 4510\n",
      "12/09/2025 02:25:54 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4510|WorkGraphEngine|continue_workgraph]: tasks ready to run: PwCalculation,PwCalculation1,PwCalculation2,PwCalculation3,PwCalculation4,PwCalculation5\n",
      "12/09/2025 02:25:56 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4510|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 4512, 4514, 4516, 4518, 4520, 4522\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:15: AiidaDeprecationWarning: The parse_xml.versions module is deprecated and will be removed in aiida-quantumespresso v5.0.\n",
      "Use get_schema_filepath() from parse_xml.parse instead.\n",
      "  from aiida_quantumespresso.parsers.parse_xml.versions import QeXmlVersion, get_xml_file_version\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/legacy.py:18: AiidaDeprecationWarning: This module has been deprecated and will be removed in aiida-quantumespresso v5.0.\n",
      "If you are seeing this warning, you will have to update your Quantum ESPRESSO version (v6.6 or above).\n",
      "  warnings.warn(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/legacy.py:27: AiidaDeprecationWarning: This module has been deprecated and will be removed in aiida-quantumespresso v5.0.\n",
      "If you are seeing this warning, you will have to update your Quantum ESPRESSO version (v6.6 or above).\n",
      "  warnings.warn(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:19: AiidaDeprecationWarning: The parse_xml.pw.parse module has been deprecated and will be removed in aiida-quantumespresso v5.0.\n",
      "Use parse_xml() from parse_xml.parse directly. Legacy XML format support will be dropped.\n",
      "  warnings.warn(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "12/09/2025 02:29:24 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4510|WorkGraphEngine|update_task_state]: Task: PwCalculation, type: CALCJOB, finished.\n",
      "12/09/2025 02:29:24 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4510|WorkGraphEngine|update_task_state]: Task: PwCalculation1, type: CALCJOB, finished.\n",
      "12/09/2025 02:29:24 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4510|WorkGraphEngine|update_task_state]: Task: PwCalculation2, type: CALCJOB, finished.\n",
      "12/09/2025 02:29:24 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4510|WorkGraphEngine|update_task_state]: Task: PwCalculation3, type: CALCJOB, finished.\n",
      "12/09/2025 02:29:24 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4510|WorkGraphEngine|update_task_state]: Task: PwCalculation4, type: CALCJOB, finished.\n",
      "12/09/2025 02:29:24 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4510|WorkGraphEngine|update_task_state]: Task: PwCalculation5, type: CALCJOB, finished.\n",
      "12/09/2025 02:29:24 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4510|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "12/09/2025 02:29:24 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4510|WorkGraphEngine|finalize]: Finalize workgraph.\n",
      "12/09/2025 02:29:24 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|update_task_state]: Task: QE_workflow, type: GRAPH, finished.\n",
      "12/09/2025 02:29:25 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|continue_workgraph]: tasks ready to run: create_train_file\n",
      "12/09/2025 02:29:26 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|update_task_state]: Task: create_train_file, type: CALCFUNCTION, finished.\n",
      "12/09/2025 02:29:26 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|continue_workgraph]: tasks ready to run: Train\n",
      "12/09/2025 02:29:27 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 4556\n",
      "12/09/2025 02:29:44 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|update_task_state]: Task: Train, type: CALCJOB, finished.\n",
      "12/09/2025 02:29:44 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "12/09/2025 02:29:44 PM <7867> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [4412|WorkGraphEngine|finalize]: Finalize workgraph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4161070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wg.tasks.create_qe_files.inputs.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a07fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(wg.tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c6d0545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa88f9c86f9340ad8dea20f53eb89519",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "NodeGraphWidget(settings={'minimap': True}, states={'graph_inputs': 'FINISHED', 'graph_outputs': 'FINISHED', 'â€¦"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3f5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "! verdi process list -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fabb5db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3b99ef4",
   "metadata": {},
   "source": [
    "# Additional information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(descriptorsCalc.spec().inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(wg.tasks.md_calc.outputs.traj_file.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aa6a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdCalc.get_description()[\"spec\"][\"outputs\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9180ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('outputs of mdCalc:', md_calc.outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c34e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(wg.tasks.md_calc.outputs.traj_file.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af828b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('outputs of descriptors_task:', descriptors_calc.outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find inputs/outputs of mdcalc uncomment following: \n",
    "# mdCalc.get_description()[\"spec\"][\"outputs\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758cd14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aiida.orm import load_node\n",
    "# traj = load_node(PK) \n",
    "\n",
    "# # print(len(list(iread(wg.tasks.md_calc.outputs.traj_file.value.as_path()))))\n",
    "# traj_length = (wg.tasks.md_calc.outputs.traj_file.value.as_path()).numsteps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf1c398",
   "metadata": {},
   "source": [
    "# Loop Descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4b63e5",
   "metadata": {},
   "source": [
    " the workflow does not have an output yet for wg.tasks.md.outputs.traj_file \n",
    "\n",
    " usually you can just pass in a socket. But because we have to get the path to read it you have to create a task\n",
    " \n",
    " you need to create a task which waites for md_task to run and then gets that output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8e7371",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fe8d0a7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0772c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sample_split import process_and_split_data\n",
    "# # @task.calcfunction(outputs = [\"test_file\", \"train_file\", \"valid_file\"])\n",
    "# # def create_split_files(**inputs):\n",
    "     \n",
    "# #     files = process_and_split_data(**inputs)\n",
    "\n",
    "# #     return {\n",
    "# #         \"train_file\": SinglefileData(files[\"train_file\"]),\n",
    "# #         \"test_file\": SinglefileData(files[\"test_file\"]),\n",
    "# #         \"valid_file\": SinglefileData(files[\"valid_file\"])\n",
    "# #     }\n",
    "\n",
    "# @task.calcfunction(outputs=[\"test_file\", \"train_file\", \"valid_file\"])\n",
    "# def create_split_files(trajectory_data, config_types, prefix, scale, append_mode):\n",
    "#     \"\"\"Create split files using plain Python function call\"\"\"\n",
    "    \n",
    "#     # Call the plain Python function directly (not as a task) ??\n",
    "#     files = process_and_split_data(\n",
    "#         trajectory_data=trajectory_data,\n",
    "#         config_types=config_types,\n",
    "#         prefix=prefix,\n",
    "#         scale=scale,\n",
    "#         append_mode=append_mode\n",
    "#     )\n",
    "    \n",
    "#     return {\n",
    "#         \"train_file\": SinglefileData(files[\"train_file\"]),\n",
    "#         \"test_file\": SinglefileData(files[\"test_file\"]),\n",
    "#         \"valid_file\": SinglefileData(files[\"valid_file\"])\n",
    "#     }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiida-mlip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
