{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ecbb39",
   "metadata": {},
   "source": [
    "# WorkGraph Tutorial: MD Simulation with DFT Labeling and MLIP Fine-tuning\n",
    "\n",
    "This tutorial demonstrates building complex workflows with AiiDA WorkGraph through a real-world example: generating DFT-labeled training data and fine-tuning a machine learning interatomic potential (MLIP).\n",
    "\n",
    "## Workflow Steps\n",
    "\n",
    "1. **MD Simulation** → Generate diverse NaCl configurations (6 snapshots)\n",
    "2. **Descriptors** → Calculate MLIP features for filtering (dynamic tasks)\n",
    "3. **Data Split** → FPS filtering into train/validation/test sets\n",
    "4. **DFT Labeling** → Quantum ESPRESSO energies, forces, stresses (nested dynamic tasks)\n",
    "5. **Training Files** → Format ExtXYZ files with DFT labels\n",
    "6. **Fine-tuning** → Train MACE model on DFT data\n",
    "\n",
    "## WorkGraph Features\n",
    "\n",
    "- **Dynamic task generation**: Create tasks at runtime based on trajectory length\n",
    "- **Nested namespaces**: Organize complex hierarchical outputs\n",
    "- **Automatic dependencies**: Tasks execute when inputs become available\n",
    "- **Parallel execution**: Independent calculations run simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bfb65e",
   "metadata": {},
   "source": [
    "### Load AiiDA Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79098139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profile<uuid='60b17659a9844c4bbd3bef8de0a8f417' name='presto'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aiida import load_profile\n",
    "load_profile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef36ae",
   "metadata": {},
   "source": [
    "### Verify SSSP Pseudopotentials\n",
    "\n",
    "Quantum ESPRESSO requires pseudopotentials for DFT calculations. We check that the SSSP library is installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716ecb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SSSP pseudopotentials installed (103 pseudos)\n"
     ]
    }
   ],
   "source": [
    "from aiida.orm import load_group\n",
    "try:\n",
    "    pseudo_family = load_group('SSSP/1.3/PBE/efficiency')\n",
    "    print(f\" SSSP pseudopotentials installed ({len(pseudo_family.nodes)} pseudos)\")\n",
    "except Exception:\n",
    "    print(\" SSSP not installed, Run: aiida-pseudo install sssp -v 1.3 -p efficiency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d393384",
   "metadata": {},
   "source": [
    "### Load ML Potential Model\n",
    "We download a pre-trained MACE model from the janus-core repository. This foundation model will be:\n",
    "- Used for the initial MD simulation\n",
    "- Used to calculate descriptors for filtering\n",
    "- Fine-tuned on our DFT-labeled data\n",
    "\n",
    "The `ModelData.from_uri()` function automatically caches the model locally to avoid repeated downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc2cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_mlip.data.model import ModelData\n",
    "uri = \"https://github.com/stfc/janus-core/raw/main/tests/models/mace_mp_small.model\"\n",
    "model = ModelData.from_uri(uri, architecture=\"mace_mp\", cache_dir=\"mlips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c68186",
   "metadata": {},
   "source": [
    "### Define Initial Structure\n",
    "\n",
    "We create a rocksalt NaCl structure with a lattice parameter of 5.63 Å. This serves as the starting point for our MD simulation.\n",
    "\n",
    "**Why NaCl?** It's a simple ionic crystal that demonstrates:\n",
    "- Multi-element systems\n",
    "- Different atomic environments\n",
    "- Structural variations during MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89ba5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import StructureData\n",
    "from ase.build import bulk\n",
    "from ase.io import read, iread\n",
    "\n",
    "# structure = StructureData(ase=read(\"Structures/qmof-ffeef76.cif\"))\n",
    "init_structure = StructureData(ase=bulk(\"NaCl\", \"rocksalt\", 5.63))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12932e35",
   "metadata": {},
   "source": [
    "### Load Computational Codes\n",
    "\n",
    "We need two codes:\n",
    "- **janus@localhost**: For MLIP calculations (MD, descriptors, training) - runs locally\n",
    "- **qe@scarf**: For DFT calculations with Quantum ESPRESSO - runs on HPC cluster\n",
    "\n",
    "See examples>tutorials>aiida_setup for setting up janus code and external computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae62816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import load_code\n",
    "janus_code = load_code(\"janus@localhost\")\n",
    "qe_code = load_code(\"qe@scarf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f240333a",
   "metadata": {},
   "source": [
    "### Define Calculation Types\n",
    "\n",
    "We define three calculation types from the `aiida-mlip` plugin:\n",
    "- `mdCalc`: Molecular dynamics simulation\n",
    "- `descriptorsCalc`: Compute structural descriptors\n",
    "- `trainCalc`: Fine-tune the MLIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4c78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.plugins import CalculationFactory\n",
    "\n",
    "mdCalc = CalculationFactory(\"mlip.md\")\n",
    "descriptorsCalc = CalculationFactory(\"mlip.descriptors\")\n",
    "trainCalc = CalculationFactory(\"mlip.train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36acd26d",
   "metadata": {},
   "source": [
    "# WorkGraph Concepts\n",
    "\n",
    "## Concept 1: Task Decorators & Dynamic Outputs\n",
    "\n",
    "WorkGraph provides decorators to convert functions and calculations into workflow tasks. There are three main types:\n",
    "\n",
    "- `task(CalculationClass)`: Wrap AiiDA calculations\n",
    "- `@task.calcfunction`: Wrap AiiDA calcfunctions\n",
    "- `@task.graph`: Create a sub-workflow (task graph)\n",
    "\n",
    "### Dynamic Task Creation\n",
    "\n",
    "The `descriptors_task` below demonstrates **dynamic task generation**:\n",
    "- The `@task.graph` decorator makes this a reusable sub-workflow\n",
    "- `dynamic(SinglefileData)` in the output namespace means the number of outputs is determined at runtime\n",
    "- Inside the function, we loop through structures and create a task for each one\n",
    "- Each task runs independently (in parallel where possible)\n",
    "\n",
    "**Key WorkGraph Feature**: Notice how we create tasks in a loop and store their outputs in a dictionary. WorkGraph automatically:\n",
    "1. Tracks dependencies between all generated tasks\n",
    "2. Executes them in parallel when resources allow\n",
    "3. Collects all results into the `final_structs` output\n",
    "\n",
    "## Dynamic Task Creation: Descriptors\n",
    "\n",
    "**WorkGraph Feature**: The `@task.graph` decorator with `dynamic(SinglefileData)` outputs allows creating variable numbers of tasks at runtime.\n",
    "\n",
    "**Scientific Purpose**: Calculate MLIP descriptors per structure for filtering diverse configurations. Descriptors characterize local atomic environments and enable intelligent selection of training data.\n",
    "\n",
    "The loop creates one descriptor calculation per MD snapshot, running in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0b91b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defining outputnode\n"
     ]
    }
   ],
   "source": [
    "from aiida_workgraph import WorkGraph, task, dynamic, namespace\n",
    "from aiida.orm import SinglefileData\n",
    "\n",
    "descriptorsTask = task(descriptorsCalc)\n",
    "\n",
    "@task.graph(outputs=namespace(final_structs=dynamic(SinglefileData)))\n",
    "def descriptors_task(\n",
    "    code,\n",
    "    model,\n",
    "    device,\n",
    "    arch,\n",
    "    file,\n",
    "):\n",
    "    results = {}\n",
    "    \n",
    "    with file.as_path() as path:\n",
    "        for i, structs in enumerate(iread(path)):\n",
    "            structure = StructureData(ase=structs)\n",
    "\n",
    "            desc_calc = descriptorsTask(\n",
    "                code=code,\n",
    "                model=model,\n",
    "                device=device,\n",
    "                arch=arch,\n",
    "                struct=structure,\n",
    "                calc_per_element=True,\n",
    "                metadata={\"options\": {\"resources\": {\"num_machines\": 1}}}\n",
    "            )\n",
    "\n",
    "            results[f\"struct{i}\"] = desc_calc.xyz_output\n",
    "\n",
    "    return {\"final_structs\": results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ecc71",
   "metadata": {},
   "source": [
    "## Concept 2: Nested Dynamic Tasks & Namespaces\n",
    "\n",
    "The `qe` task graph demonstrates more advanced WorkGraph features:\n",
    "\n",
    "### Namespaces for Structured Outputs\n",
    "\n",
    "```python\n",
    "qe_output = namespace(trajectory=TrajectoryData, parameters=Dict)\n",
    "```\n",
    "\n",
    "This defines a **namespace** - a structured output containing multiple typed fields. Each DFT calculation returns both trajectory and parameters.\n",
    "\n",
    "### Dynamic Nested Outputs\n",
    "\n",
    "```python\n",
    "outputs=namespace(\n",
    "    test_file=dynamic(qe_output),\n",
    "    train_file=dynamic(qe_output),\n",
    "    valid_file=dynamic(qe_output),\n",
    ")\n",
    "```\n",
    "\n",
    "This creates a **nested dynamic structure**:\n",
    "- Three fixed categories (test, train, valid)\n",
    "- Each category contains a dynamic number of results\n",
    "- Each result is a namespace with trajectory and parameters\n",
    "\n",
    "**WorkGraph's Power**: This task processes three input files and creates dozens of DFT calculations. WorkGraph:\n",
    "1. Automatically parallelizes all independent calculations\n",
    "2. Organizes outputs hierarchically \n",
    "3. Passes the entire structure to downstream tasks\n",
    "4. Handles remote execution (HPC cluster) transparently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62de8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import (\n",
    "    TrajectoryData,\n",
    "    StructureData, \n",
    "    load_group, \n",
    "    KpointsData, \n",
    "    InstalledCode, \n",
    "    List, \n",
    "    Dict,\n",
    ")\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from aiida_quantumespresso.calculations.pw import PwCalculation\n",
    "\n",
    "PwTask = task(PwCalculation)\n",
    "qe_output = namespace(trajectory=TrajectoryData, parameters=Dict)\n",
    "\n",
    "@task.graph(\n",
    "    outputs=namespace(\n",
    "        test_file=dynamic(qe_output),\n",
    "        train_file=dynamic(qe_output),\n",
    "        valid_file=dynamic(qe_output),\n",
    "    )\n",
    ")\n",
    "def qe(\n",
    "    code: InstalledCode,\n",
    "    kpoints_mesh: List,\n",
    "    task_metadata: Dict,\n",
    "    test_file: SinglefileData,\n",
    "    train_file: SinglefileData,\n",
    "    valid_file: SinglefileData\n",
    "    ):\n",
    "\n",
    "    kpoints = KpointsData()\n",
    "    kpoints.set_kpoints_mesh(kpoints_mesh)\n",
    "\n",
    "    pseudo_family = load_group('SSSP/1.3/PBE/efficiency')\n",
    "    \n",
    "    files = {\"test_file\": test_file, \"train_file\": train_file, \"valid_file\": valid_file}\n",
    "    results = {\"test_file\": {}, \"train_file\": {}, \"valid_file\": {}}\n",
    "    \n",
    "    for file_name, file in files.items():\n",
    "        with file.as_path() as path:\n",
    "            for i, structs in enumerate(iread(path, format=\"extxyz\")):\n",
    "                \n",
    "                structure = StructureData(ase=structs)\n",
    "                pseudos = pseudo_family.get_pseudos(structure=structure)\n",
    "\n",
    "                ecutwfc, ecutrho = pseudo_family.get_recommended_cutoffs(\n",
    "                    structure=structure,\n",
    "                    unit='Ry',\n",
    "                )\n",
    "\n",
    "                pw_params = {\n",
    "                    \"CONTROL\": {\n",
    "                        \"calculation\": \"scf\",\n",
    "                        'tprnfor': True,\n",
    "                        'tstress': True,\n",
    "                    },\n",
    "                    \"SYSTEM\": {\n",
    "                        \"ecutwfc\": ecutwfc,\n",
    "                        \"ecutrho\": ecutrho,\n",
    "                    },\n",
    "                }\n",
    "                \n",
    "                qe_task = PwTask(\n",
    "                    code=code,\n",
    "                    parameters=pw_params,\n",
    "                    kpoints=kpoints,\n",
    "                    pseudos=pseudos,\n",
    "                    metadata=task_metadata.value,\n",
    "                    structure=structure,\n",
    "                )\n",
    "                \n",
    "                structfile = f\"{file_name}.struct{i}\"\n",
    "\n",
    "               \n",
    "                results[file_name][f\"struct_{i}\"] = {\n",
    "                    \"trajectory\": qe_task.output_trajectory,\n",
    "                    \"parameters\": qe_task.output_parameters,\n",
    "                }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcacee8",
   "metadata": {},
   "source": [
    "## Concept 3: CalcFunction Tasks\n",
    "\n",
    "The `@task.calcfunction` decorator wraps AiiDA calcfunctions - Python functions that:\n",
    "- Are tracked in the provenance graph\n",
    "- Have serializable inputs and outputs  \n",
    "- Can be restarted if they fail\n",
    "\n",
    "**WorkGraph Integration**: CalcFunction tasks can:\n",
    "- Receive dynamic outputs from upstream tasks (like the QE results)\n",
    "- Process complex nested data structures\n",
    "- Return AiiDA data types that flow to downstream tasks\n",
    "\n",
    "The `create_train_file` task receives the entire nested QE output structure and processes it, demonstrating how WorkGraph handles complex data flow between tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a430a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_mlip.data.config import JanusConfigfile\n",
    "from aiida.orm import Dict\n",
    "from ase.io import write\n",
    "from ase import units\n",
    "\n",
    "@task.calcfunction(outputs = [\"JanusConfigfile\"])\n",
    "def create_train_file(**inputs):\n",
    "\n",
    "    training_files = {}\n",
    "    \n",
    "    for file_name, structs in inputs.items():\n",
    "        path = Path(f\"mlip_{file_name}.extxyz\")\n",
    "\n",
    "        for struct_out_params in structs.values():\n",
    "            \n",
    "            trajectory = struct_out_params[\"trajectory\"]\n",
    "\n",
    "            fileStructure = trajectory.get_structure(index=0)\n",
    "            fileAtoms = fileStructure.get_ase()\n",
    "\n",
    "            stress = trajectory.arrays[\"stress\"][0]\n",
    "            converted_stress = stress * units.GPa\n",
    "            fileAtoms.info[\"qe_stress\"] = converted_stress\n",
    "\n",
    "            fileAtoms.info[\"units\"] = {\n",
    "                \"energy\": \"eV\",\n",
    "                \"forces\": \"ev/Ang\",\n",
    "                \"stress\": \"ev/Ang^3\"\n",
    "            }\n",
    "            fileAtoms.set_array(\"qe_forces\", trajectory.arrays[\"forces\"][0])\n",
    "\n",
    "            parameters = struct_out_params[\"parameters\"]\n",
    "            fileParams = parameters.get_dict()\n",
    "            fileAtoms.info[\"qe_energy\"] = fileParams[\"energy\"]\n",
    "            write(path, fileAtoms, append=True)\n",
    "\n",
    "        training_files[file_name] = str(path.resolve())\n",
    "\n",
    "    with open(\"JanusConfigfile.yml\", \"a\") as f:\n",
    "        yaml.safe_dump(training_files, f, sort_keys=False)\n",
    "\n",
    "    return{'JanusConfigfile': JanusConfigfile(Path(\"JanusConfigfile.yml\").resolve())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5766874",
   "metadata": {},
   "source": [
    "## Data Processing Tasks\n",
    "\n",
    "This calcfunction task demonstrates how WorkGraph handles data transformations between computational tasks. It takes dynamic outputs from the descriptor calculation and produces structured files for the next stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ac1993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import Int\n",
    "from sample_split import process_and_split_data\n",
    "\n",
    "@task.calcfunction(outputs = [\"test_file\", \"train_file\", \"valid_file\"])\n",
    "def create_qe_files(**inputs):\n",
    "\n",
    "    n_samples = Int(len(inputs['trajectory_data']))\n",
    "    print(n_samples)\n",
    "\n",
    "    files = process_and_split_data( \n",
    "        **inputs,\n",
    "        n_samples=n_samples,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"train_file\": SinglefileData(files[\"train_file\"]),\n",
    "        \"test_file\": SinglefileData(files[\"test_file\"]),\n",
    "        \"valid_file\": SinglefileData(files[\"valid_file\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff193a2",
   "metadata": {},
   "source": [
    "## Configure Input Parameters\n",
    "\n",
    "\n",
    "**NVT Ensemble**: \n",
    "- Maintains constant Number of particles, Volume, and Temperature\n",
    "- Suitable for sampling structural variations\n",
    "- Uses a thermostat to control temperature\n",
    "\n",
    "See https://stfc.github.io/janus-core/tutorials/cli/md.html for other ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1795dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import Str, Float, Bool, Dict\n",
    "inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cpu\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "    \"ensemble\": Str(\"NVT\"),\n",
    "    \"struct\": init_structure,\n",
    "    \"md_kwargs\": Dict(\n",
    "        {\n",
    "            \"steps\": 10,\n",
    "            \"traj-every\": 2\n",
    "        }\n",
    "    )\n",
    "}\n",
    "calc_inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cpu\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "}\n",
    "split_task_inputs = {\n",
    "    \"config_types\": Str(\"\"),\n",
    "    \"prefix\": Str(\"\"),\n",
    "    \"scale\": Float(1.0e5),\n",
    "    \"append_mode\": Bool(False),\n",
    "}\n",
    "qe_inputs = {\n",
    "    \"task_metadata\": Dict({\n",
    "            \"options\": {\n",
    "                \"resources\": {\n",
    "                    \"num_machines\": 1,\n",
    "                    \"num_mpiprocs_per_machine\": 32,\n",
    "                },\n",
    "                \"max_wallclock_seconds\": 3600,\n",
    "                \"queue_name\": \"scarf\",\n",
    "                \"qos\": \"scarf\",\n",
    "                \"environment_variables\": {},\n",
    "                \"withmpi\": True,\n",
    "                \"prepend_text\": \"\"\"\n",
    "                    module purge\n",
    "                    module use /work4/scd/scarf562/eb-common/modules/all\n",
    "                    module load amd-modules\n",
    "                    module load QuantumESPRESSO/7.2-foss-2023a\n",
    "                \"\"\",\n",
    "                \"append_text\": \"\",\n",
    "            },\n",
    "    }),\n",
    "    \"kpoints_mesh\": List([1, 1, 1]),\n",
    "    \"code\": qe_code,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0241edf",
   "metadata": {},
   "source": [
    "## Concept 4: Assembling the WorkGraph\n",
    "\n",
    "Now we combine all tasks into a single workflow. The `@task.graph()` decorator creates a top-level workflow function.\n",
    "\n",
    "### Key WorkGraph Features Demonstrated:\n",
    "\n",
    "1. **Task Creation**: Convert calculations to tasks\n",
    "   ```python\n",
    "   mdTask = task(mdCalc)\n",
    "   trainTask = task(trainCalc)\n",
    "   ```\n",
    "\n",
    "2. **Automatic Dependency Resolution**: WorkGraph analyzes the data flow:\n",
    "   - `md_calc` runs first (no dependencies)\n",
    "   - `descriptors_calc` waits for `md_calc.traj_file`\n",
    "   - `split_task` waits for `descriptors_calc.final_structs`\n",
    "   - `qe_task` waits for split outputs\n",
    "   - Tasks run in parallel when possible\n",
    "\n",
    "3. **Output Linking**: Connect task outputs to downstream inputs:\n",
    "   ```python\n",
    "   file=md_calc.traj_file  # Output from md_calc flows to descriptors_task\n",
    "   ```\n",
    "\n",
    "4. **Dynamic Data Flow**: The workflow handles:\n",
    "   - Variable numbers of structures from MD\n",
    "   - Dynamic descriptor calculations  \n",
    "   - Nested QE outputs\n",
    "   - All without knowing exact counts ahead of time\n",
    "\n",
    "5. **Execution Control**: WorkGraph manages:\n",
    "   - Local vs. remote execution\n",
    "   - Resource allocation\n",
    "   - Failure handling\n",
    "   - Provenance tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e82a4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdTask = task(mdCalc)\n",
    "trainTask = task(trainCalc)\n",
    "\n",
    "@task.graph()\n",
    "def md_training_workflow(\n",
    "    janus_code,\n",
    "    qe_code,\n",
    "    model,\n",
    "    md_kwargs,\n",
    "    ensemble,\n",
    "    init_structure,\n",
    "    split_inputs,\n",
    "    qe_metadata,\n",
    "    qe_kpoints,\n",
    "):\n",
    "    md_calc = mdTask(\n",
    "        code=janus_code,\n",
    "        model=model,\n",
    "        arch=Str(model.architecture),\n",
    "        device=Str(\"cpu\"),\n",
    "        metadata={\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "        ensemble=ensemble,\n",
    "        struct=init_structure,\n",
    "        md_kwargs=md_kwargs\n",
    "    )\n",
    "\n",
    "    descriptors_calc = descriptors_task(\n",
    "        code=janus_code,\n",
    "        model=model,\n",
    "        device=Str(\"cpu\"),\n",
    "        arch=Str(model.architecture),\n",
    "        file=md_calc.traj_file\n",
    "    )\n",
    "   \n",
    "    split_task = create_qe_files(\n",
    "        **split_inputs,\n",
    "        trajectory_data=descriptors_calc.final_structs,\n",
    "    )\n",
    "    \n",
    "    qe_task = qe(\n",
    "        code=qe_code,\n",
    "        kpoints_mesh=qe_kpoints,\n",
    "        task_metadata=qe_metadata,\n",
    "        test_file=split_task.test_file,\n",
    "        train_file=split_task.train_file,\n",
    "        valid_file=split_task.valid_file,\n",
    "    )\n",
    "\n",
    "    training_files = create_train_file(\n",
    "        test_file=qe_task.test_file,\n",
    "        train_file=qe_task.train_file,\n",
    "        valid_file=qe_task.valid_file,\n",
    "    )\n",
    "\n",
    "    train_task = trainTask(\n",
    "        mlip_config=training_files.JanusConfigfile,\n",
    "        code=janus_code,\n",
    "        foundation_model=model,\n",
    "        metadata={\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "        fine_tune=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b87291f",
   "metadata": {},
   "source": [
    "### Building the WorkGraph\n",
    "\n",
    "The `.build()` method:\n",
    "1. Creates the workflow instance\n",
    "2. Analyzes task dependencies\n",
    "3. Prepares for execution\n",
    "4. Returns a WorkGraph object you can inspect, visualize, or run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3683830",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = md_training_workflow.build(\n",
    "    janus_code=janus_code,\n",
    "    qe_code=qe_code,\n",
    "    model=model,\n",
    "    md_kwargs=inputs[\"md_kwargs\"],\n",
    "    ensemble=inputs[\"ensemble\"],\n",
    "    init_structure=init_structure,\n",
    "    split_inputs=split_task_inputs,\n",
    "    qe_metadata=qe_inputs[\"task_metadata\"],\n",
    "    qe_kpoints=qe_inputs[\"kpoints_mesh\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd843a",
   "metadata": {},
   "source": [
    "### Execution\n",
    "\n",
    "`wg.run()` submits the workflow. WorkGraph:\n",
    "- Executes tasks as their dependencies become available\n",
    "- Runs independent tasks in parallel\n",
    "- Handles local and remote execution\n",
    "- Stores all data in AiiDA's database\n",
    "- Tracks full provenance automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4394b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/24/2025 10:06:56 AM <916425> aiida.broker.rabbitmq: [WARNING] RabbitMQ v3.12.1 is not supported and will cause unexpected problems!\n",
      "12/24/2025 10:06:56 AM <916425> aiida.broker.rabbitmq: [WARNING] It can cause long-running workflows to crash and jobs to be submitted multiple times.\n",
      "12/24/2025 10:06:56 AM <916425> aiida.broker.rabbitmq: [WARNING] See https://github.com/aiidateam/aiida-core/wiki/RabbitMQ-version-to-use for details.\n",
      "12/24/2025 10:06:57 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|continue_workgraph]: tasks ready to run: MD\n",
      "12/24/2025 10:06:57 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qoj42292/.aiida/scratch/presto/e6/99/6657-765e-4311-bf7a-a6f8dec4d5ae md-summary.yml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/24/2025 10:07:13 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|update_task_state]: Task: MD, type: CALCJOB, finished.\n",
      "12/24/2025 10:07:15 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|continue_workgraph]: tasks ready to run: descriptors_task\n",
      "12/24/2025 10:07:17 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7555\n",
      "12/24/2025 10:07:18 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|continue_workgraph]: tasks ready to run: Descriptors,Descriptors1,Descriptors2,Descriptors3,Descriptors4,Descriptors5\n",
      "12/24/2025 10:07:21 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7560, 7565, 7570, 7575, 7580, 7585\n",
      "12/24/2025 10:07:58 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|update_task_state]: Task: Descriptors, type: CALCJOB, finished.\n",
      "12/24/2025 10:07:58 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "12/24/2025 10:07:58 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7565, 7570, 7575, 7580, 7585\n",
      "12/24/2025 10:08:00 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|update_task_state]: Task: Descriptors1, type: CALCJOB, finished.\n",
      "12/24/2025 10:08:00 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|update_task_state]: Task: Descriptors2, type: CALCJOB, finished.\n",
      "12/24/2025 10:08:01 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|update_task_state]: Task: Descriptors3, type: CALCJOB, finished.\n",
      "12/24/2025 10:08:01 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "12/24/2025 10:08:01 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7580, 7585\n",
      "12/24/2025 10:08:02 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|update_task_state]: Task: Descriptors4, type: CALCJOB, finished.\n",
      "12/24/2025 10:08:03 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|update_task_state]: Task: Descriptors5, type: CALCJOB, finished.\n",
      "12/24/2025 10:08:03 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "12/24/2025 10:08:03 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|finalize]: Finalize workgraph.\n",
      "12/24/2025 10:08:03 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|update_task_state]: Task: descriptors_task, type: GRAPH, finished.\n",
      "12/24/2025 10:08:04 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|continue_workgraph]: tasks ready to run: create_qe_files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uuid: da09e2c1-ac92-4b8d-8fea-a0db15725209 (unstored) value: 6\n",
      "create files: train_file=PosixPath('train.xyz'), valid_file=PosixPath('valid.xyz') and test_file=PosixPath('test.xyz')\n",
      "Processing: ('all', 'aiida'), 6 frames\n",
      "  ('all', 'aiida'): total=6, train_target=4,                     vt_target=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/fpsample/wrapper.py:98: UserWarning: k is too large, set to 6\n",
      "  warnings.warn(f\"k is too large, set to {n_pts}\")\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/fpsample/wrapper.py:98: UserWarning: k is too large, set to 2\n",
      "  warnings.warn(f\"k is too large, set to {n_pts}\")\n",
      "12/24/2025 10:08:05 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|update_task_state]: Task: create_qe_files, type: CALCFUNCTION, finished.\n",
      "12/24/2025 10:08:05 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|continue_workgraph]: tasks ready to run: qe\n",
      "12/24/2025 10:08:06 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7633\n",
      "12/24/2025 10:08:06 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|continue_workgraph]: tasks ready to run: PwCalculation,PwCalculation1,PwCalculation2,PwCalculation3,PwCalculation4,PwCalculation5\n",
      "12/24/2025 10:08:08 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7635, 7637, 7639, 7641, 7643, 7645\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:15: AiidaDeprecationWarning: The parse_xml.versions module is deprecated and will be removed in aiida-quantumespresso v5.0.\n",
      "Use get_schema_filepath() from parse_xml.parse instead.\n",
      "  from aiida_quantumespresso.parsers.parse_xml.versions import QeXmlVersion, get_xml_file_version\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/legacy.py:18: AiidaDeprecationWarning: This module has been deprecated and will be removed in aiida-quantumespresso v5.0.\n",
      "If you are seeing this warning, you will have to update your Quantum ESPRESSO version (v6.6 or above).\n",
      "  warnings.warn(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/legacy.py:27: AiidaDeprecationWarning: This module has been deprecated and will be removed in aiida-quantumespresso v5.0.\n",
      "If you are seeing this warning, you will have to update your Quantum ESPRESSO version (v6.6 or above).\n",
      "  warnings.warn(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:19: AiidaDeprecationWarning: The parse_xml.pw.parse module has been deprecated and will be removed in aiida-quantumespresso v5.0.\n",
      "Use parse_xml() from parse_xml.parse directly. Legacy XML format support will be dropped.\n",
      "  warnings.warn(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "12/24/2025 10:11:33 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|update_task_state]: Task: PwCalculation, type: CALCJOB, finished.\n",
      "12/24/2025 10:11:34 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|update_task_state]: Task: PwCalculation1, type: CALCJOB, finished.\n",
      "12/24/2025 10:11:34 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|update_task_state]: Task: PwCalculation2, type: CALCJOB, finished.\n",
      "12/24/2025 10:11:34 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|update_task_state]: Task: PwCalculation3, type: CALCJOB, finished.\n",
      "12/24/2025 10:11:34 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|update_task_state]: Task: PwCalculation4, type: CALCJOB, finished.\n",
      "12/24/2025 10:11:35 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|update_task_state]: Task: PwCalculation5, type: CALCJOB, finished.\n",
      "12/24/2025 10:11:35 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "12/24/2025 10:11:35 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|finalize]: Finalize workgraph.\n",
      "12/24/2025 10:11:35 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|update_task_state]: Task: qe, type: GRAPH, finished.\n",
      "12/24/2025 10:11:36 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|continue_workgraph]: tasks ready to run: create_train_file\n",
      "12/24/2025 10:11:38 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|update_task_state]: Task: create_train_file, type: CALCFUNCTION, finished.\n",
      "12/24/2025 10:11:38 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|continue_workgraph]: tasks ready to run: Train\n",
      "12/24/2025 10:11:38 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7679\n",
      "12/24/2025 10:12:11 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|update_task_state]: Task: Train, type: CALCJOB, finished.\n",
      "12/24/2025 10:12:11 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "12/24/2025 10:12:11 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|finalize]: Finalize workgraph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9639a",
   "metadata": {},
   "source": [
    "### Visualize the WorkGraph\n",
    "\n",
    "WorkGraph provides an interactive visualization showing:\n",
    "- All tasks and their types\n",
    "- Dependencies between tasks  \n",
    "- Execution status\n",
    "- Input/output connections\n",
    "\n",
    "This helps you understand the workflow structure and debug issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c6d0545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e75d7c139cd4a7e8a478db84e4cc86b",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "NodeGraphWidget(positions={'Train': [2261.4500000000003, 12]}, settings={'minimap': True}, states={'graph_inpu…"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ed58e",
   "metadata": {},
   "source": [
    "## Summary: What You Learned\n",
    "\n",
    "### WorkGraph Concepts:\n",
    "1. **Task Decorators**: `task()`, `@task.calcfunction`, `@task.graph` for different task types\n",
    "2. **Dynamic Outputs**: Creating tasks at runtime with `dynamic()`\n",
    "3. **Namespaces**: Organizing structured outputs with `namespace()`\n",
    "4. **Data Flow**: Linking task outputs to inputs automatically\n",
    "5. **Dependency Management**: WorkGraph automatically orders tasks based on data dependencies\n",
    "6. **Parallel Execution**: Independent tasks run simultaneously\n",
    "7. **Provenance**: Full tracking of all calculations and data\n",
    "\n",
    "### Workflow Results:\n",
    "- Fine-tuned MACE model\n",
    "- Training datasets with DFT labels\n",
    "- Complete AiiDA provenance for reproducibility\n",
    "\n",
    "### Next Steps:\n",
    "- Try modifying task parameters\n",
    "- Add new tasks to the workflow\n",
    "- Explore the AiiDA provenance graph\n",
    "- Create your own WorkGraph workflows!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiida-mlip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
