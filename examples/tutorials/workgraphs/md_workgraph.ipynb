{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c13c1dd7",
   "metadata": {},
   "source": [
    "# WorkGraph example to run Molecular Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81fa1b",
   "metadata": {},
   "source": [
    "## Aim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ecbb39",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to run a molecular dynamics simulation. As an example, we start with a salt crystal structure, run a molecular dynamics simulation on it that takes snapshots of the trajectory over time and then compute the descriptors on each structure snapshot. The workgraph uses a filtering function to split the resulting data into three files for training the machine learning model.\n",
    "The goal is to show how to run the descriptors on each snapshot of the MD sim. \n",
    "\n",
    "note to self: NVT keeps temp and vol constant, is this adequate? MD req. temp change?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bfb65e",
   "metadata": {},
   "source": [
    "Load the aiida profile, structure, model and code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79098139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profile<uuid='60b17659a9844c4bbd3bef8de0a8f417' name='presto'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aiida import load_profile\n",
    "load_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bc2cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_mlip.data.model import ModelData\n",
    "uri = \"https://github.com/stfc/janus-core/raw/main/tests/models/mace_mp_small.model\"\n",
    "model = ModelData.from_uri(uri, architecture=\"mace_mp\", cache_dir=\"mlips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a89ba5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import StructureData\n",
    "from ase.build import bulk\n",
    "from ase.io import read, iread\n",
    "\n",
    "# structure = StructureData(ase=read(\"Structures/qmof-ffeef76.cif\"))\n",
    "init_structure = StructureData(ase=bulk(\"NaCl\", \"rocksalt\", 5.63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae62816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import load_code\n",
    "janus_code = load_code(\"janus@localhost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1795dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import Str, Float, Bool, Int, Dict\n",
    "inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cpu\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "    \"ensemble\": Str(\"NVT\"),\n",
    "    \"struct\": init_structure,\n",
    "    \"md_kwargs\": Dict(\n",
    "        {\n",
    "            \"steps\": 10,\n",
    "            \"traj-every\": 2\n",
    "        }\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e4c78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.plugins import CalculationFactory\n",
    "\n",
    "mdCalc = CalculationFactory(\"mlip.md\")\n",
    "descriptorsCalc = CalculationFactory(\"mlip.descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36acd26d",
   "metadata": {},
   "source": [
    "Before setting up the work graph, we first configure the descriptors task to run on each trajectory snapshop so we create multiple tasks dynamically within the same task using `get_current_graph()`. This allows us to run descriptors for each structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f0b91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_workgraph import WorkGraph, task\n",
    "from aiida_workgraph.manager import get_current_graph\n",
    "\n",
    "@task.graph(outputs=[\"structs\"])\n",
    "def descriptors_task(\n",
    "    code,\n",
    "    model,\n",
    "    device,\n",
    "    arch,\n",
    "    file,\n",
    "):\n",
    "    descriptorsCalc = CalculationFactory(\"mlip.descriptors\")\n",
    "    wg = get_current_graph()\n",
    "    final_structures={}\n",
    "\n",
    "    with file.as_path() as path:\n",
    "        for i, structs in enumerate(iread(path)):\n",
    "            structure = StructureData(ase=structs)\n",
    "\n",
    "            desc_calc = wg.add_task(\n",
    "                descriptorsCalc,\n",
    "                code=code,\n",
    "                model=model,\n",
    "                device=device,\n",
    "                arch=arch,\n",
    "                struct=structure,\n",
    "                metadata={\"options\": {\"resources\": {\"num_machines\": 1}}}\n",
    "            )\n",
    "\n",
    "            final_structures[f\"structs{i}\"] = structs\n",
    "            #   final_structures[f\"structs{i}\"] = desc_calc.outputs.xyz_output\n",
    "\n",
    "    wg.update_ctx({\n",
    "        \"structs\":final_structures\n",
    "    })\n",
    "\n",
    "    return{\n",
    "        \"structs\": wg.ctx.structs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcacee8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af1f6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e82a4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "with WorkGraph(\"MD\") as wg:\n",
    "\n",
    "    md_calc = wg.add_task(\n",
    "        mdCalc,\n",
    "        name=\"md_calc\",\n",
    "        **inputs\n",
    "    )\n",
    "\n",
    "    descriptors_calc = wg.add_task(\n",
    "        descriptors_task,\n",
    "        code=janus_code,\n",
    "        model=model,\n",
    "        device=Str(\"cpu\"),\n",
    "        arch=Str(model.architecture),\n",
    "        file=md_calc.outputs.traj_file\n",
    "    )\n",
    "\n",
    "    split_task = wg.add_task(\n",
    "        create_split_files,\n",
    "        name=\"split_data\",\n",
    "        config_types=Str(\"\"),\n",
    "        prefix=Str(\"\"),\n",
    "        scale=Float(1.0e5),\n",
    "        append_mode=Bool(False),\n",
    "        trajectory_data=descriptors_calc.outputs.structs,  \n",
    "    )\n",
    "\n",
    "    # split_task = wg.add_task(\n",
    "    #     process_and_split_data,\n",
    "    #     config_types= Str(\"\"),\n",
    "    #     n_samples=Int(len(descriptors_calc.outputs.structs)),\n",
    "    #     prefix= Str(\"\"),\n",
    "    #     scale= Float(1.0e5),\n",
    "    #     append_mode= Bool(False),\n",
    "    #     # create_aiida_files, \n",
    "    #     # **split_task_inputs,\n",
    "    #     trajectory_data=descriptors_calc.outputs.structs,\n",
    "    #     # n_samples= Int(len(final_structures)),\n",
    "    # )\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4394b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/20/2025 02:43:47 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1813|WorkGraphEngine|continue_workgraph]: tasks ready to run: md_calc\n",
      "11/20/2025 02:43:47 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1813|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 1816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qoj42292/.aiida/scratch/presto/34/d1/9b86-1210-42a4-aa21-3e0cf7bf2dcc md-summary.yml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/20/2025 02:44:00 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1813|WorkGraphEngine|continue_workgraph]: tasks ready to run: descriptors_task\n",
      "11/20/2025 02:44:00 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1813|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 1833\n",
      "11/20/2025 02:44:01 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1833|WorkGraphEngine|continue_workgraph]: tasks ready to run: Descriptors,Descriptors1,Descriptors2,Descriptors3,Descriptors4,Descriptors5\n",
      "11/20/2025 02:44:02 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1833|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 1837, 1841, 1845, 1849, 1853, 1857\n",
      "11/20/2025 02:44:21 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1833|WorkGraphEngine|update_task_state]: Task: Descriptors3, type: CALCJOB, finished.\n",
      "11/20/2025 02:44:21 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1833|WorkGraphEngine|update_task_state]: Task: Descriptors4, type: CALCJOB, finished.\n",
      "11/20/2025 02:44:22 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1833|WorkGraphEngine|update_task_state]: Task: Descriptors5, type: CALCJOB, finished.\n",
      "11/20/2025 02:44:23 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1833|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "11/20/2025 02:44:23 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1833|WorkGraphEngine|finalize]: Finalize workgraph.\n",
      "11/20/2025 02:44:23 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1813|WorkGraphEngine|update_task_state]: Task: descriptors_task, type: GRAPH, finished.\n",
      "11/20/2025 02:44:23 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1813|WorkGraphEngine|continue_workgraph]: tasks ready to run: split_data\n",
      "11/20/2025 02:44:23 PM <56463> plumpy.processes: [ERROR] Error in task split_data: Error occurred validating port 'inputs.trajectory_data': required value was not provided for 'trajectory_data'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_workgraph/engine/task_manager.py\", line 202, in execute_function_task\n",
      "    process, _ = task.execute(args, kwargs, var_kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_workgraph/tasks/aiida.py\", line 33, in execute\n",
      "    _, process = run_get_node(executor, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/launch.py\", line 65, in run_get_node\n",
      "    return runner.run_get_node(process, inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/runners.py\", line 291, in run_get_node\n",
      "    result, node = self._run(process, inputs, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/runners.py\", line 241, in _run\n",
      "    result, node = process.run_get_node(**inputs)  # type: ignore[union-attr]\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/processes/functions.py\", line 225, in run_get_node\n",
      "    process: Process = process_class(inputs=inputs, runner=runner)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/base/state_machine.py\", line 205, in __call__\n",
      "    inst.transition_to(inst.create_initial_state())\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/base/state_machine.py\", line 357, in transition_to\n",
      "    self.transition_failed(initial_state_label, label, *sys.exc_info()[1:])\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/processes.py\", line 1095, in transition_failed\n",
      "    raise exception.with_traceback(trace)\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/base/state_machine.py\", line 343, in transition_to\n",
      "    self._enter_next_state(new_state)\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/base/state_machine.py\", line 410, in _enter_next_state\n",
      "    self._fire_state_event(StateEventHook.ENTERING_STATE, next_state)\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/base/state_machine.py\", line 311, in _fire_state_event\n",
      "    callback(self, hook, state)\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/processes.py\", line 358, in <lambda>\n",
      "    state_machine.StateEventHook.ENTERING_STATE: lambda _s, _h, state: self.on_entering(\n",
      "                                                                       ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/processes.py\", line 725, in on_entering\n",
      "    call_with_super_check(self.on_create)\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/base/utils.py\", line 31, in call_with_super_check\n",
      "    wrapped(*args, **kwargs)\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/engine/processes/process.py\", line 453, in on_create\n",
      "    super().on_create()\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/base/utils.py\", line 16, in wrapper\n",
      "    wrapped(self, *args, **kwargs)\n",
      "  File \"/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/plumpy/processes.py\", line 792, in on_create\n",
      "    raise ValueError(result)\n",
      "ValueError: Error occurred validating port 'inputs.trajectory_data': required value was not provided for 'trajectory_data'\n",
      "\n",
      "11/20/2025 02:44:23 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1813|WorkGraphEngine|on_task_failed]: Task, split_data, type: CALCFUNCTION, failed.\n",
      "11/20/2025 02:44:23 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1813|WorkGraphEngine|run_error_handlers]: Run error handlers for split_data\n",
      "11/20/2025 02:44:23 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1813|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "11/20/2025 02:44:23 PM <56463> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [1813|WorkGraphEngine|is_workgraph_finished]: WorkGraph finished, but tasks: ['split_data'] failed. Thus all their child tasks are skipped.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c6d0545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838421878a8b4a73baf623652c61dc80",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "NodeGraphWidget(settings={'minimap': True}, states={'graph_inputs': 'FINISHED', 'graph_outputs': 'FINISHED', 'â€¦"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fabb5db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3b99ef4",
   "metadata": {},
   "source": [
    "# Additional information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc4a0323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"_attrs\": {\n",
      "        \"default\": [],\n",
      "        \"dynamic\": false,\n",
      "        \"help\": null,\n",
      "        \"required\": \"True\",\n",
      "        \"valid_type\": \"<class 'aiida.orm.nodes.data.data.Data'>\"\n",
      "    },\n",
      "    \"arch\": {\n",
      "        \"help\": \"MLIP architecture to use for calculation\",\n",
      "        \"is_metadata\": \"False\",\n",
      "        \"name\": \"arch\",\n",
      "        \"non_db\": \"False\",\n",
      "        \"required\": \"False\",\n",
      "        \"valid_type\": \"(<class 'aiida.orm.nodes.data.str.Str'>, <class 'NoneType'>)\"\n",
      "    },\n",
      "    \"calc_kwargs\": {\n",
      "        \"help\": \"Keyword arguments to pass to selected calculator.\",\n",
      "        \"is_metadata\": \"False\",\n",
      "        \"name\": \"calc_kwargs\",\n",
      "        \"non_db\": \"False\",\n",
      "        \"required\": \"False\",\n",
      "        \"valid_type\": \"(<class 'aiida.orm.nodes.data.dict.Dict'>, <class 'NoneType'>)\"\n",
      "    },\n",
      "    \"calc_per_atom\": {\n",
      "        \"help\": \"Calculate descriptors for each atom.\",\n",
      "        \"is_metadata\": \"False\",\n",
      "        \"name\": \"calc_per_atom\",\n",
      "        \"non_db\": \"False\",\n",
      "        \"required\": \"False\",\n",
      "        \"valid_type\": \"(<class 'aiida.orm.nodes.data.bool.Bool'>, <class 'NoneType'>)\"\n",
      "    },\n",
      "    \"calc_per_element\": {\n",
      "        \"help\": \"Calculate mean descriptors for each element.\",\n",
      "        \"is_metadata\": \"False\",\n",
      "        \"name\": \"calc_per_element\",\n",
      "        \"non_db\": \"False\",\n",
      "        \"required\": \"False\",\n",
      "        \"valid_type\": \"(<class 'aiida.orm.nodes.data.bool.Bool'>, <class 'NoneType'>)\"\n",
      "    },\n",
      "    \"code\": {\n",
      "        \"help\": \"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run.\",\n",
      "        \"is_metadata\": \"False\",\n",
      "        \"name\": \"code\",\n",
      "        \"non_db\": \"False\",\n",
      "        \"required\": \"False\",\n",
      "        \"valid_type\": \"(<class 'aiida.orm.nodes.data.code.abstract.AbstractCode'>, <class 'NoneType'>)\"\n",
      "    },\n",
      "    \"config\": {\n",
      "        \"help\": \"Name of the log output file\",\n",
      "        \"is_metadata\": \"False\",\n",
      "        \"name\": \"config\",\n",
      "        \"non_db\": \"False\",\n",
      "        \"required\": \"False\",\n",
      "        \"valid_type\": \"(<class 'aiida_mlip.data.config.JanusConfigfile'>, <class 'NoneType'>)\"\n",
      "    },\n",
      "    \"device\": {\n",
      "        \"help\": \"Device on which to run calculation (cpu, cuda or mps)\",\n",
      "        \"is_metadata\": \"False\",\n",
      "        \"name\": \"device\",\n",
      "        \"non_db\": \"False\",\n",
      "        \"required\": \"False\",\n",
      "        \"valid_type\": \"(<class 'aiida.orm.nodes.data.str.Str'>, <class 'NoneType'>)\"\n",
      "    },\n",
      "    \"invariants_only\": {\n",
      "        \"help\": \"Only calculate invariant descriptors.\",\n",
      "        \"is_metadata\": \"False\",\n",
      "        \"name\": \"invariants_only\",\n",
      "        \"non_db\": \"False\",\n",
      "        \"required\": \"False\",\n",
      "        \"valid_type\": \"(<class 'aiida.orm.nodes.data.bool.Bool'>, <class 'NoneType'>)\"\n",
      "    },\n",
      "    \"log_filename\": {\n",
      "        \"default\": \"<function BaseJanus.define.<locals>.<lambda> at 0x7f42569f27a0>\",\n",
      "        \"help\": \"Name of the log output file\",\n",
      "        \"is_metadata\": \"False\",\n",
      "        \"name\": \"log_filename\",\n",
      "        \"non_db\": \"False\",\n",
      "        \"required\": \"False\",\n",
      "        \"valid_type\": \"(<class 'aiida.orm.nodes.data.str.Str'>, <class 'NoneType'>)\"\n",
      "    },\n",
      "    \"metadata\": {\n",
      "        \"_attrs\": {\n",
      "            \"default\": [],\n",
      "            \"dynamic\": false,\n",
      "            \"help\": null,\n",
      "            \"required\": \"False\",\n",
      "            \"valid_type\": \"None\"\n",
      "        },\n",
      "        \"call_link_label\": {\n",
      "            \"default\": \"CALL\",\n",
      "            \"help\": \"The label to use for the `CALL` link if the process is called by another process.\",\n",
      "            \"is_metadata\": \"True\",\n",
      "            \"name\": \"call_link_label\",\n",
      "            \"non_db\": \"False\",\n",
      "            \"required\": \"False\",\n",
      "            \"valid_type\": \"<class 'str'>\"\n",
      "        },\n",
      "        \"computer\": {\n",
      "            \"help\": \"When using a \\\"local\\\" code, set the computer on which the calculation should be run.\",\n",
      "            \"is_metadata\": \"True\",\n",
      "            \"name\": \"computer\",\n",
      "            \"non_db\": \"False\",\n",
      "            \"required\": \"False\",\n",
      "            \"valid_type\": \"(<class 'aiida.orm.computers.Computer'>, <class 'NoneType'>)\"\n",
      "        },\n",
      "        \"description\": {\n",
      "            \"help\": \"Description to set on the process node.\",\n",
      "            \"is_metadata\": \"True\",\n",
      "            \"name\": \"description\",\n",
      "            \"non_db\": \"False\",\n",
      "            \"required\": \"False\",\n",
      "            \"valid_type\": \"(<class 'str'>, <class 'NoneType'>)\"\n",
      "        },\n",
      "        \"disable_cache\": {\n",
      "            \"help\": \"Do not consider the cache for this process, ignoring all other caching configuration rules.\",\n",
      "            \"is_metadata\": \"True\",\n",
      "            \"name\": \"disable_cache\",\n",
      "            \"non_db\": \"False\",\n",
      "            \"required\": \"False\",\n",
      "            \"valid_type\": \"(<class 'bool'>, <class 'NoneType'>)\"\n",
      "        },\n",
      "        \"dry_run\": {\n",
      "            \"default\": \"False\",\n",
      "            \"help\": \"When set to `True` will prepare the calculation job for submission but not actually launch it.\",\n",
      "            \"is_metadata\": \"True\",\n",
      "            \"name\": \"dry_run\",\n",
      "            \"non_db\": \"False\",\n",
      "            \"required\": \"False\",\n",
      "            \"valid_type\": \"<class 'bool'>\"\n",
      "        },\n",
      "        \"label\": {\n",
      "            \"help\": \"Label to set on the process node.\",\n",
      "            \"is_metadata\": \"True\",\n",
      "            \"name\": \"label\",\n",
      "            \"non_db\": \"False\",\n",
      "            \"required\": \"False\",\n",
      "            \"valid_type\": \"(<class 'str'>, <class 'NoneType'>)\"\n",
      "        },\n",
      "        \"options\": {\n",
      "            \"_attrs\": {\n",
      "                \"default\": [],\n",
      "                \"dynamic\": false,\n",
      "                \"help\": null,\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"None\"\n",
      "            },\n",
      "            \"account\": {\n",
      "                \"help\": \"Set the account to use in for the queue on the remote computer\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"account\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"(<class 'str'>, <class 'NoneType'>)\"\n",
      "            },\n",
      "            \"additional_retrieve_list\": {\n",
      "                \"help\": \"List of relative file paths that should be retrieved in addition to what the plugin specifies.\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"additional_retrieve_list\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"(<class 'list'>, <class 'tuple'>, <class 'NoneType'>)\"\n",
      "            },\n",
      "            \"append_text\": {\n",
      "                \"default\": \"\",\n",
      "                \"help\": \"Set the calculation-specific append text, which is going to be appended in the scheduler-job script, just after the code execution\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"append_text\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"<class 'str'>\"\n",
      "            },\n",
      "            \"custom_scheduler_commands\": {\n",
      "                \"default\": \"\",\n",
      "                \"help\": \"Set a (possibly multiline) string with the commands that the user wants to manually set for the scheduler. The difference of this option with respect to the `prepend_text` is the position in the scheduler submission file where such text is inserted: with this option, the string is inserted before any non-scheduler command\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"custom_scheduler_commands\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"<class 'str'>\"\n",
      "            },\n",
      "            \"environment_variables\": {\n",
      "                \"default\": \"<function CalcJob.define.<locals>.<lambda> at 0x7f42569f2a20>\",\n",
      "                \"help\": \"Set a dictionary of custom environment variables for this calculation\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"environment_variables\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"<class 'dict'>\"\n",
      "            },\n",
      "            \"environment_variables_double_quotes\": {\n",
      "                \"default\": \"False\",\n",
      "                \"help\": \"If set to True, use double quotes instead of single quotes to escape the environment variables specified in ``environment_variables``.\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"environment_variables_double_quotes\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"<class 'bool'>\"\n",
      "            },\n",
      "            \"import_sys_environment\": {\n",
      "                \"default\": \"True\",\n",
      "                \"help\": \"If set to true, the submission script will load the system environment variables\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"import_sys_environment\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"<class 'bool'>\"\n",
      "            },\n",
      "            \"input_filename\": {\n",
      "                \"default\": \"aiida.xyz\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"input_filename\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"<class 'str'>\"\n",
      "            },\n",
      "            \"max_memory_kb\": {\n",
      "                \"help\": \"Set the maximum memory (in KiloBytes) to be asked to the scheduler\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"max_memory_kb\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"(<class 'int'>, <class 'NoneType'>)\"\n",
      "            },\n",
      "            \"max_wallclock_seconds\": {\n",
      "                \"help\": \"Set the wallclock in seconds asked to the scheduler\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"max_wallclock_seconds\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"(<class 'int'>, <class 'NoneType'>)\"\n",
      "            },\n",
      "            \"mpirun_extra_params\": {\n",
      "                \"default\": \"<function CalcJob.define.<locals>.<lambda> at 0x7f4256e21620>\",\n",
      "                \"help\": \"Set the extra params to pass to the mpirun (or equivalent) command after the one provided in computer.mpirun_command. Example: mpirun -np 8 extra_params[0] extra_params[1] ... exec.x\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"mpirun_extra_params\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"(<class 'list'>, <class 'tuple'>)\"\n",
      "            },\n",
      "            \"output_filename\": {\n",
      "                \"default\": \"aiida-stdout.txt\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"output_filename\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"<class 'str'>\"\n",
      "            },\n",
      "            \"parser_name\": {\n",
      "                \"default\": \"mlip.descriptors_parser\",\n",
      "                \"help\": \"Set a string for the output parser. Can be None if no output plugin is available or needed\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"parser_name\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"(<class 'str'>, <class 'NoneType'>)\"\n",
      "            },\n",
      "            \"prepend_text\": {\n",
      "                \"default\": \"\",\n",
      "                \"help\": \"Set the calculation-specific prepend text, which is going to be prepended in the scheduler-job script, just before the code execution\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"prepend_text\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"<class 'str'>\"\n",
      "            },\n",
      "            \"priority\": {\n",
      "                \"help\": \"Set the priority of the job to be queued\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"priority\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"(<class 'str'>, <class 'NoneType'>)\"\n",
      "            },\n",
      "            \"qos\": {\n",
      "                \"help\": \"Set the quality of service to use in for the queue on the remote computer\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"qos\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"(<class 'str'>, <class 'NoneType'>)\"\n",
      "            },\n",
      "            \"queue_name\": {\n",
      "                \"help\": \"Set the name of the queue on the remote computer\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"queue_name\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"(<class 'str'>, <class 'NoneType'>)\"\n",
      "            },\n",
      "            \"rerunnable\": {\n",
      "                \"help\": \"Determines if the calculation can be requeued / rerun.\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"rerunnable\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"(<class 'bool'>, <class 'NoneType'>)\"\n",
      "            },\n",
      "            \"resources\": {\n",
      "                \"help\": \"Set the dictionary of resources to be used by the scheduler plugin, like the number of nodes, cpus etc. This dictionary is scheduler-plugin dependent. Look at the documentation of the scheduler for more details.\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"resources\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"True\",\n",
      "                \"valid_type\": \"<class 'dict'>\"\n",
      "            },\n",
      "            \"scheduler_stderr\": {\n",
      "                \"default\": \"_scheduler-stderr.txt\",\n",
      "                \"help\": \"Filename to which the content of stderr of the scheduler is written.\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"scheduler_stderr\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"<class 'str'>\"\n",
      "            },\n",
      "            \"scheduler_stdout\": {\n",
      "                \"default\": \"_scheduler-stdout.txt\",\n",
      "                \"help\": \"Filename to which the content of stdout of the scheduler is written.\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"scheduler_stdout\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"<class 'str'>\"\n",
      "            },\n",
      "            \"stash\": {\n",
      "                \"_attrs\": {\n",
      "                    \"default\": [],\n",
      "                    \"dynamic\": false,\n",
      "                    \"help\": \"Optional directives to stash files after the calculation job has completed.\",\n",
      "                    \"required\": \"False\",\n",
      "                    \"valid_type\": \"None\"\n",
      "                },\n",
      "                \"dereference\": {\n",
      "                    \"help\": \"Whether to follow symlinks while stashing or not, specific to StashMode.COMPRESS_* enums\",\n",
      "                    \"is_metadata\": \"True\",\n",
      "                    \"name\": \"dereference\",\n",
      "                    \"non_db\": \"False\",\n",
      "                    \"required\": \"False\",\n",
      "                    \"valid_type\": \"(<class 'bool'>, <class 'NoneType'>)\"\n",
      "                },\n",
      "                \"source_list\": {\n",
      "                    \"help\": \"Sequence of relative filepaths representing files in the remote directory that should be stashed.\",\n",
      "                    \"is_metadata\": \"True\",\n",
      "                    \"name\": \"source_list\",\n",
      "                    \"non_db\": \"False\",\n",
      "                    \"required\": \"False\",\n",
      "                    \"valid_type\": \"(<class 'tuple'>, <class 'list'>, <class 'NoneType'>)\"\n",
      "                },\n",
      "                \"stash_mode\": {\n",
      "                    \"help\": \"Mode with which to perform the stashing, should be value of `aiida.common.datastructures.StashMode`.\",\n",
      "                    \"is_metadata\": \"True\",\n",
      "                    \"name\": \"stash_mode\",\n",
      "                    \"non_db\": \"False\",\n",
      "                    \"required\": \"False\",\n",
      "                    \"valid_type\": \"(<class 'str'>, <class 'NoneType'>)\"\n",
      "                },\n",
      "                \"target_base\": {\n",
      "                    \"help\": \"The base location to where the files should be stashd. For example, for the `copy` stash mode, this should be an absolute filepath on the remote computer.\",\n",
      "                    \"is_metadata\": \"True\",\n",
      "                    \"name\": \"target_base\",\n",
      "                    \"non_db\": \"False\",\n",
      "                    \"required\": \"False\",\n",
      "                    \"valid_type\": \"(<class 'str'>, <class 'NoneType'>)\"\n",
      "                }\n",
      "            },\n",
      "            \"submit_script_filename\": {\n",
      "                \"default\": \"_aiidasubmit.sh\",\n",
      "                \"help\": \"Filename to which the job submission script is written.\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"submit_script_filename\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"<class 'str'>\"\n",
      "            },\n",
      "            \"withmpi\": {\n",
      "                \"help\": \"Set the calculation to use mpi\",\n",
      "                \"is_metadata\": \"True\",\n",
      "                \"name\": \"withmpi\",\n",
      "                \"non_db\": \"False\",\n",
      "                \"required\": \"False\",\n",
      "                \"valid_type\": \"(<class 'bool'>, <class 'NoneType'>)\"\n",
      "            }\n",
      "        },\n",
      "        \"store_provenance\": {\n",
      "            \"default\": \"True\",\n",
      "            \"help\": \"If set to `False` provenance will not be stored in the database.\",\n",
      "            \"is_metadata\": \"True\",\n",
      "            \"name\": \"store_provenance\",\n",
      "            \"non_db\": \"False\",\n",
      "            \"required\": \"False\",\n",
      "            \"valid_type\": \"<class 'bool'>\"\n",
      "        }\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"help\": \"MLIP model used for calculation\",\n",
      "        \"is_metadata\": \"False\",\n",
      "        \"name\": \"model\",\n",
      "        \"non_db\": \"False\",\n",
      "        \"required\": \"False\",\n",
      "        \"valid_type\": \"(<class 'aiida_mlip.data.model.ModelData'>, <class 'NoneType'>)\"\n",
      "    },\n",
      "    \"monitors\": {\n",
      "        \"_attrs\": {\n",
      "            \"default\": [],\n",
      "            \"dynamic\": true,\n",
      "            \"help\": \"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job.\",\n",
      "            \"required\": \"False\",\n",
      "            \"valid_type\": \"<class 'aiida.orm.nodes.data.dict.Dict'>\"\n",
      "        }\n",
      "    },\n",
      "    \"out\": {\n",
      "        \"default\": \"<function Singlepoint.define.<locals>.<lambda> at 0x7f42569f2fc0>\",\n",
      "        \"help\": \"Name of the xyz output file\",\n",
      "        \"is_metadata\": \"False\",\n",
      "        \"name\": \"out\",\n",
      "        \"non_db\": \"False\",\n",
      "        \"required\": \"False\",\n",
      "        \"valid_type\": \"(<class 'aiida.orm.nodes.data.str.Str'>, <class 'NoneType'>)\"\n",
      "    },\n",
      "    \"remote_folder\": {\n",
      "        \"help\": \"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual.\",\n",
      "        \"is_metadata\": \"False\",\n",
      "        \"name\": \"remote_folder\",\n",
      "        \"non_db\": \"False\",\n",
      "        \"required\": \"False\",\n",
      "        \"valid_type\": \"(<class 'aiida.orm.nodes.data.remote.base.RemoteData'>, <class 'NoneType'>)\"\n",
      "    },\n",
      "    \"struct\": {\n",
      "        \"help\": \"The input structure.\",\n",
      "        \"is_metadata\": \"False\",\n",
      "        \"name\": \"struct\",\n",
      "        \"non_db\": \"False\",\n",
      "        \"required\": \"False\",\n",
      "        \"valid_type\": \"(<class 'aiida.orm.nodes.data.structure.StructureData'>, <class 'NoneType'>)\"\n",
      "    },\n",
      "    \"summary\": {\n",
      "        \"default\": \"<function BaseJanus.define.<locals>.<lambda> at 0x7f42569f2660>\",\n",
      "        \"help\": \"Name of the summary output file\",\n",
      "        \"is_metadata\": \"False\",\n",
      "        \"name\": \"summary\",\n",
      "        \"non_db\": \"False\",\n",
      "        \"required\": \"False\",\n",
      "        \"valid_type\": \"(<class 'aiida.orm.nodes.data.str.Str'>, <class 'NoneType'>)\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(descriptorsCalc.spec().inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79e7ebbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'aiida.orm.nodes.data.singlefile.SinglefileData'>\n"
     ]
    }
   ],
   "source": [
    "print(type(wg.tasks.md_calc.outputs.traj_file.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "06aa6a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_attrs', 'remote_folder', 'remote_stash', 'retrieved', 'std_output', 'log_output', 'results_dict', 'summary', 'stats_file', 'traj_file', 'traj_output', 'final_structure'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdCalc.get_description()[\"spec\"][\"outputs\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc9180ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs of mdCalc: TaskSocketNamespace(name='outputs', sockets=['remote_folder', 'remote_stash', 'retrieved', 'std_output', 'log_output', 'results_dict', 'summary', 'stats_file', 'traj_file', 'traj_output', 'final_structure', '_outputs', '_wait'])\n"
     ]
    }
   ],
   "source": [
    "print('outputs of mdCalc:', md_calc.outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "54c34e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'aiida.orm.nodes.data.singlefile.SinglefileData'>\n"
     ]
    }
   ],
   "source": [
    "print(type(wg.tasks.md_calc.outputs.traj_file.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af828b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs of descriptors_task: TaskSocketNamespace(name='outputs', sockets=['structs', '_outputs', '_wait'])\n"
     ]
    }
   ],
   "source": [
    "print('outputs of descriptors_task:', descriptors_calc.outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62f8322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find inputs/outputs of mdcalc uncomment following: \n",
    "# mdCalc.get_description()[\"spec\"][\"outputs\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "758cd14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aiida.orm import load_node\n",
    "# traj = load_node(PK) \n",
    "\n",
    "# # print(len(list(iread(wg.tasks.md_calc.outputs.traj_file.value.as_path()))))\n",
    "# traj_length = (wg.tasks.md_calc.outputs.traj_file.value.as_path()).numsteps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf1c398",
   "metadata": {},
   "source": [
    "# Loop Descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4b63e5",
   "metadata": {},
   "source": [
    " the workflow does not have an output yet for wg.tasks.md.outputs.traj_file \n",
    "\n",
    " usually you can just pass in a socket. But because we have to get the path to read it you have to create a task\n",
    " \n",
    " you need to create a task which waites for md_task to run and then gets that output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8e7371",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fe8d0a7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0772c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sample_split import process_and_split_data\n",
    "# # @task.calcfunction(outputs = [\"test_file\", \"train_file\", \"valid_file\"])\n",
    "# # def create_split_files(**inputs):\n",
    "     \n",
    "# #     files = process_and_split_data(**inputs)\n",
    "\n",
    "# #     return {\n",
    "# #         \"train_file\": SinglefileData(files[\"train_file\"]),\n",
    "# #         \"test_file\": SinglefileData(files[\"test_file\"]),\n",
    "# #         \"valid_file\": SinglefileData(files[\"valid_file\"])\n",
    "# #     }\n",
    "\n",
    "# @task.calcfunction(outputs=[\"test_file\", \"train_file\", \"valid_file\"])\n",
    "# def create_split_files(trajectory_data, config_types, prefix, scale, append_mode):\n",
    "#     \"\"\"Create split files using plain Python function call\"\"\"\n",
    "    \n",
    "#     # Call the plain Python function directly (not as a task) ??\n",
    "#     files = process_and_split_data(\n",
    "#         trajectory_data=trajectory_data,\n",
    "#         config_types=config_types,\n",
    "#         prefix=prefix,\n",
    "#         scale=scale,\n",
    "#         append_mode=append_mode\n",
    "#     )\n",
    "    \n",
    "#     return {\n",
    "#         \"train_file\": SinglefileData(files[\"train_file\"]),\n",
    "#         \"test_file\": SinglefileData(files[\"test_file\"]),\n",
    "#         \"valid_file\": SinglefileData(files[\"valid_file\"])\n",
    "#     }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiida-mlip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
