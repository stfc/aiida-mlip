{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c13c1dd7",
   "metadata": {},
   "source": [
    "# WorkGraph example to run Molecular Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81fa1b",
   "metadata": {},
   "source": [
    "## Aim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ecbb39",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to run a molecular dynamics simulation. As an example, we start with a salt crystal structure, run a molecular dynamics simulation on it that takes snapshots of the trajectory over time and then compute the descriptors on each structure snapshot. The workgraph uses a filtering function to split the resulting data into three files for training the machine learning model.\n",
    "The goal is to show how to run the descriptors on each snapshot of the MD sim. \n",
    "\n",
    "note to self: NVT keeps temp and vol constant, is this adequate? MD req. temp change?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bfb65e",
   "metadata": {},
   "source": [
    "Load the aiida profile, structure, model and code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79098139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida import load_profile\n",
    "load_profile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef36ae",
   "metadata": {},
   "source": [
    "Check that you have the pseudopotential files from the SSSP library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716ecb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import load_group\n",
    "try:\n",
    "    pseudo_family = load_group('SSSP/1.3/PBE/efficiency')\n",
    "    print(f\"✅ SSSP pseudopotentials installed ({len(pseudo_family.nodes)} pseudos)\")\n",
    "except Exception:\n",
    "    print(\"❌ SSSP not installed, Run: aiida-pseudo install sssp -v 1.3 -p efficiency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_mlip.data.model import ModelData\n",
    "uri = \"https://github.com/stfc/janus-core/raw/main/tests/models/mace_mp_small.model\"\n",
    "model = ModelData.from_uri(uri, architecture=\"mace_mp\", cache_dir=\"mlips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89ba5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import StructureData\n",
    "from ase.build import bulk\n",
    "from ase.io import read, iread\n",
    "\n",
    "# structure = StructureData(ase=read(\"Structures/qmof-ffeef76.cif\"))\n",
    "init_structure = StructureData(ase=bulk(\"NaCl\", \"rocksalt\", 5.63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import load_code\n",
    "janus_code = load_code(\"janus@localhost\")\n",
    "qe_code = load_code(\"qe@scarf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f240333a",
   "metadata": {},
   "source": [
    "We initialize the inputs we want for all the calculations. These variables can be changed depending on the configuration you are running and whether you want to change any inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.plugins import CalculationFactory\n",
    "\n",
    "mdCalc = CalculationFactory(\"mlip.md\")\n",
    "descriptorsCalc = CalculationFactory(\"mlip.descriptors\")\n",
    "trainCalc = CalculationFactory(\"mlip.train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36acd26d",
   "metadata": {},
   "source": [
    "configure the descriptors task to run on each trajectory snapshop so we create multiple tasks dynamically within the same task using `get_current_graph()`. This allows us to run descriptors for each structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_workgraph import WorkGraph, task\n",
    "from aiida_workgraph.manager import get_current_graph\n",
    "\n",
    "@task.graph(outputs = [\"final_structs\"])\n",
    "def descriptors_task(\n",
    "    code,\n",
    "    model,\n",
    "    device,\n",
    "    arch,\n",
    "    file,\n",
    "):\n",
    "    descriptorsCalc = CalculationFactory(\"mlip.descriptors\")\n",
    "    wg = get_current_graph()\n",
    "    final_structures={}\n",
    "    \n",
    "    with file.as_path() as path:\n",
    "        for i, structs in enumerate(iread(path)):\n",
    "            structure = StructureData(ase=structs)\n",
    "\n",
    "            desc_calc = wg.add_task(\n",
    "                descriptorsCalc,\n",
    "                code=code,\n",
    "                model=model,\n",
    "                device=device,\n",
    "                arch=arch,\n",
    "                struct=structure,\n",
    "                calc_per_element=bool(True), # per element descriptors ie. mace Na and Cl\n",
    "                metadata={\"options\": {\"resources\": {\"num_machines\": 1}}}\n",
    "            )\n",
    "\n",
    "            structfile = f\"final_structs.struct{i}\"\n",
    "            #   final_structures[f\"structs{i}\"] = desc_calc.outputs.xyz_output\n",
    "            wg.update_ctx({\n",
    "                structfile : desc_calc.outputs.xyz_output,\n",
    "            })\n",
    "\n",
    "    \n",
    "    n_samp = len(final_structures)\n",
    "    return {\n",
    "        \"final_structs\": wg.ctx.final_structs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ecc71",
   "metadata": {},
   "source": [
    "configure the `Quantum Espresso (QE)` task by defining the code and input parameters. Since we need to run QE on multiple structures, we create multiple `PwCalculation` tasks dynamically within the same task using `get_current_graph()`. This allows us to run QE for each structure and return the corresponding `TrajectoryData` and parameters for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_workgraph import task\n",
    "from aiida_workgraph.manager import get_current_graph\n",
    "from aiida.orm import StructureData, load_group, KpointsData, SinglefileData, InstalledCode, List, Dict\n",
    "from ase.io import iread\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from aiida_quantumespresso.calculations.pw import PwCalculation\n",
    "from sample_split import process_and_split_data\n",
    "\n",
    "\n",
    "@task.graph(outputs = [\"test_file\", \"train_file\", \"valid_file\"])\n",
    "def qe(\n",
    "    code: InstalledCode,\n",
    "    kpoints_mesh: List,\n",
    "    task_metadata: Dict,\n",
    "    test_file: SinglefileData,\n",
    "    train_file: SinglefileData,\n",
    "    valid_file: SinglefileData\n",
    "    ):\n",
    "\n",
    "    wg = get_current_graph()\n",
    "\n",
    "    kpoints = KpointsData()\n",
    "    kpoints.set_kpoints_mesh(kpoints_mesh)\n",
    "\n",
    "    pseudo_family = load_group('SSSP/1.3/PBE/efficiency')\n",
    "    \n",
    "    files = {\"test_file\": test_file, \"train_file\": train_file, \"valid_file\": valid_file}\n",
    "\n",
    "    for file_name, file in files.items():\n",
    "        with file.as_path() as path:\n",
    "            for i, structs in enumerate(iread(path, format=\"extxyz\")):\n",
    "                \n",
    "                structure = StructureData(ase=structs)\n",
    "                pseudos = pseudo_family.get_pseudos(structure=structure)\n",
    "\n",
    "                ecutwfc, ecutrho = pseudo_family.get_recommended_cutoffs(\n",
    "                    structure=structure,\n",
    "                    unit='Ry',\n",
    "                )\n",
    "\n",
    "                pw_params = {\n",
    "                    \"CONTROL\": {\n",
    "                        \"calculation\": \"scf\",\n",
    "                        'tprnfor': True,\n",
    "                        'tstress': True,\n",
    "                    },\n",
    "                    \"SYSTEM\": {\n",
    "                        \"ecutwfc\": ecutwfc,\n",
    "                        \"ecutrho\": ecutrho,\n",
    "                    },\n",
    "                }\n",
    "                \n",
    "                qe_task = wg.add_task(\n",
    "                    PwCalculation,\n",
    "                    code=code,\n",
    "                    parameters=pw_params,\n",
    "                    kpoints=kpoints,\n",
    "                    pseudos=pseudos,\n",
    "                    metadata=task_metadata.value,\n",
    "                    structure=structure,\n",
    "                )\n",
    "                \n",
    "                structfile = f\"{file_name}.struct{i}\"\n",
    "\n",
    "                wg.update_ctx({\n",
    "                    structfile:{\n",
    "                        \"trajectory\":qe_task.outputs.output_trajectory,\n",
    "                        \"parameters\": qe_task.outputs.output_parameters\n",
    "                    }\n",
    "                })\n",
    "\n",
    "    return {\n",
    "        \"test_file\": wg.ctx.test_file,\n",
    "        \"train_file\": wg.ctx.train_file,\n",
    "        \"valid_file\": wg.ctx.valid_file\n",
    "    }    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcacee8",
   "metadata": {},
   "source": [
    "The next task we need is a function which can extract the required parameters from the QE tasks and create the files for training. This task creates `mlip_[file]_file.extxyz`, adds the filepath to the example `JanusConfigfile.yml` that we provide. This file sets all of the inputs for fine-tuning, so should be modified according to your needs. Finally, the task returns a `JanusConfigfile` object which is used for the training calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_mlip.data.config import JanusConfigfile\n",
    "from aiida.orm import Dict\n",
    "from ase.io import write\n",
    "from ase import units\n",
    "\n",
    "@task.calcfunction(outputs = [\"JanusConfigfile\"])\n",
    "def create_train_file(**inputs):\n",
    "\n",
    "    training_files = {}\n",
    "    \n",
    "    for file_name, structs in inputs.items():\n",
    "        path = Path(f\"mlip_{file_name}.extxyz\")\n",
    "\n",
    "        for struct_out_params in structs.values():\n",
    "            \n",
    "            trajectory = struct_out_params[\"trajectory\"]\n",
    "\n",
    "            fileStructure = trajectory.get_structure(index=0)\n",
    "            fileAtoms = fileStructure.get_ase()\n",
    "\n",
    "            stress = trajectory.arrays[\"stress\"][0]\n",
    "            converted_stress = stress * units.GPa\n",
    "            fileAtoms.info[\"qe_stress\"] = converted_stress\n",
    "\n",
    "            fileAtoms.info[\"units\"] = {\"energy\": \"eV\",\"forces\": \"ev/Ang\",\"stress\": \"ev/Ang^3\"}\n",
    "            fileAtoms.set_array(\"qe_forces\", trajectory.arrays[\"forces\"][0])\n",
    "\n",
    "            parameters = struct_out_params[\"parameters\"]\n",
    "            fileParams = parameters.get_dict()\n",
    "            fileAtoms.info[\"qe_energy\"] = fileParams[\"energy\"]\n",
    "            write(path, fileAtoms, append=True)\n",
    "\n",
    "        training_files[file_name] = str(path.resolve())\n",
    "\n",
    "    with open(\"JanusConfigfile.yml\", \"a\") as f:\n",
    "        yaml.safe_dump(training_files, f, sort_keys=False)\n",
    "\n",
    "    return{'JanusConfigfile': JanusConfigfile(Path(\"JanusConfigfile.yml\").resolve())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5766874",
   "metadata": {},
   "source": [
    "For this task, we are using a task to run a pure python function. This is to demonstrate the flexibility of tasks and how you can run python functions with Workgraph. Also this task has to be a calcfunction, as we are returning `SinglefileData` instances of the test, train and valid files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac1993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import Int\n",
    "@task.calcfunction(outputs = [\"test_file\", \"train_file\", \"valid_file\"])\n",
    "def create_qe_files(**inputs):\n",
    "\n",
    "    n_samples = Int(len(inputs['trajectory_data']))\n",
    "    print(n_samples)\n",
    "\n",
    "    files = process_and_split_data( \n",
    "        **inputs,\n",
    "        n_samples=n_samples,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"train_file\": SinglefileData(files[\"train_file\"]),\n",
    "        \"test_file\": SinglefileData(files[\"test_file\"]),\n",
    "        \"valid_file\": SinglefileData(files[\"valid_file\"])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to tidy up these inputs: inputs is original (needs renaming for md_inputs) and others are QE etc\n",
    "\n",
    "from aiida.orm import Str, Float, Bool, Int, Dict\n",
    "inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cpu\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "    \"ensemble\": Str(\"NVT\"),\n",
    "    \"struct\": init_structure,\n",
    "    \"md_kwargs\": Dict(\n",
    "        {\n",
    "            \"steps\": 10,\n",
    "            \"traj-every\": 2\n",
    "        }\n",
    "    )\n",
    "}\n",
    "calc_inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cpu\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "}\n",
    "\n",
    "split_task_inputs = {\n",
    "    \"config_types\": Str(\"\"),\n",
    "    \"prefix\": Str(\"\"),\n",
    "    \"scale\": Float(1.0e5),\n",
    "    \"append_mode\": Bool(False),\n",
    "}\n",
    "\n",
    "qe_inputs = {\n",
    "    \"task_metadata\": Dict({\n",
    "            \"options\": {\n",
    "                \"resources\": {\n",
    "                    \"num_machines\": 1,\n",
    "                    \"num_mpiprocs_per_machine\": 32,\n",
    "                },\n",
    "                \"max_wallclock_seconds\": 3600,\n",
    "                \"queue_name\": \"scarf\",\n",
    "                \"qos\": \"scarf\",\n",
    "                \"environment_variables\": {},\n",
    "                \"withmpi\": True,\n",
    "                \"prepend_text\": \"\"\"\n",
    "                    module purge\n",
    "                    module use /work4/scd/scarf562/eb-common/modules/all\n",
    "                    module load amd-modules\n",
    "                    module load QuantumESPRESSO/7.2-foss-2023a\n",
    "                \"\"\",\n",
    "                \"append_text\": \"\",\n",
    "            },\n",
    "    }),\n",
    "    \"kpoints_mesh\": List([1, 1, 1]),\n",
    "    \"code\": qe_code,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82a4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "with WorkGraph(\"MD\") as wg:\n",
    "\n",
    "    md_calc = wg.add_task(\n",
    "        mdCalc,\n",
    "        name=\"md_calc\",\n",
    "        **inputs\n",
    "    )\n",
    "\n",
    "    descriptors_calc = wg.add_task(\n",
    "        descriptors_task,\n",
    "        code=janus_code,\n",
    "        model=model,\n",
    "        device=Str(\"cpu\"),\n",
    "        arch=Str(model.architecture),\n",
    "        file=md_calc.outputs.traj_file\n",
    "    )\n",
    "   \n",
    "    split_task = wg.add_task(\n",
    "        create_qe_files, \n",
    "        **split_task_inputs,\n",
    "        trajectory_data=descriptors_calc.outputs.final_structs,\n",
    "    )\n",
    "    \n",
    "    qe_task = wg.add_task(\n",
    "        qe, \n",
    "        name=\"QE_workflow\",\n",
    "        test_file= split_task.outputs.test_file,\n",
    "        train_file= split_task.outputs.train_file,\n",
    "        valid_file= split_task.outputs.valid_file,\n",
    "        **qe_inputs\n",
    "    )\n",
    "\n",
    "    training_files = wg.add_task(\n",
    "        create_train_file, \n",
    "        test_file= qe_task.outputs.test_file,\n",
    "        train_file= qe_task.outputs.train_file,\n",
    "        valid_file= qe_task.outputs.valid_file,\n",
    "        )\n",
    "\n",
    "    train_task = wg.add_task(\n",
    "        trainCalc,\n",
    "        mlip_config=training_files.outputs.JanusConfigfile,\n",
    "        code=calc_inputs[\"code\"],\n",
    "        foundation_model=calc_inputs[\"model\"],\n",
    "        metadata=calc_inputs[\"metadata\"],\n",
    "        fine_tune=True,\n",
    "    )\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394b437",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d0545",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fabb5db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3b99ef4",
   "metadata": {},
   "source": [
    "# Additional information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a07fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(wg.tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3f5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "! verdi process list -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(descriptorsCalc.spec().inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(wg.tasks.md_calc.outputs.traj_file.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aa6a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdCalc.get_description()[\"spec\"][\"outputs\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9180ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('outputs of mdCalc:', md_calc.outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c34e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(wg.tasks.md_calc.outputs.traj_file.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af828b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('outputs of descriptors_task:', descriptors_calc.outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find inputs/outputs of mdcalc uncomment following: \n",
    "mdCalc.get_description()[\"spec\"][\"outputs\"].keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiida-mlip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
