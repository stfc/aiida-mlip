{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ecbb39",
   "metadata": {},
   "source": [
    "# WorkGraph Example: MD Simulation with DFT Labeling and Model Fine-tuning\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial demonstrates an end-to-end workflow for generating training data and fine-tuning a machine learning interatomic potential (MLIP). The workflow consists of:\n",
    "\n",
    "1. **Molecular Dynamics (MD)**: Generate diverse structural configurations of NaCl\n",
    "2. **Descriptor Calculation**: Compute MLIP descriptors for structure filtering\n",
    "3. **Data Splitting**: Filter and split structures into train/validation/test sets\n",
    "4. **DFT Labeling**: Calculate accurate energies, forces, and stresses using Quantum ESPRESSO\n",
    "5. **Model Fine-tuning**: Train a MACE model on the DFT-labeled data\n",
    "\n",
    "\n",
    "## Workflow Architecture\n",
    "\n",
    "```\n",
    "Initial Structure (NaCl)\n",
    "        ↓\n",
    "    [MD Simulation] → Trajectory (6 snapshots)\n",
    "        ↓\n",
    "    [Descriptors] → Structure features\n",
    "        ↓\n",
    "    [Filter & Split] → Train/Valid/Test sets\n",
    "        ↓\n",
    "    [Quantum ESPRESSO] → DFT energies/forces/stresses\n",
    "        ↓\n",
    "    [Create Training Files] → ExtXYZ with DFT labels\n",
    "        ↓\n",
    "    [Fine-tune MACE] → Improved MLIP model\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bfb65e",
   "metadata": {},
   "source": [
    "### Load AiiDA Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79098139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profile<uuid='60b17659a9844c4bbd3bef8de0a8f417' name='presto'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aiida import load_profile\n",
    "load_profile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef36ae",
   "metadata": {},
   "source": [
    "### Verify SSSP Pseudopotentials\n",
    "\n",
    "Quantum ESPRESSO requires pseudopotentials for DFT calculations. We check that the SSSP library is installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716ecb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SSSP pseudopotentials installed (103 pseudos)\n"
     ]
    }
   ],
   "source": [
    "from aiida.orm import load_group\n",
    "try:\n",
    "    pseudo_family = load_group('SSSP/1.3/PBE/efficiency')\n",
    "    print(f\" SSSP pseudopotentials installed ({len(pseudo_family.nodes)} pseudos)\")\n",
    "except Exception:\n",
    "    print(\" SSSP not installed, Run: aiida-pseudo install sssp -v 1.3 -p efficiency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d393384",
   "metadata": {},
   "source": [
    "### Load ML Potential Model\n",
    "We download a pre-trained MACE model from the janus-core repository. This foundation model will be:\n",
    "- Used for the initial MD simulation\n",
    "- Used to calculate descriptors for filtering\n",
    "- Fine-tuned on our DFT-labeled data\n",
    "\n",
    "The `ModelData.from_uri()` function automatically caches the model locally to avoid repeated downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc2cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_mlip.data.model import ModelData\n",
    "uri = \"https://github.com/stfc/janus-core/raw/main/tests/models/mace_mp_small.model\"\n",
    "model = ModelData.from_uri(uri, architecture=\"mace_mp\", cache_dir=\"mlips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c68186",
   "metadata": {},
   "source": [
    "### Define Initial Structure\n",
    "\n",
    "We create a rocksalt NaCl structure with a lattice parameter of 5.63 Å. This serves as the starting point for our MD simulation.\n",
    "\n",
    "**Why NaCl?** It's a simple ionic crystal that demonstrates:\n",
    "- Multi-element systems\n",
    "- Different atomic environments\n",
    "- Structural variations during MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89ba5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import StructureData\n",
    "from ase.build import bulk\n",
    "from ase.io import read, iread\n",
    "\n",
    "# structure = StructureData(ase=read(\"Structures/qmof-ffeef76.cif\"))\n",
    "init_structure = StructureData(ase=bulk(\"NaCl\", \"rocksalt\", 5.63))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12932e35",
   "metadata": {},
   "source": [
    "### Load Computational Codes\n",
    "\n",
    "We need two codes:\n",
    "- **janus@localhost**: For MLIP calculations (MD, descriptors, training) - runs locally\n",
    "- **qe@scarf**: For DFT calculations with Quantum ESPRESSO - runs on HPC cluster\n",
    "\n",
    "See examples>tutorials>aiida_setup for setting up janus code and external computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae62816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import load_code\n",
    "janus_code = load_code(\"janus@localhost\")\n",
    "qe_code = load_code(\"qe@scarf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f240333a",
   "metadata": {},
   "source": [
    "### Define Calculation Types\n",
    "\n",
    "We define three calculation types from the `aiida-mlip` plugin:\n",
    "- `mdCalc`: Molecular dynamics simulation\n",
    "- `descriptorsCalc`: Compute structural descriptors\n",
    "- `trainCalc`: Fine-tune the MLIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4c78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.plugins import CalculationFactory\n",
    "\n",
    "mdCalc = CalculationFactory(\"mlip.md\")\n",
    "descriptorsCalc = CalculationFactory(\"mlip.descriptors\")\n",
    "trainCalc = CalculationFactory(\"mlip.train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36acd26d",
   "metadata": {},
   "source": [
    "## Task 1: Descriptors Calculation\n",
    "\n",
    "### Purpose\n",
    "After MD generates trajectory snapshots, we calculate descriptors for each structure. These descriptors:\n",
    "- Characterize the local atomic environment\n",
    "- Enable intelligent filtering of structures\n",
    "- Are calculated per-element (separate Na and Cl descriptors)\n",
    "\n",
    "### Implementation Details\n",
    "This task uses a **dynamic graph** pattern:\n",
    "- Loops over each structure in the trajectory\n",
    "- Creates a separate `Descriptors` calculation task for each\n",
    "- Stores results in the workflow context\n",
    "- Returns all structures as `final_structs` dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0b91b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defining outputnode\n"
     ]
    }
   ],
   "source": [
    "from aiida_workgraph import WorkGraph, task, dynamic, namespace\n",
    "from aiida.orm import SinglefileData\n",
    "\n",
    "descriptorsTask = task(descriptorsCalc)\n",
    "\n",
    "@task.graph(outputs=namespace(final_structs=dynamic(SinglefileData)))\n",
    "def descriptors_task(\n",
    "    code,\n",
    "    model,\n",
    "    device,\n",
    "    arch,\n",
    "    file,\n",
    "):\n",
    "    results = {}\n",
    "    \n",
    "    with file.as_path() as path:\n",
    "        for i, structs in enumerate(iread(path)):\n",
    "            structure = StructureData(ase=structs)\n",
    "\n",
    "            desc_calc = descriptorsTask(\n",
    "                code=code,\n",
    "                model=model,\n",
    "                device=device,\n",
    "                arch=arch,\n",
    "                struct=structure,\n",
    "                calc_per_element=True,\n",
    "                metadata={\"options\": {\"resources\": {\"num_machines\": 1}}}\n",
    "            )\n",
    "\n",
    "            results[f\"struct{i}\"] = desc_calc.xyz_output\n",
    "\n",
    "    return {\"final_structs\": results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ecc71",
   "metadata": {},
   "source": [
    "## Task 2: Quantum ESPRESSO DFT Calculations\n",
    "\n",
    "### Purpose\n",
    "Run high-accuracy DFT calculations to obtain reference data:\n",
    "- **Total energy**: Ground state energy of each structure\n",
    "- **Forces**: Atomic forces for training\n",
    "- **Stress tensor**: Needed for NPT dynamics and equation of state\n",
    "\n",
    "### Implementation Details\n",
    "\n",
    "This task processes three files (train, test, validation) and runs DFT calculations on each structure:\n",
    "\n",
    "**Pseudopotentials**: Automatically retrieves appropriate pseudopotentials for Na and Cl from SSSP library\n",
    "\n",
    "**Cutoff energies**: Uses recommended values from SSSP for convergence:\n",
    "- `ecutwfc`: Plane-wave kinetic energy cutoff\n",
    "- `ecutrho`: Charge density cutoff\n",
    "\n",
    "**K-points**: Uses Γ-point only (1×1×1 mesh) - sufficient for the supercell size\n",
    "\n",
    "**DFT Parameters**:\n",
    "- SCF calculation (self-consistent field)\n",
    "- `tprnfor=True`: Calculate forces\n",
    "- `tstress=True`: Calculate stress tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62de8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import (\n",
    "    TrajectoryData,\n",
    "    StructureData, \n",
    "    load_group, \n",
    "    KpointsData, \n",
    "    InstalledCode, \n",
    "    List, \n",
    "    Dict,\n",
    ")\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from aiida_quantumespresso.calculations.pw import PwCalculation\n",
    "\n",
    "PwTask = task(PwCalculation)\n",
    "qe_output = namespace(trajectory=TrajectoryData, parameters=Dict)\n",
    "\n",
    "@task.graph(\n",
    "    outputs=namespace(\n",
    "        test_file=dynamic(qe_output),\n",
    "        train_file=dynamic(qe_output),\n",
    "        valid_file=dynamic(qe_output),\n",
    "    )\n",
    ")\n",
    "def qe(\n",
    "    code: InstalledCode,\n",
    "    kpoints_mesh: List,\n",
    "    task_metadata: Dict,\n",
    "    test_file: SinglefileData,\n",
    "    train_file: SinglefileData,\n",
    "    valid_file: SinglefileData\n",
    "    ):\n",
    "\n",
    "    kpoints = KpointsData()\n",
    "    kpoints.set_kpoints_mesh(kpoints_mesh)\n",
    "\n",
    "    pseudo_family = load_group('SSSP/1.3/PBE/efficiency')\n",
    "    \n",
    "    files = {\"test_file\": test_file, \"train_file\": train_file, \"valid_file\": valid_file}\n",
    "    results = {\"test_file\": {}, \"train_file\": {}, \"valid_file\": {}}\n",
    "    \n",
    "    for file_name, file in files.items():\n",
    "        with file.as_path() as path:\n",
    "            for i, structs in enumerate(iread(path, format=\"extxyz\")):\n",
    "                \n",
    "                structure = StructureData(ase=structs)\n",
    "                pseudos = pseudo_family.get_pseudos(structure=structure)\n",
    "\n",
    "                ecutwfc, ecutrho = pseudo_family.get_recommended_cutoffs(\n",
    "                    structure=structure,\n",
    "                    unit='Ry',\n",
    "                )\n",
    "\n",
    "                pw_params = {\n",
    "                    \"CONTROL\": {\n",
    "                        \"calculation\": \"scf\",\n",
    "                        'tprnfor': True,\n",
    "                        'tstress': True,\n",
    "                    },\n",
    "                    \"SYSTEM\": {\n",
    "                        \"ecutwfc\": ecutwfc,\n",
    "                        \"ecutrho\": ecutrho,\n",
    "                    },\n",
    "                }\n",
    "                \n",
    "                qe_task = PwTask(\n",
    "                    code=code,\n",
    "                    parameters=pw_params,\n",
    "                    kpoints=kpoints,\n",
    "                    pseudos=pseudos,\n",
    "                    metadata=task_metadata.value,\n",
    "                    structure=structure,\n",
    "                )\n",
    "                \n",
    "                structfile = f\"{file_name}.struct{i}\"\n",
    "\n",
    "               \n",
    "                results[file_name][f\"struct_{i}\"] = {\n",
    "                    \"trajectory\": qe_task.output_trajectory,\n",
    "                    \"parameters\": qe_task.output_parameters,\n",
    "                }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcacee8",
   "metadata": {},
   "source": [
    "## Task 3: Create Training Files\n",
    "\n",
    "Extract DFT results from Quantum ESPRESSO and format them for MLIP training.\n",
    "\n",
    "1. **Extract data** from QE output:\n",
    "   - Energy from `output_parameters`\n",
    "   - Forces from `output_trajectory`\n",
    "   - Stress tensor from `output_trajectory`\n",
    "\n",
    "2. **Unit conversion**:\n",
    "   - Stress: Convert from Quantum ESPRESSO units to eV/Å³\n",
    "   - Energy: Already in eV\n",
    "   - Forces: Already in eV/Å\n",
    "\n",
    "3. **Create ExtXYZ files**:\n",
    "   - `mlip_train_file.extxyz`: Structures for training\n",
    "   - `mlip_valid_file.extxyz`: Structures for validation\n",
    "   - `mlip_test_file.extxyz`: Structures for testing\n",
    "\n",
    "4. **Update config file**:\n",
    "   - Adds file paths to `JanusConfigfile.yml`\n",
    "   - This config file contains all training parameters\n",
    "\n",
    "\n",
    "The extended XYZ format includes:\n",
    "- Atomic positions\n",
    "- Lattice vectors\n",
    "- DFT energies in `info` dict\n",
    "- Forces as atomic arrays\n",
    "- Stress tensor in `info` dict\n",
    "- Unit specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a430a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_mlip.data.config import JanusConfigfile\n",
    "from aiida.orm import Dict\n",
    "from ase.io import write\n",
    "from ase import units\n",
    "\n",
    "@task.calcfunction(outputs = [\"JanusConfigfile\"])\n",
    "def create_train_file(**inputs):\n",
    "\n",
    "    training_files = {}\n",
    "    \n",
    "    for file_name, structs in inputs.items():\n",
    "        path = Path(f\"mlip_{file_name}.extxyz\")\n",
    "\n",
    "        for struct_out_params in structs.values():\n",
    "            \n",
    "            trajectory = struct_out_params[\"trajectory\"]\n",
    "\n",
    "            fileStructure = trajectory.get_structure(index=0)\n",
    "            fileAtoms = fileStructure.get_ase()\n",
    "\n",
    "            stress = trajectory.arrays[\"stress\"][0]\n",
    "            converted_stress = stress * units.GPa\n",
    "            fileAtoms.info[\"qe_stress\"] = converted_stress\n",
    "\n",
    "            fileAtoms.info[\"units\"] = {\n",
    "                \"energy\": \"eV\",\n",
    "                \"forces\": \"ev/Ang\",\n",
    "                \"stress\": \"ev/Ang^3\"\n",
    "            }\n",
    "            fileAtoms.set_array(\"qe_forces\", trajectory.arrays[\"forces\"][0])\n",
    "\n",
    "            parameters = struct_out_params[\"parameters\"]\n",
    "            fileParams = parameters.get_dict()\n",
    "            fileAtoms.info[\"qe_energy\"] = fileParams[\"energy\"]\n",
    "            write(path, fileAtoms, append=True)\n",
    "\n",
    "        training_files[file_name] = str(path.resolve())\n",
    "\n",
    "    with open(\"JanusConfigfile.yml\", \"a\") as f:\n",
    "        yaml.safe_dump(training_files, f, sort_keys=False)\n",
    "\n",
    "    return{'JanusConfigfile': JanusConfigfile(Path(\"JanusConfigfile.yml\").resolve())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5766874",
   "metadata": {},
   "source": [
    "## Task 4: Data Filtering and Splitting\n",
    "\n",
    "Split the MD trajectory into train/validation/test sets using FPS (Farthest Point Sampling).\n",
    "\n",
    "Note: The warnings about `k is too large` appear when you have fewer structures than the target split size - the algorithm automatically adjusts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ac1993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import Int\n",
    "from sample_split import process_and_split_data\n",
    "\n",
    "@task.calcfunction(outputs = [\"test_file\", \"train_file\", \"valid_file\"])\n",
    "def create_qe_files(**inputs):\n",
    "\n",
    "    n_samples = Int(len(inputs['trajectory_data']))\n",
    "    print(n_samples)\n",
    "\n",
    "    files = process_and_split_data( \n",
    "        **inputs,\n",
    "        n_samples=n_samples,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"train_file\": SinglefileData(files[\"train_file\"]),\n",
    "        \"test_file\": SinglefileData(files[\"test_file\"]),\n",
    "        \"valid_file\": SinglefileData(files[\"valid_file\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff193a2",
   "metadata": {},
   "source": [
    "## Configure Input Parameters\n",
    "\n",
    "\n",
    "**NVT Ensemble**: \n",
    "- Maintains constant Number of particles, Volume, and Temperature\n",
    "- Suitable for sampling structural variations\n",
    "- Uses a thermostat to control temperature\n",
    "\n",
    "See https://stfc.github.io/janus-core/tutorials/cli/md.html for other ensemvles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1795dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import Str, Float, Bool, Dict\n",
    "inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cpu\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "    \"ensemble\": Str(\"NVT\"),\n",
    "    \"struct\": init_structure,\n",
    "    \"md_kwargs\": Dict(\n",
    "        {\n",
    "            \"steps\": 10,\n",
    "            \"traj-every\": 2\n",
    "        }\n",
    "    )\n",
    "}\n",
    "calc_inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cpu\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "}\n",
    "split_task_inputs = {\n",
    "    \"config_types\": Str(\"\"),\n",
    "    \"prefix\": Str(\"\"),\n",
    "    \"scale\": Float(1.0e5),\n",
    "    \"append_mode\": Bool(False),\n",
    "}\n",
    "qe_inputs = {\n",
    "    \"task_metadata\": Dict({\n",
    "            \"options\": {\n",
    "                \"resources\": {\n",
    "                    \"num_machines\": 1,\n",
    "                    \"num_mpiprocs_per_machine\": 32,\n",
    "                },\n",
    "                \"max_wallclock_seconds\": 3600,\n",
    "                \"queue_name\": \"scarf\",\n",
    "                \"qos\": \"scarf\",\n",
    "                \"environment_variables\": {},\n",
    "                \"withmpi\": True,\n",
    "                \"prepend_text\": \"\"\"\n",
    "                    module purge\n",
    "                    module use /work4/scd/scarf562/eb-common/modules/all\n",
    "                    module load amd-modules\n",
    "                    module load QuantumESPRESSO/7.2-foss-2023a\n",
    "                \"\"\",\n",
    "                \"append_text\": \"\",\n",
    "            },\n",
    "    }),\n",
    "    \"kpoints_mesh\": List([1, 1, 1]),\n",
    "    \"code\": qe_code,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0241edf",
   "metadata": {},
   "source": [
    "\n",
    "## Build and Run the WorkGraph\n",
    "\n",
    "### WorkGraph Structure\n",
    "\n",
    "The workflow is defined using AiiDA WorkGraph, which:\n",
    "- Automatically manages task dependencies\n",
    "- Enables parallel execution where possible\n",
    "- Tracks provenance of all calculations\n",
    "- Handles job submission to HPC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e82a4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdTask = task(mdCalc)\n",
    "trainTask = task(trainCalc)\n",
    "\n",
    "@task.graph()\n",
    "def md_training_workflow(\n",
    "    janus_code,\n",
    "    qe_code,\n",
    "    model,\n",
    "    md_kwargs,\n",
    "    ensemble,\n",
    "    init_structure,\n",
    "    split_inputs,\n",
    "    qe_metadata,\n",
    "    qe_kpoints,\n",
    "):\n",
    "    md_calc = mdTask(\n",
    "        code=janus_code,\n",
    "        model=model,\n",
    "        arch=Str(model.architecture),\n",
    "        device=Str(\"cpu\"),\n",
    "        metadata={\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "        ensemble=ensemble,\n",
    "        struct=init_structure,\n",
    "        md_kwargs=md_kwargs\n",
    "    )\n",
    "\n",
    "    descriptors_calc = descriptors_task(\n",
    "        code=janus_code,\n",
    "        model=model,\n",
    "        device=Str(\"cpu\"),\n",
    "        arch=Str(model.architecture),\n",
    "        file=md_calc.traj_file\n",
    "    )\n",
    "   \n",
    "    split_task = create_qe_files(\n",
    "        **split_inputs,\n",
    "        trajectory_data=descriptors_calc.final_structs,\n",
    "    )\n",
    "    \n",
    "    qe_task = qe(\n",
    "        code=qe_code,\n",
    "        kpoints_mesh=qe_kpoints,\n",
    "        task_metadata=qe_metadata,\n",
    "        test_file=split_task.test_file,\n",
    "        train_file=split_task.train_file,\n",
    "        valid_file=split_task.valid_file,\n",
    "    )\n",
    "\n",
    "    training_files = create_train_file(\n",
    "        test_file=qe_task.test_file,\n",
    "        train_file=qe_task.train_file,\n",
    "        valid_file=qe_task.valid_file,\n",
    "    )\n",
    "\n",
    "    train_task = trainTask(\n",
    "        mlip_config=training_files.JanusConfigfile,\n",
    "        code=janus_code,\n",
    "        foundation_model=model,\n",
    "        metadata={\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "        fine_tune=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b87291f",
   "metadata": {},
   "source": [
    "### Build the workgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3683830",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = md_training_workflow.build(\n",
    "    janus_code=janus_code,\n",
    "    qe_code=qe_code,\n",
    "    model=model,\n",
    "    md_kwargs=inputs[\"md_kwargs\"],\n",
    "    ensemble=inputs[\"ensemble\"],\n",
    "    init_structure=init_structure,\n",
    "    split_inputs=split_task_inputs,\n",
    "    qe_metadata=qe_inputs[\"task_metadata\"],\n",
    "    qe_kpoints=qe_inputs[\"kpoints_mesh\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd843a",
   "metadata": {},
   "source": [
    "### Execution\n",
    "\n",
    "`wg.run()` submits the entire workflow and monitors its progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4394b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/24/2025 10:06:56 AM <916425> aiida.broker.rabbitmq: [WARNING] RabbitMQ v3.12.1 is not supported and will cause unexpected problems!\n",
      "12/24/2025 10:06:56 AM <916425> aiida.broker.rabbitmq: [WARNING] It can cause long-running workflows to crash and jobs to be submitted multiple times.\n",
      "12/24/2025 10:06:56 AM <916425> aiida.broker.rabbitmq: [WARNING] See https://github.com/aiidateam/aiida-core/wiki/RabbitMQ-version-to-use for details.\n",
      "12/24/2025 10:06:57 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|continue_workgraph]: tasks ready to run: MD\n",
      "12/24/2025 10:06:57 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qoj42292/.aiida/scratch/presto/e6/99/6657-765e-4311-bf7a-a6f8dec4d5ae md-summary.yml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/24/2025 10:07:13 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|update_task_state]: Task: MD, type: CALCJOB, finished.\n",
      "12/24/2025 10:07:15 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|continue_workgraph]: tasks ready to run: descriptors_task\n",
      "12/24/2025 10:07:17 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7555\n",
      "12/24/2025 10:07:18 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|continue_workgraph]: tasks ready to run: Descriptors,Descriptors1,Descriptors2,Descriptors3,Descriptors4,Descriptors5\n",
      "12/24/2025 10:07:21 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7560, 7565, 7570, 7575, 7580, 7585\n",
      "12/24/2025 10:07:58 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|update_task_state]: Task: Descriptors, type: CALCJOB, finished.\n",
      "12/24/2025 10:07:58 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "12/24/2025 10:07:58 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7565, 7570, 7575, 7580, 7585\n",
      "12/24/2025 10:08:00 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|update_task_state]: Task: Descriptors1, type: CALCJOB, finished.\n",
      "12/24/2025 10:08:00 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|update_task_state]: Task: Descriptors2, type: CALCJOB, finished.\n",
      "12/24/2025 10:08:01 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|update_task_state]: Task: Descriptors3, type: CALCJOB, finished.\n",
      "12/24/2025 10:08:01 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "12/24/2025 10:08:01 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7580, 7585\n",
      "12/24/2025 10:08:02 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|update_task_state]: Task: Descriptors4, type: CALCJOB, finished.\n",
      "12/24/2025 10:08:03 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|update_task_state]: Task: Descriptors5, type: CALCJOB, finished.\n",
      "12/24/2025 10:08:03 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "12/24/2025 10:08:03 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7555|WorkGraphEngine|finalize]: Finalize workgraph.\n",
      "12/24/2025 10:08:03 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|update_task_state]: Task: descriptors_task, type: GRAPH, finished.\n",
      "12/24/2025 10:08:04 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|continue_workgraph]: tasks ready to run: create_qe_files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uuid: da09e2c1-ac92-4b8d-8fea-a0db15725209 (unstored) value: 6\n",
      "create files: train_file=PosixPath('train.xyz'), valid_file=PosixPath('valid.xyz') and test_file=PosixPath('test.xyz')\n",
      "Processing: ('all', 'aiida'), 6 frames\n",
      "  ('all', 'aiida'): total=6, train_target=4,                     vt_target=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/fpsample/wrapper.py:98: UserWarning: k is too large, set to 6\n",
      "  warnings.warn(f\"k is too large, set to {n_pts}\")\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/fpsample/wrapper.py:98: UserWarning: k is too large, set to 2\n",
      "  warnings.warn(f\"k is too large, set to {n_pts}\")\n",
      "12/24/2025 10:08:05 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|update_task_state]: Task: create_qe_files, type: CALCFUNCTION, finished.\n",
      "12/24/2025 10:08:05 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|continue_workgraph]: tasks ready to run: qe\n",
      "12/24/2025 10:08:06 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7633\n",
      "12/24/2025 10:08:06 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|continue_workgraph]: tasks ready to run: PwCalculation,PwCalculation1,PwCalculation2,PwCalculation3,PwCalculation4,PwCalculation5\n",
      "12/24/2025 10:08:08 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7635, 7637, 7639, 7641, 7643, 7645\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida/transports/plugins/ssh.py:674: AiidaDeprecationWarning: `chdir()` is deprecated and will be removed in the next major version. Use absolute paths instead. (this will be removed in v3)\n",
      "  warn_deprecation(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:15: AiidaDeprecationWarning: The parse_xml.versions module is deprecated and will be removed in aiida-quantumespresso v5.0.\n",
      "Use get_schema_filepath() from parse_xml.parse instead.\n",
      "  from aiida_quantumespresso.parsers.parse_xml.versions import QeXmlVersion, get_xml_file_version\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/legacy.py:18: AiidaDeprecationWarning: This module has been deprecated and will be removed in aiida-quantumespresso v5.0.\n",
      "If you are seeing this warning, you will have to update your Quantum ESPRESSO version (v6.6 or above).\n",
      "  warnings.warn(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/legacy.py:27: AiidaDeprecationWarning: This module has been deprecated and will be removed in aiida-quantumespresso v5.0.\n",
      "If you are seeing this warning, you will have to update your Quantum ESPRESSO version (v6.6 or above).\n",
      "  warnings.warn(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:19: AiidaDeprecationWarning: The parse_xml.pw.parse module has been deprecated and will be removed in aiida-quantumespresso v5.0.\n",
      "Use parse_xml() from parse_xml.parse directly. Legacy XML format support will be dropped.\n",
      "  warnings.warn(\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "/home/qoj42292/aiida-mlip/.venv/lib/python3.12/site-packages/aiida_quantumespresso/parsers/parse_xml/pw/parse.py:35: AiidaDeprecationWarning: parse_xml_post_6_2() is deprecated. Use parse_xml() instead which takes a file-like object.\n",
      "This function will be removed in aiida-quantumespresso v5.0.\n",
      "  parsed_data, logs = parse_xml_post_6_2(xml_parsed)\n",
      "12/24/2025 10:11:33 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|update_task_state]: Task: PwCalculation, type: CALCJOB, finished.\n",
      "12/24/2025 10:11:34 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|update_task_state]: Task: PwCalculation1, type: CALCJOB, finished.\n",
      "12/24/2025 10:11:34 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|update_task_state]: Task: PwCalculation2, type: CALCJOB, finished.\n",
      "12/24/2025 10:11:34 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|update_task_state]: Task: PwCalculation3, type: CALCJOB, finished.\n",
      "12/24/2025 10:11:34 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|update_task_state]: Task: PwCalculation4, type: CALCJOB, finished.\n",
      "12/24/2025 10:11:35 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|update_task_state]: Task: PwCalculation5, type: CALCJOB, finished.\n",
      "12/24/2025 10:11:35 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "12/24/2025 10:11:35 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7633|WorkGraphEngine|finalize]: Finalize workgraph.\n",
      "12/24/2025 10:11:35 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|update_task_state]: Task: qe, type: GRAPH, finished.\n",
      "12/24/2025 10:11:36 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|continue_workgraph]: tasks ready to run: create_train_file\n",
      "12/24/2025 10:11:38 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|update_task_state]: Task: create_train_file, type: CALCFUNCTION, finished.\n",
      "12/24/2025 10:11:38 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|continue_workgraph]: tasks ready to run: Train\n",
      "12/24/2025 10:11:38 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|on_wait]: Process status: Waiting for child processes: 7679\n",
      "12/24/2025 10:12:11 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|update_task_state]: Task: Train, type: CALCJOB, finished.\n",
      "12/24/2025 10:12:11 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n",
      "12/24/2025 10:12:11 AM <916425> aiida.orm.nodes.process.workflow.workchain.WorkChainNode: [REPORT] [7535|WorkGraphEngine|finalize]: Finalize workgraph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9639a",
   "metadata": {},
   "source": [
    "\n",
    "### Visualize the WorkGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c6d0545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e75d7c139cd4a7e8a478db84e4cc86b",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "NodeGraphWidget(settings={'minimap': True}, states={'graph_inputs': 'FINISHED', 'graph_outputs': 'FINISHED', '…"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ed58e",
   "metadata": {},
   "source": [
    "### After successful completion, you have:\n",
    "\n",
    "1. **Fine-tuned MACE model**: Improved accuracy for NaCl systems\n",
    "2. **Training datasets**: ExtXYZ files with DFT labels\n",
    "3. **Complete provenance**: Full AiiDA history of all calculations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiida-mlip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
