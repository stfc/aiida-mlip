{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ecbb39",
   "metadata": {},
   "source": [
    "# WorkGraph Example: MD Simulation with DFT Labeling and Model Fine-tuning\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial demonstrates an end-to-end workflow for generating training data and fine-tuning a machine learning interatomic potential (MLIP). The workflow consists of:\n",
    "\n",
    "1. **Molecular Dynamics (MD)**: Generate diverse structural configurations of NaCl\n",
    "2. **Descriptor Calculation**: Compute MLIP descriptors for structure filtering\n",
    "3. **Data Splitting**: Filter and split structures into train/validation/test sets\n",
    "4. **DFT Labeling**: Calculate accurate energies, forces, and stresses using Quantum ESPRESSO\n",
    "5. **Model Fine-tuning**: Train a MACE model on the DFT-labeled data\n",
    "\n",
    "This approach allows you to create high-quality training data from MD simulations and improve your MLIP's accuracy on specific systems.\n",
    "\n",
    "## Workflow Architecture\n",
    "\n",
    "```\n",
    "Initial Structure (NaCl)\n",
    "        ↓\n",
    "    [MD Simulation] → Trajectory (6 snapshots)\n",
    "        ↓\n",
    "    [Descriptors] → Structure features\n",
    "        ↓\n",
    "    [Filter & Split] → Train/Valid/Test sets\n",
    "        ↓\n",
    "    [Quantum ESPRESSO] → DFT energies/forces/stresses\n",
    "        ↓\n",
    "    [Create Training Files] → ExtXYZ with DFT labels\n",
    "        ↓\n",
    "    [Fine-tune MACE] → Improved MLIP model\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bfb65e",
   "metadata": {},
   "source": [
    "### Load AiiDA Profile\n",
    "\n",
    "First, we load the AiiDA profile to access the database and computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79098139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida import load_profile\n",
    "load_profile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef36ae",
   "metadata": {},
   "source": [
    "### Verify SSSP Pseudopotentials\n",
    "\n",
    "Quantum ESPRESSO requires pseudopotentials for DFT calculations. We check that the SSSP library is installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716ecb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import load_group\n",
    "try:\n",
    "    pseudo_family = load_group('SSSP/1.3/PBE/efficiency')\n",
    "    print(f\" SSSP pseudopotentials installed ({len(pseudo_family.nodes)} pseudos)\")\n",
    "except Exception:\n",
    "    print(\" SSSP not installed, Run: aiida-pseudo install sssp -v 1.3 -p efficiency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d393384",
   "metadata": {},
   "source": [
    "### Load ML Potential Model\n",
    "We download a pre-trained MACE model from the janus-core repository. This foundation model will be:\n",
    "- Used for the initial MD simulation\n",
    "- Used to calculate descriptors for filtering\n",
    "- Fine-tuned on our DFT-labeled data\n",
    "\n",
    "The `ModelData.from_uri()` function automatically caches the model locally to avoid repeated downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_mlip.data.model import ModelData\n",
    "uri = \"https://github.com/stfc/janus-core/raw/main/tests/models/mace_mp_small.model\"\n",
    "model = ModelData.from_uri(uri, architecture=\"mace_mp\", cache_dir=\"mlips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c68186",
   "metadata": {},
   "source": [
    "### Define Initial Structure\n",
    "\n",
    "We create a rocksalt NaCl structure with a lattice parameter of 5.63 Å. This serves as the starting point for our MD simulation.\n",
    "\n",
    "**Why NaCl?** It's a simple ionic crystal that demonstrates:\n",
    "- Multi-element systems\n",
    "- Different atomic environments\n",
    "- Structural variations during MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89ba5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import StructureData\n",
    "from ase.build import bulk\n",
    "from ase.io import read, iread\n",
    "\n",
    "# structure = StructureData(ase=read(\"Structures/qmof-ffeef76.cif\"))\n",
    "init_structure = StructureData(ase=bulk(\"NaCl\", \"rocksalt\", 5.63))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12932e35",
   "metadata": {},
   "source": [
    "### Load Computational Codes\n",
    "\n",
    "We need two codes:\n",
    "- **janus@localhost**: For MLIP calculations (MD, descriptors, training) - runs locally\n",
    "- **qe@scarf**: For DFT calculations with Quantum ESPRESSO - runs on HPC cluster\n",
    "\n",
    "See examples>tutorials>aiida_setup for setting up janus code and external computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import load_code\n",
    "janus_code = load_code(\"janus@localhost\")\n",
    "qe_code = load_code(\"qe@scarf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f240333a",
   "metadata": {},
   "source": [
    "### Define Calculation Types\n",
    "\n",
    "We define three calculation types from the `aiida-mlip` plugin:\n",
    "- `mdCalc`: Molecular dynamics simulation\n",
    "- `descriptorsCalc`: Compute structural descriptors\n",
    "- `trainCalc`: Fine-tune the MLIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.plugins import CalculationFactory\n",
    "\n",
    "mdCalc = CalculationFactory(\"mlip.md\")\n",
    "descriptorsCalc = CalculationFactory(\"mlip.descriptors\")\n",
    "trainCalc = CalculationFactory(\"mlip.train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36acd26d",
   "metadata": {},
   "source": [
    "## Task 1: Descriptors Calculation\n",
    "\n",
    "### Purpose\n",
    "After MD generates trajectory snapshots, we calculate descriptors for each structure. These descriptors:\n",
    "- Characterize the local atomic environment\n",
    "- Enable intelligent filtering of structures\n",
    "- Are calculated per-element (separate Na and Cl descriptors)\n",
    "\n",
    "### Implementation Details\n",
    "This task uses a **dynamic graph** pattern:\n",
    "- Loops over each structure in the trajectory\n",
    "- Creates a separate `Descriptors` calculation task for each\n",
    "- Stores results in the workflow context\n",
    "- Returns all structures as `final_structs` dictionary\n",
    "\n",
    "The `get_current_graph()` function allows us to dynamically add tasks within this task, enabling parallel execution of descriptor calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_workgraph import WorkGraph, task\n",
    "from aiida_workgraph.manager import get_current_graph\n",
    "\n",
    "@task.graph(outputs = [\"final_structs\"])\n",
    "def descriptors_task(\n",
    "    code,\n",
    "    model,\n",
    "    device,\n",
    "    arch,\n",
    "    file,\n",
    "):\n",
    "    descriptorsCalc = CalculationFactory(\"mlip.descriptors\")\n",
    "    wg = get_current_graph()\n",
    "    final_structures={}\n",
    "    \n",
    "    with file.as_path() as path:\n",
    "        for i, structs in enumerate(iread(path)):\n",
    "            structure = StructureData(ase=structs)\n",
    "\n",
    "            desc_calc = wg.add_task(\n",
    "                descriptorsCalc,\n",
    "                code=code,\n",
    "                model=model,\n",
    "                device=device,\n",
    "                arch=arch,\n",
    "                struct=structure,\n",
    "                calc_per_element=bool(True), # per element descriptors ie. mace Na and Cl\n",
    "                metadata={\"options\": {\"resources\": {\"num_machines\": 1}}}\n",
    "            )\n",
    "\n",
    "            structfile = f\"final_structs.struct{i}\"\n",
    "            #   final_structures[f\"structs{i}\"] = desc_calc.outputs.xyz_output\n",
    "            wg.update_ctx({\n",
    "                structfile : desc_calc.outputs.xyz_output,\n",
    "            })\n",
    "\n",
    "    \n",
    "    n_samp = len(final_structures)\n",
    "    return {\n",
    "        \"final_structs\": wg.ctx.final_structs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ecc71",
   "metadata": {},
   "source": [
    "## Task 2: Quantum ESPRESSO DFT Calculations\n",
    "\n",
    "### Purpose\n",
    "Run high-accuracy DFT calculations to obtain reference data:\n",
    "- **Total energy**: Ground state energy of each structure\n",
    "- **Forces**: Atomic forces for training\n",
    "- **Stress tensor**: Needed for NPT dynamics and equation of state\n",
    "\n",
    "### Implementation Details\n",
    "\n",
    "This task processes three files (train, test, validation) and runs DFT calculations on each structure:\n",
    "\n",
    "**Pseudopotentials**: Automatically retrieves appropriate pseudopotentials for Na and Cl from SSSP library\n",
    "\n",
    "**Cutoff energies**: Uses recommended values from SSSP for convergence:\n",
    "- `ecutwfc`: Plane-wave kinetic energy cutoff\n",
    "- `ecutrho`: Charge density cutoff\n",
    "\n",
    "**K-points**: Uses Γ-point only (1×1×1 mesh) - sufficient for the supercell size\n",
    "\n",
    "**DFT Parameters**:\n",
    "- SCF calculation (self-consistent field)\n",
    "- `tprnfor=True`: Calculate forces\n",
    "- `tstress=True`: Calculate stress tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_workgraph import task\n",
    "from aiida_workgraph.manager import get_current_graph\n",
    "from aiida.orm import StructureData, load_group, KpointsData, SinglefileData, InstalledCode, List, Dict\n",
    "from ase.io import iread\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from aiida_quantumespresso.calculations.pw import PwCalculation\n",
    "from sample_split import process_and_split_data\n",
    "\n",
    "\n",
    "@task.graph(outputs = [\"test_file\", \"train_file\", \"valid_file\"])\n",
    "def qe(\n",
    "    code: InstalledCode,\n",
    "    kpoints_mesh: List,\n",
    "    task_metadata: Dict,\n",
    "    test_file: SinglefileData,\n",
    "    train_file: SinglefileData,\n",
    "    valid_file: SinglefileData\n",
    "    ):\n",
    "\n",
    "    wg = get_current_graph()\n",
    "\n",
    "    kpoints = KpointsData()\n",
    "    kpoints.set_kpoints_mesh(kpoints_mesh)\n",
    "\n",
    "    pseudo_family = load_group('SSSP/1.3/PBE/efficiency')\n",
    "    \n",
    "    files = {\"test_file\": test_file, \"train_file\": train_file, \"valid_file\": valid_file}\n",
    "\n",
    "    for file_name, file in files.items():\n",
    "        with file.as_path() as path:\n",
    "            for i, structs in enumerate(iread(path, format=\"extxyz\")):\n",
    "                \n",
    "                structure = StructureData(ase=structs)\n",
    "                pseudos = pseudo_family.get_pseudos(structure=structure)\n",
    "\n",
    "                ecutwfc, ecutrho = pseudo_family.get_recommended_cutoffs(\n",
    "                    structure=structure,\n",
    "                    unit='Ry',\n",
    "                )\n",
    "\n",
    "                pw_params = {\n",
    "                    \"CONTROL\": {\n",
    "                        \"calculation\": \"scf\",\n",
    "                        'tprnfor': True,\n",
    "                        'tstress': True,\n",
    "                    },\n",
    "                    \"SYSTEM\": {\n",
    "                        \"ecutwfc\": ecutwfc,\n",
    "                        \"ecutrho\": ecutrho,\n",
    "                    },\n",
    "                }\n",
    "                \n",
    "                qe_task = wg.add_task(\n",
    "                    PwCalculation,\n",
    "                    code=code,\n",
    "                    parameters=pw_params,\n",
    "                    kpoints=kpoints,\n",
    "                    pseudos=pseudos,\n",
    "                    metadata=task_metadata.value,\n",
    "                    structure=structure,\n",
    "                )\n",
    "                \n",
    "                structfile = f\"{file_name}.struct{i}\"\n",
    "\n",
    "                wg.update_ctx({\n",
    "                    structfile:{\n",
    "                        \"trajectory\":qe_task.outputs.output_trajectory,\n",
    "                        \"parameters\": qe_task.outputs.output_parameters\n",
    "                    }\n",
    "                })\n",
    "\n",
    "    return {\n",
    "        \"test_file\": wg.ctx.test_file,\n",
    "        \"train_file\": wg.ctx.train_file,\n",
    "        \"valid_file\": wg.ctx.valid_file\n",
    "    }    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcacee8",
   "metadata": {},
   "source": [
    "## Task 3: Create Training Files\n",
    "\n",
    "### Purpose\n",
    "Extract DFT results from Quantum ESPRESSO and format them for MLIP training.\n",
    "\n",
    "### What it does:\n",
    "\n",
    "1. **Extract data** from QE output:\n",
    "   - Energy from `output_parameters`\n",
    "   - Forces from `output_trajectory`\n",
    "   - Stress tensor from `output_trajectory`\n",
    "\n",
    "2. **Unit conversion**:\n",
    "   - Stress: Convert from Quantum ESPRESSO units to eV/Å³\n",
    "   - Energy: Already in eV\n",
    "   - Forces: Already in eV/Å\n",
    "\n",
    "3. **Create ExtXYZ files**:\n",
    "   - `mlip_train_file.extxyz`: Structures for training\n",
    "   - `mlip_valid_file.extxyz`: Structures for validation\n",
    "   - `mlip_test_file.extxyz`: Structures for testing\n",
    "\n",
    "4. **Update config file**:\n",
    "   - Adds file paths to `JanusConfigfile.yml`\n",
    "   - This config file contains all training parameters\n",
    "\n",
    "### ExtXYZ Format\n",
    "The extended XYZ format includes:\n",
    "- Atomic positions\n",
    "- Lattice vectors\n",
    "- DFT energies in `info` dict\n",
    "- Forces as atomic arrays\n",
    "- Stress tensor in `info` dict\n",
    "- Unit specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_mlip.data.config import JanusConfigfile\n",
    "from aiida.orm import Dict\n",
    "from ase.io import write\n",
    "from ase import units\n",
    "\n",
    "@task.calcfunction(outputs = [\"JanusConfigfile\"])\n",
    "def create_train_file(**inputs):\n",
    "\n",
    "    training_files = {}\n",
    "    \n",
    "    for file_name, structs in inputs.items():\n",
    "        path = Path(f\"mlip_{file_name}.extxyz\")\n",
    "\n",
    "        for struct_out_params in structs.values():\n",
    "            \n",
    "            trajectory = struct_out_params[\"trajectory\"]\n",
    "\n",
    "            fileStructure = trajectory.get_structure(index=0)\n",
    "            fileAtoms = fileStructure.get_ase()\n",
    "\n",
    "            stress = trajectory.arrays[\"stress\"][0]\n",
    "            converted_stress = stress * units.GPa\n",
    "            fileAtoms.info[\"qe_stress\"] = converted_stress\n",
    "\n",
    "            fileAtoms.info[\"units\"] = {\"energy\": \"eV\",\"forces\": \"ev/Ang\",\"stress\": \"ev/Ang^3\"}\n",
    "            fileAtoms.set_array(\"qe_forces\", trajectory.arrays[\"forces\"][0])\n",
    "\n",
    "            parameters = struct_out_params[\"parameters\"]\n",
    "            fileParams = parameters.get_dict()\n",
    "            fileAtoms.info[\"qe_energy\"] = fileParams[\"energy\"]\n",
    "            write(path, fileAtoms, append=True)\n",
    "\n",
    "        training_files[file_name] = str(path.resolve())\n",
    "\n",
    "    with open(\"JanusConfigfile.yml\", \"a\") as f:\n",
    "        yaml.safe_dump(training_files, f, sort_keys=False)\n",
    "\n",
    "    return{'JanusConfigfile': JanusConfigfile(Path(\"JanusConfigfile.yml\").resolve())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5766874",
   "metadata": {},
   "source": [
    "## Task 4: Data Filtering and Splitting\n",
    "\n",
    "### Purpose\n",
    "Split the MD trajectory into train/validation/test sets using **FPS (Farthest Point Sampling)** for optimal coverage of configuration space.\n",
    "\n",
    "### How it works:\n",
    "\n",
    "1. **Input**: Descriptor outputs from all structures\n",
    "2. **Filtering**: Uses descriptor-based distance metrics\n",
    "3. **FPS Algorithm**: Selects maximally diverse structures\n",
    "4. **Split ratio**: \n",
    "   - ~67% training\n",
    "   - ~33% validation + test\n",
    "\n",
    "### Why FPS?\n",
    "- Ensures diverse training data\n",
    "- Avoids redundant similar structures\n",
    "- Maximizes information per structure\n",
    "- Better than random sampling\n",
    "\n",
    "The warnings about `k is too large` appear when you have fewer structures than the target split size - the algorithm automatically adjusts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac1993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import Int\n",
    "@task.calcfunction(outputs = [\"test_file\", \"train_file\", \"valid_file\"])\n",
    "def create_qe_files(**inputs):\n",
    "\n",
    "    n_samples = Int(len(inputs['trajectory_data']))\n",
    "    print(n_samples)\n",
    "\n",
    "    files = process_and_split_data( \n",
    "        **inputs,\n",
    "        n_samples=n_samples,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"train_file\": SinglefileData(files[\"train_file\"]),\n",
    "        \"test_file\": SinglefileData(files[\"test_file\"]),\n",
    "        \"valid_file\": SinglefileData(files[\"valid_file\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff193a2",
   "metadata": {},
   "source": [
    "## Configure Input Parameters\n",
    "\n",
    "\n",
    "**NVT Ensemble**: \n",
    "- Maintains constant Number of particles, Volume, and Temperature\n",
    "- Suitable for sampling structural variations\n",
    "- Uses a thermostat to control temperature\n",
    "\n",
    "See https://stfc.github.io/janus-core/tutorials/cli/md.html for other ensemvles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import Str, Float, Bool, Int, Dict\n",
    "inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cpu\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "    \"ensemble\": Str(\"NVT\"),\n",
    "    \"struct\": init_structure,\n",
    "    \"md_kwargs\": Dict(\n",
    "        {\n",
    "            \"steps\": 10,\n",
    "            \"traj-every\": 2\n",
    "        }\n",
    "    )\n",
    "}\n",
    "calc_inputs = {\n",
    "    \"code\": janus_code,\n",
    "    \"model\": model,\n",
    "    \"arch\": Str(model.architecture),\n",
    "    \"device\": Str(\"cpu\"),\n",
    "    \"metadata\": {\"options\": {\"resources\": {\"num_machines\": 1}}},\n",
    "}\n",
    "split_task_inputs = {\n",
    "    \"config_types\": Str(\"\"),\n",
    "    \"prefix\": Str(\"\"),\n",
    "    \"scale\": Float(1.0e5),\n",
    "    \"append_mode\": Bool(False),\n",
    "}\n",
    "qe_inputs = {\n",
    "    \"task_metadata\": Dict({\n",
    "            \"options\": {\n",
    "                \"resources\": {\n",
    "                    \"num_machines\": 1,\n",
    "                    \"num_mpiprocs_per_machine\": 32,\n",
    "                },\n",
    "                \"max_wallclock_seconds\": 3600,\n",
    "                \"queue_name\": \"scarf\",\n",
    "                \"qos\": \"scarf\",\n",
    "                \"environment_variables\": {},\n",
    "                \"withmpi\": True,\n",
    "                \"prepend_text\": \"\"\"\n",
    "                    module purge\n",
    "                    module use /work4/scd/scarf562/eb-common/modules/all\n",
    "                    module load amd-modules\n",
    "                    module load QuantumESPRESSO/7.2-foss-2023a\n",
    "                \"\"\",\n",
    "                \"append_text\": \"\",\n",
    "            },\n",
    "    }),\n",
    "    \"kpoints_mesh\": List([1, 1, 1]),\n",
    "    \"code\": qe_code,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0241edf",
   "metadata": {},
   "source": [
    "\n",
    "## Build and Run the WorkGraph\n",
    "\n",
    "### WorkGraph Structure\n",
    "\n",
    "The workflow is defined using AiiDA WorkGraph, which:\n",
    "- Automatically manages task dependencies\n",
    "- Enables parallel execution where possible\n",
    "- Tracks provenance of all calculations\n",
    "- Handles job submission to HPC\n",
    "\n",
    "Each task waits for its inputs before executing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82a4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "with WorkGraph(\"MD\") as wg:\n",
    "\n",
    "    md_calc = wg.add_task(\n",
    "        mdCalc,\n",
    "        name=\"md_calc\",\n",
    "        **inputs\n",
    "    )\n",
    "\n",
    "    descriptors_calc = wg.add_task(\n",
    "        descriptors_task,\n",
    "        code=janus_code,\n",
    "        model=model,\n",
    "        device=Str(\"cpu\"),\n",
    "        arch=Str(model.architecture),\n",
    "        file=md_calc.outputs.traj_file\n",
    "    )\n",
    "   \n",
    "    split_task = wg.add_task(\n",
    "        create_qe_files, \n",
    "        **split_task_inputs,\n",
    "        trajectory_data=descriptors_calc.outputs.final_structs,\n",
    "    )\n",
    "    \n",
    "    qe_task = wg.add_task(\n",
    "        qe, \n",
    "        name=\"QE_workflow\",\n",
    "        test_file= split_task.outputs.test_file,\n",
    "        train_file= split_task.outputs.train_file,\n",
    "        valid_file= split_task.outputs.valid_file,\n",
    "        **qe_inputs\n",
    "    )\n",
    "\n",
    "    training_files = wg.add_task(\n",
    "        create_train_file, \n",
    "        test_file= qe_task.outputs.test_file,\n",
    "        train_file= qe_task.outputs.train_file,\n",
    "        valid_file= qe_task.outputs.valid_file,\n",
    "        )\n",
    "\n",
    "    train_task = wg.add_task(\n",
    "        trainCalc,\n",
    "        mlip_config=training_files.outputs.JanusConfigfile,\n",
    "        code=calc_inputs[\"code\"],\n",
    "        foundation_model=calc_inputs[\"model\"],\n",
    "        metadata=calc_inputs[\"metadata\"],\n",
    "        fine_tune=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd843a",
   "metadata": {},
   "source": [
    "### Execution\n",
    "\n",
    "`wg.run()` submits the entire workflow and monitors its progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394b437",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9639a",
   "metadata": {},
   "source": [
    "\n",
    "## Visualize the WorkGraph\n",
    "\n",
    "The `wg` object displays an interactive visualization showing:\n",
    "- All tasks and their status\n",
    "- Data flow between tasks\n",
    "- Input/output connections\n",
    "- Task execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d0545",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ed58e",
   "metadata": {},
   "source": [
    "## Results and Next Steps\n",
    "\n",
    "### After successful completion, you have:\n",
    "\n",
    "1. **Fine-tuned MACE model**: Improved accuracy for NaCl systems\n",
    "2. **Training datasets**: ExtXYZ files with DFT labels\n",
    "3. **Complete provenance**: Full AiiDA history of all calculations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a07fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(wg.tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3f5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "! verdi process list -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(descriptorsCalc.spec().inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(wg.tasks.md_calc.outputs.traj_file.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aa6a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdCalc.get_description()[\"spec\"][\"outputs\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9180ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('outputs of mdCalc:', md_calc.outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c34e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(wg.tasks.md_calc.outputs.traj_file.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af828b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('outputs of descriptors_task:', descriptors_calc.outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find inputs/outputs of mdcalc uncomment following: \n",
    "mdCalc.get_description()[\"spec\"][\"outputs\"].keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiida-mlip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
